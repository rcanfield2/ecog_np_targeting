{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac050bf3-ff0c-4dd1-8fa1-d04f493b96a7",
   "metadata": {},
   "source": [
    "This script loads raw neuropixel spike times and prepares data for further analysis by performing the following steps:\n",
    "1. Select which task entries to analyze\n",
    "2. Load behavioral data and select good trials based on the reach time distributions.\n",
    "3. Load neuropixel spike times\n",
    "    - Bin spike times\n",
    "    - Align data to the even of interest\n",
    "    - Smooth timeseries with a Gaussian kernel\n",
    "4. Saves preprocessed data\n",
    "5. Plots basic neural data figures\n",
    "    - Trial averaged firing rate\n",
    "    - Raster plots\n",
    "    - Raster plots organized by target direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb7086-70d1-4e3b-9508-43151da8df12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.291137Z",
     "start_time": "2024-05-03T18:35:59.145410Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aopy\n",
    "import os\n",
    "import pandas as pds\n",
    "from db import dbfunctions as db\n",
    "from ipywidgets import interactive, widgets\n",
    "import scipy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931fac6",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7cb844-4915-420c-984b-581e0c9685bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.415295Z",
     "start_time": "2024-05-03T18:36:03.294173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "subject = 'beignet'\n",
    "data_path_preproc = '/media/moor-data/preprocessed.new/'\n",
    "data_path_raw = '/media/moor-data/raw/neuropixels/'\n",
    "save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/np_analysis_preproc_data\"\n",
    "behavior_save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/behavior\"\n",
    "ap_band_power_save_dir = f\"/media/moor-data/postprocessed/{subject}/neuropixel_ap_band_power\"\n",
    "save_ap_band_power = True\n",
    "\n",
    "# General data parameters\n",
    "task_coords = 'yzx'\n",
    "task_perturb = None\n",
    "task_rotation = 0\n",
    "\n",
    "# Task event code definitions\n",
    "task_codes = aopy.data.bmi3d.load_bmi3d_task_codes()\n",
    "CENTER_TARGET_ON = 16\n",
    "CURSOR_ENTER_CENTER_TARGET = 80\n",
    "CURSOR_ENTER_PERIPHERAL_TARGET = list(range(81,89))\n",
    "PERIPHERAL_TARGET_ON = list(range(17,25))\n",
    "CENTER_TARGET_OFF = 32\n",
    "REWARD = 48\n",
    "DELAY_PENALTY = 66\n",
    "TIMEOUT_PENALTY = 65\n",
    "HOLD_PENALTY = 64\n",
    "PAUSE = 254\n",
    "TIME_ZERO = 238\n",
    "TRIAL_END = 239\n",
    "\n",
    "# # Select which event to align to\n",
    "# # align_event = 'TARGET ONSET'\n",
    "# # align_event = 'GO CUE'\n",
    "# align_event = 'MOVEMENT ONSET'\n",
    "# # align_event = 'ENTER TARGET'\n",
    "# END_TRIAL_CODE = REWARD\n",
    "\n",
    "\n",
    "# Trial selection parameters\n",
    "trial_filter = lambda t: CENTER_TARGET_OFF in t\n",
    "success_rate_window = 19\n",
    "reach_time_std_thresh = 3\n",
    "\n",
    "# Neuropixel data parameters\n",
    "implant_name = ['NP_Insert72', 'NP_Insert137']\n",
    "start_date = '2023-07-13'\n",
    "end_date = '2024-02-05'\n",
    "# end_date = date.today()\n",
    "elec_config = 'bottom'\n",
    "spike_bin_width_mc = 0.01 #[s]\n",
    "smooth_width = 150\n",
    "smooth_nstd = 3\n",
    "\n",
    "# Task data selection parameters\n",
    "tbefore_mc = 0.2\n",
    "tafter_mc = .8\n",
    "\n",
    "# Visualization parameters\n",
    "colors = sn.color_palette(n_colors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68d1899-903a-4783-9967-8f99303b68b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.428058Z",
     "start_time": "2024-05-03T18:36:03.417715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cursor_leave_center_time(data, samplerate, target_radius):\n",
    "    '''\n",
    "    Compute the time when the cursor leaves the center target radius\n",
    "    \n",
    "    Args:\n",
    "        traj (ntrials list of (nt,2)): x,y trajectory data\n",
    "        samplerate\n",
    "        target_radius (float): the radius of the center target\n",
    "        \n",
    "    Returns:\n",
    "        cursor_leave_center_time (ntrials list): the time when the cursor leaves the center target radius\n",
    "    '''\n",
    "    ntr = len(data)\n",
    "    cursor_leave_center_time = []\n",
    "    \n",
    "    for itr in range(ntr):\n",
    "        t_axis = np.arange(data[itr].shape[0])/samplerate\n",
    "        \n",
    "        dist = np.sqrt(data[itr][:,0]**2 + data[itr][:,1]**2)\n",
    "        leave_idx = np.where(dist>target_radius)[0]\n",
    "        temp = t_axis[leave_idx]\n",
    "        cursor_leave_center_time.append(temp[0])\n",
    "    \n",
    "    return cursor_leave_center_time\n",
    "\n",
    "def get_cursor_leave_center_idx(data, target_radius):\n",
    "    '''\n",
    "    Compute the time when the cursor leaves the center target radius\n",
    "    \n",
    "    Args:\n",
    "        traj (ntrials list of (nt,2)): x,y trajectory data\n",
    "        target_radius (float): the radius of the center target\n",
    "        \n",
    "    Returns:\n",
    "        cursor_leave_center_time (ntrials list): the time when the cursor leaves the center target radius. Nan if cursor doesn't leave center target.\n",
    "    '''\n",
    "    ntr = len(data)\n",
    "    cursor_leave_center_time = []\n",
    "    leave_idx = []\n",
    "    for itr in range(ntr):\n",
    "        dist = np.sqrt(data[itr][:,0]**2 + data[itr][:,1]**2)\n",
    "        \n",
    "        try:\n",
    "            temp_leave_idx = np.where(dist>target_radius)[0][0]\n",
    "        except:\n",
    "            temp_leave_idx = np.nan\n",
    "        leave_idx.append(temp_leave_idx)\n",
    "    \n",
    "    return leave_idx\n",
    "\n",
    "def smooth_timeseries_gaus(timeseries_data, samplerate, width, nstd=3, conv_mode='same'):\n",
    "    '''\n",
    "    Smooths across 2 \n",
    "    \n",
    "    Args:\n",
    "        timeseries_data (ntime, ...)\n",
    "        samplerate (int): Sample rate of timeseries\n",
    "        width (float): Width of the gaussian in time [ms] from -nstd to +nstd\n",
    "        nstd (float/int): Number of standard deviations to be used in the filter calculation.\n",
    "        conv_mode (str): Sets the size of the output. Takes eithe 'full', 'valid', or 'same'. See scipy.signal.convolve for full documentationat\n",
    "        \n",
    "    Returns: \n",
    "        smoothed_timeseries\n",
    "    '''\n",
    "    sample_std = (width/nstd)*(samplerate/(1000)) # Convert from s to ms\n",
    "    x = np.arange(-sample_std*nstd, nstd*sample_std+1)\n",
    "    gaus_filter = (1/(sample_std*np.sqrt(2*np.pi)))*np.exp(-(x**2)/(2*sample_std**2))\n",
    "    return np.apply_along_axis(scipy.signal.convolve, 0, timeseries_data, gaus_filter, mode=conv_mode, method='direct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277b839-a384-441f-b0c5-463988c44011",
   "metadata": {},
   "source": [
    "# Select relevant task entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c65d569-1f01-41ad-b204-307475974f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.599978Z",
     "start_time": "2024-05-03T18:36:03.436723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-13 13:06:46.567000: beignet on manual control task, id=9923, 2023-07-13 13:09:07.735000: beignet on manual control task, id=9924, 2023-07-13 13:41:06.548000: beignet on manual control task, id=9925, 2023-07-14 12:10:54.765000: beignet on manual control task, id=9928, 2023-07-14 13:12:04.967000: beignet on manual control task, id=9931, 2023-07-18 14:56:35.442000: beignet on manual control task, id=9940, 2023-07-19 11:49:20.267000: beignet on manual control task, id=9958, 2023-08-28 14:03:24.447000: beignet on manual control task, id=10802, 2023-08-29 15:21:49.044000: beignet on manual control task, id=10812, 2023-08-30 12:01:38.097000: beignet on manual control task, id=10820, 2023-08-31 13:12:42.458000: beignet on manual control task, id=10828, 2023-09-01 11:55:47.553000: beignet on manual control task, id=10835, 2023-11-16 13:24:31.399000: beignet on manual control task, id=12269, 2023-12-28 13:25:30.554000: beignet on manual control task, id=13122, 2024-01-03 14:56:35.152000: beignet on manual control task, id=13239, 2024-01-04 12:41:21.900000: beignet on manual control task, id=13256, 2024-02-01 13:08:57.622000: beignet on manual control task, id=14116, 2024-02-02 13:40:14.082000: beignet on manual control task, id=14139] \n",
      " \n",
      " [datetime.date(2023, 7, 13) datetime.date(2023, 7, 14)\n",
      " datetime.date(2023, 7, 18) datetime.date(2023, 7, 19)\n",
      " datetime.date(2023, 8, 28) datetime.date(2023, 8, 29)\n",
      " datetime.date(2023, 8, 30) datetime.date(2023, 8, 31)\n",
      " datetime.date(2023, 9, 1) datetime.date(2023, 11, 16)\n",
      " datetime.date(2023, 12, 28) datetime.date(2024, 1, 3)\n",
      " datetime.date(2024, 1, 4) datetime.date(2024, 2, 1)\n",
      " datetime.date(2024, 2, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Load neuropixel center-out task data\n",
    "# bad_tes = [13152, 13153, 13154, 13155, 13156, 13272]\n",
    "bad_tes = [13152, 13153, 13154, 13155, 13156, 13272, 12290, 12291, 13102] # Also remove recording at site 48\n",
    "# bad_tes = [13102,13152, 13153, 13154, 13155, 13156, 13272, 9940, 9958, 10812, 10820, 12290, 12291]\n",
    "mc_entries =  db.get_task_entries(subject__name=subject, task__name='manual control', date=(start_date, end_date))\n",
    "mc_entries = [me for me in mc_entries if 'neuropixel_port1_drive_type' in me.task_params and me.task_params['neuropixel_port1_drive_type'] in implant_name\n",
    "             and me.task_params['rotation']==task_coords and me.entry_name != 'flash']\n",
    "\n",
    "# Remove bad TE IDs\n",
    "mc_entries = [me for me in mc_entries if me.id not in bad_tes]\n",
    "dates = np.unique([me.date.date() for me in mc_entries])\n",
    "\n",
    "print(mc_entries, '\\n','\\n', dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887cd896-a30a-4388-b826-1e0d9d733e2c",
   "metadata": {},
   "source": [
    "# Load behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf663d9c-1fd6-4cfb-8675-bce96960c3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:55.009490Z",
     "start_time": "2024-05-03T18:36:03.604742Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e19290f49c4045ae65ee67ea1c229c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subjects = [subject for me in mc_entries]\n",
    "te_ids = [me.id for me in mc_entries]\n",
    "me_dates = [me.date.date() for me in mc_entries]\n",
    "df = aopy.data.bmi3d.tabulate_behavior_data_center_out(data_path_preproc, subjects, te_ids, me_dates, metadata=['target_radius'])\n",
    "df['reward'] = df['reward'].astype(bool)\n",
    "success_rate = aopy.analysis.calc_success_rate_trials(df['reward'], df['reach_completed'], window_size=success_rate_window)\n",
    "success_rate_date_labels = df['date']\n",
    "df = df[df['reward']].reset_index(drop=True)\n",
    "\n",
    "# Add cursor trajectories\n",
    "traj_times = np.array([(hst-tbefore_mc, e[-1]+tafter_mc) for hst, e in zip(df['hold_start_time'], df['event_times'])])\n",
    "df['cursor_traj'] = aopy.data.bmi3d.tabulate_kinematic_data(data_path_preproc, df['subject'], df['te_id'], df['date'], traj_times[:,0], traj_times[:,1], datatype='cursor')\n",
    "df['hand_traj'] = aopy.data.bmi3d.tabulate_kinematic_data(data_path_preproc, df['subject'], df['te_id'], df['date'], traj_times[:,0], traj_times[:,1], datatype='hand')\n",
    "df['start_time'] = traj_times[:,0]\n",
    "\n",
    "# Add behavior metrics\n",
    "df['duration'] = [(t[-1]-t[0])- (tbefore_mc+tafter_mc) for t in traj_times] \n",
    "cursor_traj = [np.array(t) for t in df['cursor_traj']]\n",
    "hand_traj = [np.array(t) for t in df['hand_traj']]\n",
    "df['cursor_vel_traj'] = [np.array([aopy.utils.derivative(np.arange(len(t))/1000, t[:,0]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,1])]).T for t in cursor_traj]\n",
    "df['cursor_vel'] =  [np.mean(aopy.utils.derivative(np.arange(len(t))/1000, t)) for t in cursor_traj]\n",
    "df['hand_vel_traj'] = [np.array([aopy.utils.derivative(np.arange(len(t))/1000, t[:,0]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,1]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,2])]).T for t in hand_traj]\n",
    "df['hand_vel'] =  [np.mean(aopy.utils.derivative(np.arange(len(t))/1000, t)) for t in hand_traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71b386e-f1a4-4cc8-b5ae-f1cd5b24da45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:56.862544Z",
     "start_time": "2024-05-03T19:28:55.012122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get specs of loaded data\n",
    "reach_times = np.array(df['duration'][df['reward']])\n",
    "n_mctrials = [len(df[(df['date']==date)*df['reward']]) for date in dates]\n",
    "ntargets = len(np.unique(np.array(df['target_idx'][df['reward']])))\n",
    "unique_targets = aopy.data.bmi3d.get_target_locations(data_path_preproc, subject, df['te_id'][0], df['date'][0], np.unique(df['target_idx']))\n",
    "reach_time_thresh = np.median(np.hstack(reach_times)) + (np.median(np.hstack(reach_times))-np.min(np.hstack(reach_times)))\n",
    "good_trial_idx1 = df['duration'] <= reach_time_thresh # Labels for reach trials less than the max time (doesn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783ba6e7-e014-4468-b4cd-8453b5db9d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:57.127133Z",
     "start_time": "2024-05-03T19:28:56.864933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define 'good_trial_idx' so that all targets from all penetrations have the same number of trials\n",
    "min_trials_to_target = np.min([np.min(np.unique(np.array(df['target_idx'])[df['date']==date][good_trial_idx1[df['date']==date]], return_counts=True)[1]) for dateidx, date in enumerate(dates)])\n",
    "ngood_trials = ntargets*min_trials_to_target\n",
    "df['good_trial'] = False\n",
    "good_trial_idx = []\n",
    "for idate, date in enumerate(dates):\n",
    "    good_trial_idx_temp = []    \n",
    "    [good_trial_idx_temp.extend(np.where(np.logical_and(df['target_idx'][df['date']==date]==itarget+1, good_trial_idx1[df['date']==date]))[0][:min_trials_to_target]) for itarget in range(ntargets)]\n",
    "    good_trial_idx_mask = np.zeros(n_mctrials[idate], dtype=bool)\n",
    "    good_trial_idx_mask[good_trial_idx_temp] = True\n",
    "    # df['good_trial'][df['date']==date] = good_trial_idx_mask\n",
    "    df.loc[df['date']==date, ['good_trial']] = good_trial_idx_mask\n",
    "    # df.loc[df['te_id']==me.id, ['recording_site']] = exp_metadata['neuropixel_port1_site']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba96b3-8ac9-42c7-9a65-b548184ef461",
   "metadata": {},
   "source": [
    "## Plot behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1aa43c1-6d25-44ea-a755-0264d102c4dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:30.364336Z",
     "start_time": "2024-05-03T19:28:59.162913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All trials\n",
    "samplerate = 1000\n",
    "go_cue_idx = np.ceil((df['go_cue_time'] - df['start_time'])*samplerate).astype(int)\n",
    "trial_end_idx = np.ceil((df['reach_end_time'] - df['start_time'])*samplerate).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c786b813-feb4-4b7a-b619-b03f93aa66c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.670626Z",
     "start_time": "2024-05-03T19:29:51.486532Z"
    }
   },
   "outputs": [],
   "source": [
    "reach_time_list = [np.array(df['duration'][df['date']==date])[df['good_trial'][df['date']==date]] for date in dates]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d590d9-722a-405a-85e7-0faaa944680f",
   "metadata": {},
   "source": [
    "# Load neuropixel spiking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfa3c6c-bcb5-4138-9249-6acf36cd1a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.694477Z",
     "start_time": "2024-05-03T19:29:51.688849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ntime = np.round((tafter_mc + tbefore_mc)/spike_bin_width_mc).astype(int)\n",
    "trial_time_axis = np.arange(-tbefore_mc, tafter_mc, spike_bin_width_mc)\n",
    "ntargets = len(np.unique(df['target_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9357a98b-cb84-48c1-9f82-4587d5c9d7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:59:58.284227Z",
     "start_time": "2024-05-03T19:29:51.696732Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236e6a18a29e477fa968822c2c1d929f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate trials across sessions within a day\n",
    "# TODO: concatenatmc_entries if recorded at the same stim site but during different days\n",
    "start = time.time()\n",
    "spike_times = []\n",
    "unit_labels = []\n",
    "trial_times = []\n",
    "spike_segs = []\n",
    "spike_align = []\n",
    "spike_align_raster = []\n",
    "spike_labels = []\n",
    "spike_pos = []\n",
    "ks_labels = []\n",
    "recording_site = []\n",
    "implant_name = []\n",
    "df['recording_site'] = 0\n",
    "df['implant_name'] = ''\n",
    "\n",
    "for ime, me in enumerate(tqdm(mc_entries)):\n",
    "\n",
    "    # Load data from sessions recorded on the same day and combine \n",
    "    # Load data\n",
    "    exp_data, exp_metadata = aopy.data.load_preproc_exp_data(data_path_preproc, subject, me.id, me.date.date())\n",
    "    filename_mc = aopy.data.get_preprocessed_filename(subject, me.id, me.date.date(), 'ap'\n",
    "        \n",
    "    samplerate = exp_metadata['cursor_interp_samplerate']    \n",
    "    \n",
    "    df.loc[df['te_id']==me.id, ['recording_site']] = exp_metadata['neuropixel_port1_site']\n",
    "    df.loc[df['te_id']==me.id, ['implant_name']] = exp_metadata['neuropixel_port1_drive_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e888ac-d214-444b-9897-964c32a99eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:00:09.203197Z",
     "start_time": "2024-05-03T20:00:07.499899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get spike_seg idx for relevant events (Also will need to get idx for kinematics)\n",
    "df['delay_start_kin_idx'] = np.ceil((df['delay_start_time'] - df['start_time'])*samplerate)\n",
    "df['delay_start_neural_idx'] = np.ceil((df['delay_start_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['go_cue_kin_idx'] = np.ceil((df['go_cue_time'] - df['start_time'])*samplerate)\n",
    "df['go_cue_neural_idx'] = np.ceil((df['go_cue_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['reach_end_kin_idx'] = np.ceil((df['reach_end_time'] - df['start_time'])*samplerate)\n",
    "df['reach_end_neural_idx'] = np.ceil((df['reach_end_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['mov_onset_kin_idx'] = 0\n",
    "df['mov_onset_neural_idx'] = 0\n",
    "\n",
    "# Calculate movement onset\n",
    "for ite in np.unique(df['te_id']): # Each TE has the same target radius\n",
    "    # Must start at delay_start_time \n",
    "    traj = [temp_traj[np.array(go_cue_idx[df['te_id']==ite])[itraj]:,:] for itraj, temp_traj in enumerate(df['cursor_traj'][df['te_id']==ite])]\n",
    "    df.loc[df['te_id']==ite, ['mov_onset_kin_idx']] = np.array(get_cursor_leave_center_idx(traj, np.array(df['target_radius'][df['te_id']==ite])[0])) + np.array(go_cue_idx[df['te_id']==ite])\n",
    "    kin_neural_samplerate_ratio = samplerate/(1/spike_bin_width_mc)\n",
    "    df.loc[df['te_id']==ite, ['mov_onset_neural_idx']] = np.array(df['mov_onset_kin_idx'][df['te_id']==ite])//kin_neural_samplerate_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50826ac-c1bc-40d2-beef-329d95400719",
   "metadata": {},
   "source": [
    "# Load neuropixel spike band power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df61627b-7298-4166-bd1c-3f78fc5d565f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:04:47.923354Z",
     "start_time": "2024-05-03T20:04:47.913292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3983718/3629496738.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['recording_site'][(df['recording_site']==55)*(df['date']==dates[2])] = 56\n",
      "/tmp/ipykernel_3983718/3629496738.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['recording_site'][(df['recording_site']==55)*(df['date']==dates[4])] = 47\n"
     ]
    }
   ],
   "source": [
    "df['recording_site'][(df['recording_site']==55)*(df['date']==dates[2])] = 56\n",
    "df['recording_site'][(df['recording_site']==55)*(df['date']==dates[4])] = 47\n",
    "ks_combined_tes = {dates[0]: [9922, 9924, 9925],     # (2023, 7, 13)\n",
    "                   dates[1]: [9928, 9929],           # (2023, 7, 14)\n",
    "                   dates[2]: [9940],                 # (2023, 7, 18)\n",
    "                   dates[3]: [9958],                 # (2023, 7, 19)\n",
    "                   dates[4]: [10799, 10800, 10802],  # (2023, 8, 28)\n",
    "                   dates[5]: [10810, 10812],         # (2023, 8, 29)\n",
    "                   dates[6]: [10818, 10820],         # (2023, 8, 30)\n",
    "                   dates[7]: [10824, 10827, 10828],  # (2023, 8, 31)\n",
    "                   dates[8]: [10835],                # (2023, 9, 1)\n",
    "                   dates[9]: [12269, 12270],         # (2023, 11, 16)\n",
    "                   dates[10]: [13122],               # (2023, 12, 28)\n",
    "                   dates[11]: [13239],               # (2023, 1, 3)\n",
    "                   dates[12]: [13256],               # (2023, 1, 4)\n",
    "                   dates[13]: [14116],               # (2023, 2, 1)\n",
    "                   dates[14]: [14139, 14141]}        # (2023, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0003ea5-3e37-41a2-a0ee-74cf0afe4b3d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 2.5 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c377b3472c4962aff1529e8f25cb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ap band power data already exists from te9924\n",
      "Ap band power data already exists from te9925\n",
      "AP band power already exists for all TEs on 2023-07-13\n",
      "Ap band power data already exists from te9928\n",
      "AP band power already exists for all TEs on 2023-07-14\n",
      "Ap band power data already exists from te9940\n",
      "AP band power already exists for all TEs on 2023-07-18\n",
      "Ap band power data already exists from te9958\n",
      "AP band power already exists for all TEs on 2023-07-19\n",
      "Ap band power data already exists from te10802\n",
      "AP band power already exists for all TEs on 2023-08-28\n",
      "Ap band power data already exists from te10812\n",
      "AP band power already exists for all TEs on 2023-08-29\n",
      "Ap band power data already exists from te10820\n",
      "AP band power already exists for all TEs on 2023-08-30\n",
      "Ap band power data already exists from te10828\n",
      "AP band power already exists for all TEs on 2023-08-31\n",
      "No ap band power data found for te10835 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16613c6e6f12475a9036e7fce3788d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te10835\n",
      "Saved.\n",
      "No ap band power data found for te12269 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad3c8f8621d41a99ae4bf681f4ad3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/752 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te12269\n",
      "Saved.\n",
      "No ap band power data found for te13122 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1170022fd06642e8af6f9020100bb828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te13122\n",
      "Saved.\n",
      "No ap band power data found for te13239 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81fe2298db841b2abf73afd790488fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te13239\n",
      "Saved.\n",
      "No ap band power data found for te13256 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acebf458873b45f6b99954d45392d863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te13256\n",
      "Saved.\n",
      "No ap band power data found for te14116 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45a0e4229614a1480e7133a098946f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te14116\n",
      "Saved.\n",
      "No ap band power data found for te14139 - processing now....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364f7f4f78c04268831b6ec48606d47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ap band power data for te14139\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "dtype = 'int16'\n",
    "nch = 384\n",
    "samplerate_dwns = 10000\n",
    "bands = [(300,3000)]\n",
    "n = .01\n",
    "w = 250\n",
    "step_size = 0.005\n",
    "ks_folder_name_cutoff = date(2023, 8, 15)\n",
    "n,p,k = aopy.precondition.base.convert_taper_parameters(n,w)\n",
    "print(n,p,k)\n",
    "\n",
    "aopy.utils.release_memory_limit()\n",
    "apband_spec_segs = []\n",
    "for idate, date in enumerate(tqdm(dates[:])):\n",
    "    if date > ks_folder_name_cutoff:\n",
    "        ks_preproc_path = os.path.join(data_path_preproc, f\"kilosort/{date}_Neuropixel_ks_{subject}_site{list(df['recording_site'][df['date']==date])[0]}_bottom_port1\")\n",
    "    else:\n",
    "        ks_preproc_path = os.path.join(data_path_preproc, f\"kilosort/{date}_Neuropixel_ks_{subject}_bottom_port1\")\n",
    "    \n",
    "    # If all data is loaded from this day, go to next day\n",
    "    nte_id = np.unique(df['te_id'][df['date']==date])\n",
    "    try:\n",
    "        for ite_id, te_id_temp in enumerate(nte_id):\n",
    "            _ = aopy.data.base.pkl_read(f'ap_band_power_te{te_id_temp}', ap_band_power_save_dir)\n",
    "            # apband_spec_segs.extend(apband_spec_segs_teid)\n",
    "            print(f\"Ap band power data already exists from te{te_id_temp}\")\n",
    "\n",
    "        print(f\"AP band power already exists for all TEs on {date}\")\n",
    "    except:\n",
    "        # Get whitening matrix\n",
    "        rez_path = os.path.join(ks_preproc_path, 'kilosort_output/rez.mat')\n",
    "        with h5py.File(rez_path, 'r') as f:\n",
    "            whitening_matrix = np.array(f['rez']['Wrot'])\n",
    "\n",
    "        inv_wht_matrix = np.linalg.pinv(whitening_matrix)\n",
    "\n",
    "        # Load drift corrected and whitened apdata\n",
    "        drift_corrected_apdata_path = os.path.join(ks_preproc_path, 'temp_wh.dat')\n",
    "        data = np.memmap(drift_corrected_apdata_path, mode='r', dtype=dtype).reshape(-1,nch)\n",
    "\n",
    "        # Correct by multiplying ap data by inverse whitening matrix\n",
    "        corrected_data = data @ inv_wht_matrix\n",
    "        # corrected_data = data\n",
    "\n",
    "        \n",
    "        # Load raw apdata and check that it is the same length. If not, subselect the relevant data. This happens because data was concatenated before kilosort    \n",
    "        temp_data = []\n",
    "        if len(ks_combined_tes[date]) > 1:\n",
    "            relevant_tes = np.unique(df['te_id'][df['date']==date])\n",
    "            start_sample = 0\n",
    "            for te_id_temp in ks_combined_tes[date]:\n",
    "                data_folder_mc = f\"{date}_Neuropixel_{subject}_te{te_id_temp}\"\n",
    "                rawdata_mc, rawmetadata = aopy.data.neuropixel.load_neuropixel_data(data_path_raw, data_folder_mc, 'ap')\n",
    "                end_sample = start_sample + rawdata_mc.samples.shape[0]\n",
    "                if te_id_temp in relevant_tes:\n",
    "                    temp_data.append(corrected_data[start_sample:end_sample,:])\n",
    "                start_sample = end_sample\n",
    "\n",
    "        else:\n",
    "            temp_data = [corrected_data]   \n",
    "        del corrected_data, data # Clear up memory\n",
    "            # print(f\"WARNING: Mismatch of samples between temp_wh.dat file and raw ap data -- please check\")\n",
    "\n",
    "\n",
    "    #     # Downsample AP band data --- this needs to handle multiple TEs\n",
    "        for ite_id, te_id_temp in enumerate(nte_id):\n",
    "            try:\n",
    "                apband_spec_segs_teid = aopy.data.base.pkl_read(f'ap_band_power_te{te_id_temp}', ap_band_power_save_dir)\n",
    "                # apband_spec_segs.extend(apband_spec_segs_teid)\n",
    "                print(f\"Ap band power data already exists from te{te_id_temp}\")\n",
    "            except:\n",
    "                print(f\"No ap band power data found for te{te_id_temp} - processing now....\")\n",
    "                preproc_filename_mc = aopy.data.get_preprocessed_filename(subject, te_id_temp, date, 'lfp')\n",
    "                lfp_data_mc = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), preproc_filename_mc, 'lfp')\n",
    "                lfp_metadata_mc = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), preproc_filename_mc, 'metadata')\n",
    "                \n",
    "                data_folder_mc = f\"{date}_Neuropixel_{subject}_te{te_id_temp}\"\n",
    "                rawdata_mc, metadata_mc = aopy.data.neuropixel.load_neuropixel_data(data_path_raw, data_folder_mc, 'ap')\n",
    "                corrected_apdata_dwns = aopy.precondition.base.downsample(temp_data[ite_id], metadata_mc['sample_rate'], samplerate_dwns)\n",
    "                ap_timestamps,_ = aopy.preproc.base.interp_timestamps2timeseries(lfp_data_mc['sync_timestamp'], lfp_data_mc['sync_timestamp'], samplerate=samplerate_dwns) # upsample lfp timestamps to AP\n",
    "\n",
    "                # Trial align ap_timestamps for each TE and put into DF\n",
    "                traj_times = np.array([(hst-tbefore_mc, e[-1]+tafter_mc) for hst, e in zip(np.array(df['hold_start_time'][df['te_id']==te_id_temp]), np.array(df['event_times'][df['te_id']==te_id_temp]))])\n",
    "                ntrials_teid=traj_times.shape[0]\n",
    "                talign_times_mc_segs = []\n",
    "                talign_idx_mc_segs = []\n",
    "                apband_spec_segs_teid = []\n",
    "                for itrial in tqdm(range(ntrials_teid)):\n",
    "                    talign_times_mc, talign_idx_mc = aopy.preproc.base.trial_align_times(ap_timestamps, [traj_times[itrial,0]], 0, traj_times[itrial,1]-traj_times[itrial,0])\n",
    "                    talign_times_mc_segs.append(talign_times_mc)\n",
    "                    talign_idx_mc_segs.append(talign_idx_mc)\n",
    "                \n",
    "                    #filter\n",
    "                    t, spec_temp = aopy.analysis.base.get_bandpower_feats(corrected_apdata_dwns[talign_idx_mc[0],:], samplerate_dwns, bands=bands, log=True, ref=True, \n",
    "                                                                n=n, p=p, k=k, fk=bands[0][1], step = step_size)\n",
    "                    apband_spec_segs_teid.append(aopy.precondition.base.bin_spikes(spec_temp, int(1/step_size), spike_bin_width_mc))\n",
    "                # apband_spec_segs.extend(apband_spec_segs_teid)\n",
    "                \n",
    "                ap_band_power_metadata = {'samplerate': int(1/spike_bin_width_mc), 'frequency_band': bands, 'ch_ypos': lfp_metadata_mc['ypos'], 'ch_xpos': lfp_metadata_mc['xpos']}\n",
    "\n",
    "                if save_ap_band_power:\n",
    "                    print(f\"Saving ap band power data for te{te_id_temp}\")\n",
    "                    aopy.data.base.pkl_write(f'ap_band_power_te{te_id_temp}', (apband_spec_segs_teid, ap_band_power_metadata), ap_band_power_save_dir)\n",
    "                    print(\"Saved.\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "np_targeting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
