{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac050bf3-ff0c-4dd1-8fa1-d04f493b96a7",
   "metadata": {},
   "source": [
    "This script loads raw neuropixel spike times and prepares data for further analysis by performing the following steps:\n",
    "1. Select which task entries to analyze\n",
    "2. Load behavioral data and select good trials based on the reach time distributions.\n",
    "3. Load neuropixel spike times\n",
    "    - Bin spike times\n",
    "    - Align data to the even of interest\n",
    "    - Smooth timeseries with a Gaussian kernel\n",
    "4. Saves preprocessed data\n",
    "5. Plots basic neural data figures\n",
    "    - Trial averaged firing rate\n",
    "    - Raster plots\n",
    "    - Raster plots organized by target direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb7086-70d1-4e3b-9508-43151da8df12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.291137Z",
     "start_time": "2024-05-03T18:35:59.145410Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T20:40:36.921860Z",
     "iopub.status.busy": "2024-07-15T20:40:36.921376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aopy\n",
    "import os\n",
    "import pandas as pds\n",
    "from db import dbfunctions as db\n",
    "from ipywidgets import interactive, widgets\n",
    "import scipy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931fac6",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cb844-4915-420c-984b-581e0c9685bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.415295Z",
     "start_time": "2024-05-03T18:36:03.294173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "subject = 'affi'\n",
    "data_path_preproc = '/media/moor-data/preprocessed.new/'\n",
    "data_path_raw = '/media/moor-data/raw/neuropixels/'\n",
    "save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/np_analysis_preproc_data\"\n",
    "behavior_save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/behavior\"\n",
    "ap_band_power_save_dir = f\"/media/moor-data/postprocessed/{subject}/neuropixel_ap_band_power\"\n",
    "save_ap_band_power = True\n",
    "\n",
    "# General data parameters\n",
    "task_coords = 'yzx'\n",
    "task_perturb = None\n",
    "task_rotation = 0\n",
    "\n",
    "# Task event code definitions\n",
    "task_codes = aopy.data.bmi3d.load_bmi3d_task_codes()\n",
    "CENTER_TARGET_ON = 16\n",
    "CURSOR_ENTER_CENTER_TARGET = 80\n",
    "CURSOR_ENTER_PERIPHERAL_TARGET = list(range(81,89))\n",
    "PERIPHERAL_TARGET_ON = list(range(17,25))\n",
    "CENTER_TARGET_OFF = 32\n",
    "REWARD = 48\n",
    "DELAY_PENALTY = 66\n",
    "TIMEOUT_PENALTY = 65\n",
    "HOLD_PENALTY = 64\n",
    "PAUSE = 254\n",
    "TIME_ZERO = 238\n",
    "TRIAL_END = 239\n",
    "\n",
    "# # Select which event to align to\n",
    "# # align_event = 'TARGET ONSET'\n",
    "# # align_event = 'GO CUE'\n",
    "# align_event = 'MOVEMENT ONSET'\n",
    "# # align_event = 'ENTER TARGET'\n",
    "# END_TRIAL_CODE = REWARD\n",
    "\n",
    "\n",
    "# Trial selection parameters\n",
    "trial_filter = lambda t: CENTER_TARGET_OFF in t\n",
    "success_rate_window = 19\n",
    "reach_time_std_thresh = 3\n",
    "\n",
    "# Neuropixel data parameters\n",
    "implant_name = ['NP_Insert72', 'NP_Insert137']\n",
    "start_date = '2023-07-13'\n",
    "if subject == 'beignet':\n",
    "    end_date = '2024-02-05' # for beignet\n",
    "else:\n",
    "    end_date = date.today()\n",
    "elec_config = 'bottom'\n",
    "spike_bin_width_mc = 0.01 #[s]\n",
    "smooth_width = 150\n",
    "smooth_nstd = 3\n",
    "min_trials_to_target = 50 # If None, code will automatically update with as many trials as possible while keeping the same number of trials to each target and on each recording\n",
    "\n",
    "# Task data selection parameters\n",
    "tbefore_mc = 0.2\n",
    "tafter_mc = .8\n",
    "\n",
    "# Visualization parameters\n",
    "colors = sn.color_palette(n_colors=9)\n",
    "plt.rcParams['xtick.labelsize']=24\n",
    "plt.rcParams['ytick.labelsize']=24\n",
    "plt.rcParams['axes.labelsize']=28\n",
    "plt.rcParams['axes.spines.top']=False\n",
    "plt.rcParams['axes.spines.right']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d1899-903a-4783-9967-8f99303b68b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.428058Z",
     "start_time": "2024-05-03T18:36:03.417715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cursor_leave_center_time(data, samplerate, target_radius):\n",
    "    '''\n",
    "    Compute the time when the cursor leaves the center target radius\n",
    "    \n",
    "    Args:\n",
    "        traj (ntrials list of (nt,2)): x,y trajectory data\n",
    "        samplerate\n",
    "        target_radius (float): the radius of the center target\n",
    "        \n",
    "    Returns:\n",
    "        cursor_leave_center_time (ntrials list): the time when the cursor leaves the center target radius\n",
    "    '''\n",
    "    ntr = len(data)\n",
    "    cursor_leave_center_time = []\n",
    "    \n",
    "    for itr in range(ntr):\n",
    "        t_axis = np.arange(data[itr].shape[0])/samplerate\n",
    "        \n",
    "        dist = np.sqrt(data[itr][:,0]**2 + data[itr][:,1]**2)\n",
    "        leave_idx = np.where(dist>target_radius)[0]\n",
    "        temp = t_axis[leave_idx]\n",
    "        cursor_leave_center_time.append(temp[0])\n",
    "    \n",
    "    return cursor_leave_center_time\n",
    "\n",
    "def get_cursor_leave_center_idx(data, target_radius):\n",
    "    '''\n",
    "    Compute the time when the cursor leaves the center target radius\n",
    "    \n",
    "    Args:\n",
    "        traj (ntrials list of (nt,2)): x,y trajectory data\n",
    "        target_radius (float): the radius of the center target\n",
    "        \n",
    "    Returns:\n",
    "        cursor_leave_center_time (ntrials list): the time when the cursor leaves the center target radius. Nan if cursor doesn't leave center target.\n",
    "    '''\n",
    "    ntr = len(data)\n",
    "    cursor_leave_center_time = []\n",
    "    leave_idx = []\n",
    "    for itr in range(ntr):\n",
    "        dist = np.sqrt(data[itr][:,0]**2 + data[itr][:,1]**2)\n",
    "        \n",
    "        try:\n",
    "            temp_leave_idx = np.where(dist>target_radius)[0][0]\n",
    "        except:\n",
    "            temp_leave_idx = np.nan\n",
    "        leave_idx.append(temp_leave_idx)\n",
    "    \n",
    "    return leave_idx\n",
    "\n",
    "def smooth_timeseries_gaus(timeseries_data, samplerate, width, nstd=3, conv_mode='same'):\n",
    "    '''\n",
    "    Smooths across 2 \n",
    "    \n",
    "    Args:\n",
    "        timeseries_data (ntime, ...)\n",
    "        samplerate (int): Sample rate of timeseries\n",
    "        width (float): Width of the gaussian in time [ms] from -nstd to +nstd\n",
    "        nstd (float/int): Number of standard deviations to be used in the filter calculation.\n",
    "        conv_mode (str): Sets the size of the output. Takes eithe 'full', 'valid', or 'same'. See scipy.signal.convolve for full documentationat\n",
    "        \n",
    "    Returns: \n",
    "        smoothed_timeseries\n",
    "    '''\n",
    "    sample_std = (width/nstd)*(samplerate/(1000)) # Convert from s to ms\n",
    "    x = np.arange(-sample_std*nstd, nstd*sample_std+1)\n",
    "    gaus_filter = (1/(sample_std*np.sqrt(2*np.pi)))*np.exp(-(x**2)/(2*sample_std**2))\n",
    "    return np.apply_along_axis(scipy.signal.convolve, 0, timeseries_data, gaus_filter, mode=conv_mode, method='direct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277b839-a384-441f-b0c5-463988c44011",
   "metadata": {},
   "source": [
    "# Select relevant task entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8d520-b1f1-495a-87cb-e70b44d9a6af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.434728Z",
     "start_time": "2024-05-03T18:36:03.431380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if align_event == 'TARGET ONSET':\n",
    "#     START_TRIAL_CODE = PERIPHERAL_TARGET_ON\n",
    "#     START_TRIAL_CODE_BEHAVIOR = PERIPHERAL_TARGET_ON\n",
    "#     align_movement_onset = False\n",
    "# elif align_event == 'GO CUE':\n",
    "#     START_TRIAL_CODE = CENTER_TARGET_OFF\n",
    "#     START_TRIAL_CODE_BEHAVIOR = CENTER_TARGET_OFF\n",
    "#     align_movement_onset = False\n",
    "# elif align_event == 'MOVEMENT ONSET':\n",
    "#     START_TRIAL_CODE = CENTER_TARGET_OFF\n",
    "#     START_TRIAL_CODE_BEHAVIOR = CENTER_TARGET_OFF\n",
    "#     align_movement_onset = True\n",
    "# elif align_event == 'ENTER TARGET':\n",
    "#     START_TRIAL_CODE = CURSOR_ENTER_PERIPHERAL_TARGET\n",
    "#     START_TRIAL_CODE_BEHAVIOR = CENTER_TARGET_OFF\n",
    "#     align_movement_onset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65d569-1f01-41ad-b204-307475974f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T18:36:03.599978Z",
     "start_time": "2024-05-03T18:36:03.436723Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load neuropixel center-out task data\n",
    "# Potentially bad TEs:\n",
    "# 13272 - site 30 insert 137\n",
    "# 12290 & 12291 - site 48 insert 137 - probe only in ~2mm\n",
    "# 13102 - site 10 insert 137 - bmi3d crashed\n",
    "\n",
    "# Beignet\n",
    "if subject == 'beignet':\n",
    "    # bad_tes = [13152, 13153, 13154, 13155, 13156, 13102]\n",
    "    bad_tes = [13152, 13153, 13154, 13155, 13156, 13272, 12290, 12291, 13102, 11971] # Also remove recording at site 48 (12290 & 12291)\n",
    "    # bad_tes = [13102,13152, 13153, 13154, 13155, 13156, 13272, 9940, 9958, 10812, 10820, 12290, 12291]\n",
    "\n",
    "# Affi\n",
    "elif subject == 'affi':\n",
    "    bad_tes = [11971, 11974, 11981, 11982, 11999, 12001, 12013, 12016, 12027, 12028, 12385, 12389, 12390, 12391, 12392, 12393, 12394, 12396, 12397,\n",
    "              17294, 17296, 17297, 17299, 17301, 17302, 17303, 17304, 17305, 17316, 17318, 17319, 17547, 17552, 17558, 12365, 12000] \n",
    "mc_entries =  db.get_task_entries(subject__name=subject, task__name='manual control', date=(start_date, end_date))\n",
    "mc_entries = [me for me in mc_entries if 'neuropixel_port1_drive_type' in me.task_params and me.task_params['neuropixel_port1_drive_type'] in implant_name\n",
    "             and me.task_params['rotation']==task_coords and me.entry_name != 'flash']\n",
    "\n",
    "# Remove bad TE IDs\n",
    "mc_entries = [me for me in mc_entries if me.id not in bad_tes]\n",
    "dates = np.unique([me.date.date() for me in mc_entries])\n",
    "\n",
    "print(mc_entries, '\\n','\\n', dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887cd896-a30a-4388-b826-1e0d9d733e2c",
   "metadata": {},
   "source": [
    "# Load behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf663d9c-1fd6-4cfb-8675-bce96960c3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:55.009490Z",
     "start_time": "2024-05-03T18:36:03.604742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects = [subject for me in mc_entries]\n",
    "te_ids = [me.id for me in mc_entries]\n",
    "me_dates = [me.date.date() for me in mc_entries]\n",
    "df = aopy.data.bmi3d.tabulate_behavior_data_center_out(data_path_preproc, subjects, te_ids, me_dates, metadata=['target_radius'])\n",
    "df['reward'] = df['reward'].astype(bool)\n",
    "success_rate = aopy.analysis.calc_success_rate_trials(df['reward'], df['reach_completed'], window_size=success_rate_window)\n",
    "success_rate_date_labels = df['date']\n",
    "df = df[df['reward']].reset_index(drop=True)\n",
    "\n",
    "# Add cursor trajectories\n",
    "traj_times = np.array([(hst-tbefore_mc, e[-1]+tafter_mc) for hst, e in zip(df['hold_start_time'], df['event_times'])])\n",
    "df['cursor_traj'] = aopy.data.bmi3d.tabulate_kinematic_data(data_path_preproc, df['subject'], df['te_id'], df['date'], traj_times[:,0], traj_times[:,1], datatype='cursor')\n",
    "df['hand_traj'] = aopy.data.bmi3d.tabulate_kinematic_data(data_path_preproc, df['subject'], df['te_id'], df['date'], traj_times[:,0], traj_times[:,1], datatype='hand')\n",
    "df['start_time'] = traj_times[:,0]\n",
    "\n",
    "# Add behavior metrics\n",
    "df['duration'] = [(t[-1]-t[0])- (tbefore_mc+tafter_mc) for t in traj_times] \n",
    "cursor_traj = [np.array(t) for t in df['cursor_traj']]\n",
    "hand_traj = [np.array(t) for t in df['hand_traj']]\n",
    "df['cursor_vel_traj'] = [np.array([aopy.utils.derivative(np.arange(len(t))/1000, t[:,0]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,1])]).T for t in cursor_traj]\n",
    "df['cursor_vel'] =  [np.mean(aopy.utils.derivative(np.arange(len(t))/1000, t)) for t in cursor_traj]\n",
    "df['hand_vel_traj'] = [np.array([aopy.utils.derivative(np.arange(len(t))/1000, t[:,0]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,1]), aopy.utils.derivative(np.arange(len(t))/1000, t[:,2])]).T for t in hand_traj]\n",
    "df['hand_vel'] =  [np.mean(aopy.utils.derivative(np.arange(len(t))/1000, t)) for t in hand_traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b386e-f1a4-4cc8-b5ae-f1cd5b24da45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:56.862544Z",
     "start_time": "2024-05-03T19:28:55.012122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get specs of loaded data\n",
    "reach_times = np.array(df['duration'][df['reward']])\n",
    "n_mctrials = [len(df[(df['date']==date)*df['reward']]) for date in dates]\n",
    "ntargets = len(np.unique(np.array(df['target_idx'][df['reward']])))\n",
    "unique_targets = aopy.data.bmi3d.get_target_locations(data_path_preproc, subject, df['te_id'][0], df['date'][0], np.unique(df['target_idx']))\n",
    "reach_time_thresh = np.median(np.hstack(reach_times)) + (np.median(np.hstack(reach_times))-np.min(np.hstack(reach_times)))\n",
    "good_trial_idx1 = df['duration'] <= reach_time_thresh # Labels for reach trials less than the max time (doesn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ba6e7-e014-4468-b4cd-8453b5db9d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:57.127133Z",
     "start_time": "2024-05-03T19:28:56.864933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define 'good_trial_idx' so that all targets from all penetrations have the same number of trials\n",
    "if min_trials_to_target is None:\n",
    "    min_trials_to_target = np.min([np.min(np.unique(np.array(df['target_idx'])[df['date']==date][good_trial_idx1[df['date']==date]], return_counts=True)[1]) for dateidx, date in enumerate(dates)])\n",
    "\n",
    "ngood_trials = ntargets*min_trials_to_target\n",
    "df['good_trial'] = False\n",
    "good_trial_idx = []\n",
    "for idate, date in enumerate(dates):\n",
    "    good_trial_idx_temp = []    \n",
    "    [good_trial_idx_temp.extend(np.where(np.logical_and(df['target_idx'][df['date']==date]==itarget+1, good_trial_idx1[df['date']==date]))[0][:min_trials_to_target]) for itarget in range(ntargets)]\n",
    "    good_trial_idx_mask = np.zeros(n_mctrials[idate], dtype=bool)\n",
    "    good_trial_idx_mask[good_trial_idx_temp] = True\n",
    "    # df['good_trial'][df['date']==date] = good_trial_idx_mask\n",
    "    df.loc[df['date']==date, ['good_trial']] = good_trial_idx_mask\n",
    "    # df.loc[df['te_id']==me.id, ['recording_site']] = exp_metadata['neuropixel_port1_site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a8455-b480-4a7a-914c-0acd6c0aaeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:28:59.161247Z",
     "start_time": "2024-05-03T19:28:57.129150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3))\n",
    "ax.hist(np.hstack(reach_times), bins=2000)\n",
    "ax.set(xlim=[0, 3], xlabel='Reach Time [s]', ylabel='Trial Count')\n",
    "ax.plot([np.mean(np.hstack(reach_times)), np.mean(np.hstack(reach_times))], [0, 350], label='Mean')\n",
    "ax.plot([np.median(np.hstack(reach_times))+np.std(np.hstack(reach_times)),np.median(np.hstack(reach_times))+np.std(np.hstack(reach_times))], [0, 350],\n",
    "        color='red', label='1 sd')\n",
    "ax.plot([np.median(np.hstack(reach_times)), np.median(np.hstack(reach_times))], [0, 350], label='Median')\n",
    "ax.plot([reach_time_thresh, reach_time_thresh], [0, 350], color='darkgreen', label='Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8207a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get spike_seg idx for relevant events (Also will need to get idx for kinematics)\n",
    "samplerate=1000\n",
    "go_cue_idx = np.ceil((df['go_cue_time'] - df['start_time'])*samplerate).astype(int)\n",
    "trial_end_idx = np.ceil((df['reach_end_time'] - df['start_time'])*samplerate).astype(int)\n",
    "df['delay_start_kin_idx'] = np.ceil((df['delay_start_time'] - df['start_time'])*samplerate)\n",
    "df['delay_start_neural_idx'] = np.ceil((df['delay_start_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['go_cue_kin_idx'] = np.ceil((df['go_cue_time'] - df['start_time'])*samplerate)\n",
    "df['go_cue_neural_idx'] = np.ceil((df['go_cue_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['reach_end_kin_idx'] = np.ceil((df['reach_end_time'] - df['start_time'])*samplerate)\n",
    "df['reach_end_neural_idx'] = np.ceil((df['reach_end_time'] - df['start_time'])*(1/spike_bin_width_mc))\n",
    "df['mov_onset_kin_idx'] = 0\n",
    "df['mov_onset_neural_idx'] = 0\n",
    "\n",
    "# Calculate movement onset\n",
    "for ite in np.unique(df['te_id']): # Each TE has the same target radius\n",
    "    # Must start at delay_start_time \n",
    "    traj = [temp_traj[np.array(go_cue_idx[df['te_id']==ite])[itraj]:,:] for itraj, temp_traj in enumerate(df['cursor_traj'][df['te_id']==ite])]\n",
    "    df.loc[df['te_id']==ite, ['mov_onset_kin_idx']] = np.array(get_cursor_leave_center_idx(traj, np.array(df['target_radius'][df['te_id']==ite])[0])) + np.array(go_cue_idx[df['te_id']==ite])\n",
    "    kin_neural_samplerate_ratio = samplerate/(1/spike_bin_width_mc)\n",
    "    df.loc[df['te_id']==ite, ['mov_onset_neural_idx']] = np.array(df['mov_onset_kin_idx'][df['te_id']==ite])//kin_neural_samplerate_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba96b3-8ac9-42c7-9a65-b548184ef461",
   "metadata": {},
   "source": [
    "## Plot behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062cb94",
   "metadata": {},
   "source": [
    "### Trajectories and reach times for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa43c1-6d25-44ea-a755-0264d102c4dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:30.364336Z",
     "start_time": "2024-05-03T19:28:59.162913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All trials\n",
    "samplerate = 1000\n",
    "# go_cue_idx = np.ceil((df['go_cue_time'] - df['start_time'])*samplerate).astype(int)\n",
    "# go_cue_idx = np.array(df['mov_onset_kin_idx'])\n",
    "go_cue_idx = np.array(df['go_cue_kin_idx']).astype(int)\n",
    "trial_end_idx = np.ceil((df['reach_end_time'] - df['start_time'])*samplerate).astype(int)\n",
    "for idate, date in enumerate(dates):\n",
    "    \n",
    "    fig, ax = plt.subplot_mosaic(\"ABB;ACC\",figsize=(8,2.5))\n",
    "    labels=np.array(df['target_idx'][df['date']==date])\n",
    "    traj = [temp_traj[np.array(go_cue_idx[df['date']==date])[itraj]:np.array(trial_end_idx[df['date']==date])[itraj],:] for itraj, temp_traj in enumerate(df['cursor_traj'][df['date']==date])]\n",
    "    aopy.visualization.color_trajectories(traj, labels, colors=colors, ax=ax['A'])\n",
    "    aopy.visualization.plot_targets(unique_targets, df['target_radius'][0], ax=ax['A'])\n",
    "    ax['A'].set_title('Cursor Trajectories')\n",
    "    ax['A'].spines.right.set_visible(False)\n",
    "    ax['A'].spines.top.set_visible(False)\n",
    "    ax['A'].set(xlim=(-10, 10), ylim=(-10,10), xlabel='', ylabel='')\n",
    "\n",
    "    # Plot success rate\n",
    "    # ax['B'].plot(np.arange(success_rate_window/2, n_mctrials[idate]-(success_rate_window/2)+1), success_rate[idate])\n",
    "    ax['B'].plot(np.arange(success_rate[success_rate_date_labels==date].shape[0]), success_rate[success_rate_date_labels==date])\n",
    "    ax['B'].set(xlabel='Trials', ylabel='[rew/min]')\n",
    "    ax['B'].spines.right.set_visible(False)\n",
    "    ax['B'].spines.top.set_visible(False)\n",
    "\n",
    "    # Plot reach time\n",
    "    ax['C'].plot(np.array(df['duration'][df['date']==date]))\n",
    "    ax['C'].set(xlabel='Trials', ylabel='Reach Time [s]')\n",
    "    ax['C'].spines.right.set_visible(False)\n",
    "    ax['C'].spines.top.set_visible(False)\n",
    "    plt.suptitle(date)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # if save_figs:\n",
    "    #     aopy.visualization.savefig(full_save_dir, subject+'_mc_behavior.svg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105a446-7d6b-4186-885c-9d75f55faa51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.484788Z",
     "start_time": "2024-05-03T19:29:30.366022Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With bad trials removed from trajectories and reach times.\n",
    "# cursor_traj_clean = [[traj for itraj, traj in enumerate(df['cursor_traj'][df['date']==date]) if good_trial_idx[idate][itraj]] for idate, date in enumerate(dates)]\n",
    "for idate, date in enumerate(dates):\n",
    "    fig, ax = plt.subplot_mosaic(\"ABB\",figsize=(8,2.5))\n",
    "    labels=np.array(df['target_idx'][df['date']==date])[df['good_trial'][df['date']==date]].astype(int)\n",
    "    style = plt.cycler(color=[colors[i] for i in labels])\n",
    "    ax['A'].set_prop_cycle(style)\n",
    "    traj = [temp_traj[np.array(go_cue_idx[(df['date']==date)*df['good_trial']])[itraj]:np.array(trial_end_idx[(df['date']==date)*df['good_trial']])[itraj],:] for itraj, temp_traj in enumerate(df['cursor_traj'][(df['date']==date)*df['good_trial']])]\n",
    "    aopy.visualization.plot_trajectories(traj,  ax=ax['A'])\n",
    "    aopy.visualization.plot_targets(unique_targets, df['target_radius'][0], ax=ax['A'])\n",
    "    ax['A'].set_title('Cursor Trajectories')\n",
    "    ax['A'].spines.right.set_visible(False)\n",
    "    ax['A'].spines.top.set_visible(False)\n",
    "    ax['A'].set(xlim=(-10, 10), ylim=(-10,10), xlabel='', ylabel='')\n",
    "\n",
    "    # Plot reach time\n",
    "    ax['B'].plot(np.array(df['duration'][df['date']==date])[df['good_trial'][df['date']==date]])\n",
    "    ax['B'].set(xlabel='Trials', ylabel='Reach Time [s]')\n",
    "    ax['B'].spines.right.set_visible(False)\n",
    "    ax['B'].spines.top.set_visible(False)\n",
    "\n",
    "    plt.suptitle(date)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f91cb-b55e-44b0-8532-ca667924d9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot trajectories from multiple days overlapping\n",
    "traj_colors = ['red', 'black']\n",
    "fig, ax = plt.subplots(1,1,figsize=(4.5,4.5))\n",
    "for idate in range(2):\n",
    "    traj = [temp_traj[np.array(go_cue_idx[(df['date']==date)*df['good_trial']])[itraj]:np.array(trial_end_idx[(df['date']==date)*df['good_trial']])[itraj],:] for itraj, temp_traj in enumerate(df['cursor_traj'][(df['date']==date)*df['good_trial']])]\n",
    "    aopy.visualization.plot_trajectories(traj,  ax=ax, color=traj_colors[idate], alpha=0.25)\n",
    "\n",
    "aopy.visualization.plot_targets(unique_targets, df['target_radius'][0], ax=ax)\n",
    "ax.set(xlabel='', ylabel='', xlim=(-10,10), ylim=(-10,10), xticks=[], yticks=[])\n",
    "ax.spines[['bottom', 'left']].set_visible(False)\n",
    "for itarget in range(unique_targets.shape[0]):\n",
    "    ax.annotate(str(itarget+1), (unique_targets[itarget,0], unique_targets[itarget,1]), fontsize=24, ha='center', va='center')\n",
    "ax.set_aspect('equal')\n",
    "aopy.visualization.savefig(save_dir, '2day_traj_comp.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05b574",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786b813-feb4-4b7a-b619-b03f93aa66c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.670626Z",
     "start_time": "2024-05-03T19:29:51.486532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reach_time_list = [np.array(df['duration'][df['date']==date])[df['good_trial'][df['date']==date]] for date in dates]\n",
    "# _, pval = scipy.stats.f_oneway(reach_time_list[0], reach_time_list[1], reach_time_list[2], reach_time_list[3], reach_time_list[4])\n",
    "# print(pval)\n",
    "\n",
    "# Plot reach time histograms across recordings\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,3.5))\n",
    "aopy.visualization.plot_boxplots(reach_time_list, plt_xaxis=np.arange(len(dates)), trendline=False)\n",
    "ax.set(xlabel='Date', ylabel='Reach Time [s]', ylim=(0.8,2))\n",
    "ax.set_xticks(np.arange(len(dates)), dates, rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803224a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot correlation between recordings for reaches - also probably need to do this for hand traj in 3D\n",
    "samples_corr = 500 # ms to plot\n",
    "from sklearn.feature_selection import r_regression\n",
    "go_cue_idx = np.array(df['mov_onset_kin_idx']).astype(int)\n",
    "behavior_corr_x = np.zeros((np.sum(df['good_trial']), np.sum(df['good_trial'])))*np.nan\n",
    "behavior_corr_y = np.zeros((np.sum(df['good_trial']), np.sum(df['good_trial'])))*np.nan\n",
    "behavior_corr = np.zeros((np.sum(df['good_trial']), np.sum(df['good_trial'])))*np.nan\n",
    "trial_labels = np.array(df['target_idx'][df['good_trial']])\n",
    "traj_corr = np.array([temp_traj[np.array(go_cue_idx[df['good_trial']])[itraj]:(np.array(go_cue_idx[df['good_trial']])[itraj]+samples_corr),:] for itraj, temp_traj in enumerate(df['cursor_traj'][df['good_trial']])])\n",
    "# interp_traj_corr\n",
    "for itrial in tqdm(range(len(traj_corr))): # Look at every trial\n",
    "    temp_corrs_x = r_regression(traj_corr[:,:,0].T, traj_corr[itrial,:,0].flatten(), center=True)\n",
    "    temp_corrs_y = r_regression(traj_corr[:,:,1].T, traj_corr[itrial,:,1].flatten(), center=True)   \n",
    "    behavior_corr_x[itrial, :] = temp_corrs_x\n",
    "    behavior_corr_y[itrial, :] = temp_corrs_y\n",
    "    behavior_corr[itrial, :] = (temp_corrs_x + temp_corrs_y)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb716e50-fa04-4ed6-bf41-69720871115b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aopy.utils.release_memory_limit()\n",
    "ntargets = len(np.unique(trial_labels))\n",
    "fig, ax = plt.subplots(3, ntargets, figsize=(20,8))\n",
    "for itarget in range(ntargets):\n",
    "    ax[0,itarget].pcolor(behavior_corr[trial_labels==(itarget+1),:][:,trial_labels==(itarget+1)],vmin=0, vmax=1)\n",
    "    ax[0,itarget].set(xlabel='Trial', ylabel='Trial', title=f\"Target: {itarget}\")\n",
    "    \n",
    "    ax[1,itarget].pcolor(behavior_corr_x[trial_labels==(itarget+1),:][:,trial_labels==(itarget+1)],vmin=0, vmax=1)\n",
    "    ax[1,itarget].set(xlabel='Trial', ylabel='Trial', title=f\"X Target: {itarget}\")\n",
    "    \n",
    "    ax[2,itarget].pcolor(behavior_corr_y[trial_labels==(itarget+1),:][:,trial_labels==(itarget+1)],vmin=0, vmax=1)\n",
    "    ax[2,itarget].set(xlabel='Trial', ylabel='Trial', title=f\"Y Target: {itarget}\")\n",
    "    \n",
    "    daily_behavioral_corr = []\n",
    "    for iday, date in enumerate(dates):\n",
    "        tidx_start = iday*(ngood_trials//ntargets)\n",
    "        tidx_end = (iday+1)*(ngood_trials//ntargets)\n",
    "        daily_behavioral_corr_temp = np.triu(behavior_corr[trial_labels==(itarget+1)][:,trial_labels==(itarget+1)][tidx_start:tidx_end, tidx_start:tidx_end])\n",
    "        daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "        daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "        daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "        daily_behavioral_corr.append(daily_behavioral_corr_temp)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070674aa-5ee4-4996-911b-2bf7474be884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targ_idxs, unique_idx = np.unique(np.vstack(df['target_idx']), axis=0, return_index=True)\n",
    "ordered_targ_idx = unique_idx[np.sort(targ_idxs)-1]\n",
    "ordered_targ_loc = np.squeeze(np.vstack(df['target_location'])[ordered_targ_idx,:])\n",
    "print(ordered_targ_loc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dffce1-8ef3-4428-b025-92b8ad382cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only include axis used in the direction of the target\n",
    "# This is the trajectory correlation of all trials on the given day to each other trial in the dataset\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,3))\n",
    "daily_behavioral_corr_all = []\n",
    "for iday, date in enumerate(dates):\n",
    "    daily_behavioral_corr = []\n",
    "    for itarget in range(ntargets):\n",
    "        direction_mask = ordered_targ_loc[itarget,:] != 0\n",
    "        tidx_start = iday*(ngood_trials//ntargets)\n",
    "        tidx_end = (iday+1)*(ngood_trials//ntargets)\n",
    "        if direction_mask[0] and direction_mask[1]: # If target uses both X and Y\n",
    "            daily_behavioral_corr_temp = np.triu(behavior_corr[trial_labels==(itarget+1)][:,trial_labels==(itarget+1)][tidx_start:tidx_end, tidx_start:tidx_end])\n",
    "            daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "            daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "            daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "            daily_behavioral_corr.extend(daily_behavioral_corr_temp)\n",
    "            \n",
    "        elif direction_mask[0]: # If target only X\n",
    "            daily_behavioral_corr_temp = np.triu(behavior_corr_x[trial_labels==(itarget+1)][:,trial_labels==(itarget+1)][tidx_start:tidx_end, tidx_start:tidx_end])\n",
    "            daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "            daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "            daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "            daily_behavioral_corr.extend(daily_behavioral_corr_temp)\n",
    "            \n",
    "        elif direction_mask[1]: # If target uses only Y\n",
    "            daily_behavioral_corr_temp = np.triu(behavior_corr_y[trial_labels==(itarget+1)][:,trial_labels==(itarget+1)][tidx_start:tidx_end, tidx_start:tidx_end])\n",
    "            daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "            daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "            daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "            daily_behavioral_corr.extend(daily_behavioral_corr_temp)\n",
    "\n",
    "    daily_behavioral_corr_all.append(daily_behavioral_corr)\n",
    "# vplt = ax.violinplot(daily_behavioral_corr_all, showmeans=True, positions = np.arange(len(dates)))\n",
    "# for pc in vplt['bodies']:\n",
    "#     pc.set_facecolor=('black')\n",
    "#     pc.set_edgecolor=('black')\n",
    "bplt = ax.boxplot(daily_behavioral_corr_all, showfliers=False, positions = np.arange(len(dates)))\n",
    "ax.set_xticks(np.arange(len(dates)), dates, rotation=30)\n",
    "ax.set(xlabel='Recording Day', ylabel='Trajectory correlation', ylim=(0.5,1))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7b9ff-ac1f-47cc-819e-877ad51e7f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only include axis used in the direction of the target\n",
    "daily_behavioral_corr_mat = np.zeros((len(dates), len(dates), ntargets))*np.nan\n",
    "ntrial_per_day = behavior_corr.shape[0]//len(dates)\n",
    "behavioral_corr_trial_date_labels = [np.arange(iday*ntrial_per_day,(iday+1)*ntrial_per_day) for iday in range(len(dates))]\n",
    "\n",
    "\n",
    "for iday, date in enumerate(dates):\n",
    "    for iday2, date2 in enumerate(dates):        \n",
    "        for itarget in range(ntargets):\n",
    "            direction_mask = ordered_targ_loc[itarget,:] != 0 # Direction of the target\n",
    "            tidx_start = iday*(ngood_trials//ntargets)\n",
    "            tidx_end = (iday+1)*(ngood_trials//ntargets)\n",
    "            trial_mask = np.zeros(behavior_corr.shape[0], dtype=bool)\n",
    "            trial_mask2 = np.zeros(behavior_corr.shape[0], dtype=bool)\n",
    "            trial_mask[behavioral_corr_trial_date_labels[iday]] = trial_labels[behavioral_corr_trial_date_labels[iday]]==(itarget+1)\n",
    "            trial_mask2[behavioral_corr_trial_date_labels[iday2]] = trial_labels[behavioral_corr_trial_date_labels[iday2]]==(itarget+1)\n",
    "            \n",
    "            if direction_mask[0] and direction_mask[1]: # If target uses both X and Y\n",
    "                daily_behavioral_corr_temp = np.triu(behavior_corr[trial_mask,:][:,trial_mask2])\n",
    "                daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "                daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "                daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "\n",
    "            elif direction_mask[0]: # If target only X\n",
    "                daily_behavioral_corr_temp = np.triu(behavior_corr_x[trial_mask,:][:,trial_mask2])\n",
    "                daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "                daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "                daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "\n",
    "            elif direction_mask[1]: # If target uses only Y\n",
    "                daily_behavioral_corr_temp = np.triu(behavior_corr_y[trial_mask,:][:,trial_mask2])\n",
    "                daily_behavioral_corr_temp[daily_behavioral_corr_temp==0] = np.nan\n",
    "                daily_behavioral_corr_temp[np.diag(np.diag(daily_behavioral_corr_temp))>0] = np.nan\n",
    "                daily_behavioral_corr_temp = daily_behavioral_corr_temp.flatten()[~np.isnan(daily_behavioral_corr_temp.flatten())]\n",
    "            \n",
    "            daily_behavioral_corr_mat[iday,iday2,itarget] = np.mean(daily_behavioral_corr_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a1d3e-4971-417a-838b-d9c7fd85c284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "corr_map = ax.pcolor(np.mean(daily_behavioral_corr_mat, axis=2), vmin=0.5, vmax=1, cmap='Greys')\n",
    "cb = plt.colorbar(corr_map, label='Trajecotry Corr')\n",
    "cb.set_ticks([0.8, 1])\n",
    "# ax.set_xticks(np.arange(0, len(dates),2)+0.5, np.arange(0, len(dates),2)+1)\n",
    "# ax.set_yticks(np.arange(0, len(dates),2)+0.5, np.arange(0, len(dates),2)+1)\n",
    "ax.set_xticks(np.array([0, len(dates)-1])+0.5, np.array([1, len(dates)]))\n",
    "ax.set_yticks(np.array([0, len(dates)-1])+0.5, np.array([1, len(dates)]))\n",
    "ax.set(xlabel='Recording Day', ylabel='Recording Day')\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(False)\n",
    "fig.tight_layout()\n",
    "aopy.visualization.savefig(save_dir, subject+'_mc_behavior_traj_corr.svg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9129030-9fae-4ad1-b7bb-07dad85de8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "# cmap_plt = ax.pcolor(np.zeros((4,4)), cmap='cool')\n",
    "# cb = plt.colorbar(cmap_plt)\n",
    "# aopy.visualization.savefig(save_dir, 'colorbar.svg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99edac00-147b-46b4-8288-05777b042732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5ddfe-d795-441a-a129-ec4e96a968ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254a314-6840-41bd-98b6-8db84355eee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d590d9-722a-405a-85e7-0faaa944680f",
   "metadata": {},
   "source": [
    "# Load neuropixel spiking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c739f-0e4e-4884-808d-f9baa48bdc1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.686319Z",
     "start_time": "2024-05-03T19:29:51.676589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tabulate_neuropixel_data(preproc_dir, subjects, ids, dates, trigger_times, datatype, spike_bin_width, metadata=[], df=None):\n",
    "    '''\n",
    "    Automatically returns recording site, neuropixel implant type, \n",
    "    '''\n",
    "    if df is None:\n",
    "        df = pd.DataFrame()\n",
    "    \n",
    "    entries = list(zip(subjects, dates, ids))\n",
    "    for subject, date, te in tqdm(entries): \n",
    "    \n",
    "            # Load data\n",
    "        # exp_data, exp_metadata = aopy.data.load_preproc_exp_data(data_path_preproc, subject, me.id, me.date.date())\n",
    "        filename_mc = aopy.data.get_preprocessed_filename(subject, te, date, 'ap')\n",
    "        try:\n",
    "            if datatype == 'ap':\n",
    "                ap_data = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_mc, 'ap')\n",
    "            elif datatype == 'lfp':\n",
    "                ...\n",
    "            else:\n",
    "                print('Please enter a valid datatype (ap or lfp)')\n",
    "                return\n",
    "            ap_metadata = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_mc, 'metadata')\n",
    "\n",
    "        except:\n",
    "            print(f\"Could not load data from date: {date}, te:{te}\")\n",
    "            continue\n",
    "        \n",
    "        unit_labels\n",
    "        spike_times\n",
    "        recording_site\n",
    "        implant_name\n",
    "        spike_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa3c6c-bcb5-4138-9249-6acf36cd1a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:29:51.694477Z",
     "start_time": "2024-05-03T19:29:51.688849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ntime = np.round((tafter_mc + tbefore_mc)/spike_bin_width_mc).astype(int)\n",
    "trial_time_axis = np.arange(-tbefore_mc, tafter_mc, spike_bin_width_mc)\n",
    "ntargets = len(np.unique(df['target_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357a98b-cb84-48c1-9f82-4587d5c9d7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:59:58.284227Z",
     "start_time": "2024-05-03T19:29:51.696732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate trials across sessions within a day\n",
    "# TODO: concatenatmc_entries if recorded at the same stim site but during different days\n",
    "start = time.time()\n",
    "spike_times = []\n",
    "unit_labels = []\n",
    "trial_times = []\n",
    "spike_segs = []\n",
    "spike_align = []\n",
    "spike_align_raster = []\n",
    "spike_labels = []\n",
    "spike_pos = []\n",
    "ks_labels = []\n",
    "recording_site = []\n",
    "implant_name = []\n",
    "df['recording_site'] = 0\n",
    "df['implant_name'] = ''\n",
    "\n",
    "for ime, me in enumerate(tqdm(mc_entries)):\n",
    "\n",
    "    ########################################################\n",
    "    ### FUNCTION 1 - concatenate spike times across sessions\n",
    "    ########################################################\n",
    "\n",
    "    # Load data from sessions recorded on the same day and combine \n",
    "    # Load data\n",
    "    exp_data, exp_metadata = aopy.data.load_preproc_exp_data(data_path_preproc, subject, me.id, me.date.date())\n",
    "    filename_mc = aopy.data.get_preprocessed_filename(subject, me.id, me.date.date(), 'ap')\n",
    "    try:\n",
    "        ap_data = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_mc, 'ap')\n",
    "        ap_metadata = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_mc, 'metadata')\n",
    "\n",
    "    except:\n",
    "        print(f\"Could not load data. (TE: {me.id}, Date: {me.date.date()})\")\n",
    "        continue\n",
    "        \n",
    "    samplerate = exp_metadata['cursor_interp_samplerate']    \n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    unit_labels.append(ap_data['unique_label'])\n",
    "    spike_times.append(ap_data['unit']) # Assumes spike labels are consistent across recording sessions (works if recorded on the same day, but otherwise it does not)\n",
    "    spike_pos.append(ap_data['pos'])\n",
    "    df.loc[df['te_id']==me.id, ['recording_site']] = exp_metadata['neuropixel_port1_site']\n",
    "    df.loc[df['te_id']==me.id, ['implant_name']] = exp_metadata['neuropixel_port1_drive_type']\n",
    "    # df['recording_site'][df['te_id']==me.id] = exp_metadata['neuropixel_port1_site'] # TODO: quirry this from the db instead of metadata\n",
    "    # df['implant_name'][df['te_id']==me.id] = me.task_params['neuropixel_port1_drive_type']\n",
    "    # Fix bmi3d data entry error\n",
    "    if me.id == 10802:\n",
    "        df.loc[df['te_id']==me.id, ['recording_site']] = exp_metadata['neuropixel_port1_site']\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    spike_segs_day = {}\n",
    "    for iunit, unitid in enumerate(ap_data['unique_label']):\n",
    "        binned_spikes, time_bins = aopy.precondition.bin_spike_times(ap_data['unit'][str(unitid)], 0, np.array(df['reach_end_time'][df['te_id']==me.id])[-1]+20, spike_bin_width_mc)\n",
    "\n",
    "        # Align trial segments\n",
    "        spike_segs_day[str(unitid)] = aopy.preproc.base.get_data_segments(binned_spikes, traj_times[df['te_id']==me.id,:], 1/spike_bin_width_mc)\n",
    "        # spike_segs_day[str(unitid)] = [smooth_timeseries_gaus(data_segs[itr], 1/spike_bin_width_mc, width=smooth_width, nstd=smooth_nstd) for itr in range(len(data_segs))]\n",
    "        \n",
    "    spike_segs.append(spike_segs_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0147719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update unit labels for each trial\n",
    "unique_ids = np.unique(df['te_id'])\n",
    "unit_label_list_4df = []\n",
    "for itrial in range(len(df)):\n",
    "    trial_te_id = df['te_id'][itrial]\n",
    "    ite_id = np.where(unique_ids==trial_te_id)[0][0]\n",
    "    unit_label_list_4df.append(unit_labels[ite_id])\n",
    "df['unit_labels'] = pds.Series(unit_label_list_4df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac752c3-ddcb-4e6c-986e-94aad43809f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:59:58.658181Z",
     "start_time": "2024-05-03T19:59:58.423127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine unit labels for sessions recorded on the same day\n",
    "for idate, date in enumerate(np.unique(df['date'])):\n",
    "    # Only necessary if there are multiple TEs from the dame day\n",
    "    nsessions_day = len(np.unique(df['te_id'][df['date']==date])) \n",
    "    if nsessions_day > 1:\n",
    "        # Get times from the first session to add to.\n",
    "        sessions_today = np.unique(df['te_id'][df['date']==date])\n",
    "        baseline_times = {}\n",
    "        baseline_times['unit_labels'] = np.array(df['unit_labels'][df['te_id']==sessions_today[0]])[0]\n",
    "\n",
    "        max_time = np.array(df['reach_end_time'][df['te_id']==sessions_today[0]])[-1]\n",
    "        for isess in range(1,nsessions_day):\n",
    "            # Update unit labels\n",
    "            unit_labels_today = np.array(df['unit_labels'][df['te_id']==sessions_today[isess]])[0]\n",
    "            good_unit_label_mask = np.in1d(baseline_times['unit_labels'], unit_labels_today) # Get units from first session that are also in the second\n",
    "            baseline_times['unit_labels'] = baseline_times['unit_labels'][good_unit_label_mask] # Upate list of units to keep\n",
    "        \n",
    "        # Update unit labels in dataframe\n",
    "        for itrial in range(len(df)):\n",
    "            if df['te_id'][itrial] in sessions_today:\n",
    "                df.at[itrial, 'unit_labels'] = baseline_times['unit_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd6c40-d17c-45a9-8b0e-b320e22863d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:00:07.498147Z",
     "start_time": "2024-05-03T19:59:58.660565Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restructure dictionaries of spike segments and save in dataframe\n",
    "# Want a list each entry is a dictionary of spike segs. Each entry of the dict is a spike seg\n",
    "unique_ids = np.unique(df['te_id'])\n",
    "spike_seg_list_4df = []\n",
    "for itrial in tqdm(range(len(df))):\n",
    "    trial_te_id = df['te_id'][itrial]\n",
    "    ite_id = np.where(unique_ids==trial_te_id)[0][0]\n",
    "    idx_trial = itrial - np.min(np.where(df['te_id']==trial_te_id))\n",
    "    spike_dict = {}\n",
    "    for iunit, unitid in enumerate(list(df['unit_labels'][df['te_id']==trial_te_id])[0]): #Each TE has the same unit labels\n",
    "        spike_dict[str(unitid)] = spike_segs[ite_id][str(unitid)][idx_trial]\n",
    "    # print(spike_segs[ite_id][str(unitid)][idx_trial])\n",
    "    spike_seg_list_4df.append(spike_dict)\n",
    "    \n",
    "df['spike_segs'] = spike_seg_list_4df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc911c34-0b7d-4c6b-b850-e3ac828d6507",
   "metadata": {},
   "source": [
    "## Plot a few rasters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c19c-6a46-4070-b901-b2919ca779eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:00:09.212915Z",
     "start_time": "2024-05-03T20:00:09.205183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_raster(data, trigger_idx, tbefore, tafter, samplerate, unit_data=False, smooth=False):\n",
    "    '''\n",
    "    args:\n",
    "        data(ntrial-list of data dict): Each element of the list is a dictionary with each entry being a (nt) array of binned spikes\n",
    "        trigger_idx (ntrial):\n",
    "        tbefore (float):\n",
    "        tafter (float):\n",
    "        unit_data (bool): If data is labelled units\n",
    "        samplerate (int): neural data samplerate\n",
    "    '''\n",
    "    \n",
    "    idx_before = int(np.ceil(tbefore*samplerate))\n",
    "    idx_after = int(np.ceil(tafter*samplerate))    \n",
    "    ntrials = len(data)\n",
    "    ntime = int(idx_before+idx_after)\n",
    "    \n",
    "    if unit_data:\n",
    "        unique_unit_labels = np.sort(np.unique([list(itrial_data.keys()) for itrial_data in data]).astype(int))\n",
    "        nunits = len(unique_unit_labels)\n",
    "        raster_array = np.zeros((ntime, ntrials, nunits))*np.nan\n",
    "    else:\n",
    "        unique_unit_labels = None\n",
    "        raster_array = np.zeros((ntime, ntrials, data[0].shape[1]))*np.nan\n",
    "    \n",
    "    for itrial in range(ntrials):\n",
    "        start_idx = int(trigger_idx[itrial]-idx_before)\n",
    "        end_idx = int(trigger_idx[itrial]+idx_after)\n",
    "        raster_idx_start = int(0)\n",
    "        raster_idx_end = ntime\n",
    "        \n",
    "        if unit_data:\n",
    "            trial_len = len(data[itrial][str(unique_unit_labels[0])])\n",
    "        else:\n",
    "            trial_len = data[itrial].shape[0]\n",
    "        \n",
    "        # Contingency if start_idx < 0 or end_idx is longer than the data segment\n",
    "        if start_idx < 0:\n",
    "            print('start_idx < 0')\n",
    "            raster_idx_start = -start_idx\n",
    "            start_idx = 0\n",
    "            \n",
    "        if end_idx > trial_len:\n",
    "            print('end_idx < trial_len')\n",
    "            if unit_data:\n",
    "                trial_len = len(data[itrial][str(unique_unit_labels[itrial])])\n",
    "            else:\n",
    "                trial_len = len(data[itrial][itrial])\n",
    "            raster_idx_end = int(trial_len - trigger_idx[itrial] + idx_before)\n",
    "            end_idx = trial_len\n",
    "\n",
    "        if unit_data:\n",
    "            for iunit, unit_label in enumerate(unique_unit_labels):\n",
    "                if smooth:\n",
    "                    # [smooth_timeseries_gaus(data_segs[itr], 1/spike_bin_width_mc, width=smooth_width, nstd=smooth_nstd) for itr in range(len(data_segs))]\n",
    "                    raster_array[raster_idx_start:raster_idx_end,itrial,iunit] = smooth_timeseries_gaus(data[itrial][str(unit_label)], 1/spike_bin_width_mc, width=smooth_width, nstd=smooth_nstd)[start_idx:end_idx]\n",
    "                else:\n",
    "                    raster_array[raster_idx_start:raster_idx_end,itrial,iunit] = data[itrial][str(unit_label)][start_idx:end_idx]\n",
    "                    \n",
    "        else:\n",
    "            raster_array[raster_idx_start:raster_idx_end,itrial,:] = data[itrial][start_idx:end_idx,:]\n",
    "            \n",
    "    return raster_array, unique_unit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e7236-1473-4ba5-97f4-f5321f591922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:00:43.762926Z",
     "start_time": "2024-05-03T20:00:09.214762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create trial aligned arrays to go cue from spike segments on each day.\n",
    "rasters = {}\n",
    "rasters['neural'] = {}\n",
    "rasters['cursor_pos'] = {}\n",
    "rasters['cursor_velo'] = {}\n",
    "rasters['hand_pos'] = {}\n",
    "rasters['hand_velo'] = {}\n",
    "rasters['neural']['TARGET ONSET'] = []\n",
    "rasters['neural']['GO CUE'] = []\n",
    "rasters['neural']['MOVEMENT ONSET'] = []\n",
    "rasters['cursor_pos']['TARGET ONSET'] = []\n",
    "rasters['cursor_pos']['GO CUE'] = []\n",
    "rasters['cursor_pos']['MOVEMENT ONSET'] = []\n",
    "rasters['cursor_velo']['TARGET ONSET'] = []\n",
    "rasters['cursor_velo']['GO CUE'] = []\n",
    "rasters['cursor_velo']['MOVEMENT ONSET'] = []\n",
    "rasters['hand_pos']['TARGET ONSET'] = []\n",
    "rasters['hand_pos']['GO CUE'] = []\n",
    "rasters['hand_pos']['MOVEMENT ONSET'] = []\n",
    "rasters['hand_velo']['TARGET ONSET'] = []\n",
    "rasters['hand_velo']['GO CUE'] = []\n",
    "rasters['hand_velo']['MOVEMENT ONSET'] = []\n",
    "for idate, date in enumerate(tqdm(dates)):\n",
    "    rasters['neural']['TARGET ONSET'].append(compile_raster(list(df['spike_segs'][df['date']==date]), np.array(df['delay_start_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=True)[0])\n",
    "    rasters['neural']['GO CUE'].append(compile_raster(list(df['spike_segs'][df['date']==date]), np.array(df['go_cue_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=True)[0])\n",
    "    rasters['neural']['MOVEMENT ONSET'].append(compile_raster(list(df['spike_segs'][df['date']==date]), np.array(df['mov_onset_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=True)[0])\n",
    "    \n",
    "    rasters['cursor_pos']['TARGET ONSET'].append(compile_raster(list(df['cursor_traj'][df['date']==date]), np.array(df['delay_start_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['cursor_pos']['GO CUE'].append(compile_raster(list(df['cursor_traj'][df['date']==date]), np.array(df['go_cue_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['cursor_pos']['MOVEMENT ONSET'].append(compile_raster(list(df['cursor_traj'][df['date']==date]), np.array(df['mov_onset_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    \n",
    "    rasters['cursor_velo']['TARGET ONSET'].append(compile_raster(list(df['cursor_vel_traj'][df['date']==date]), np.array(df['delay_start_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['cursor_velo']['GO CUE'].append(compile_raster(list(df['cursor_vel_traj'][df['date']==date]), np.array(df['go_cue_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['cursor_velo']['MOVEMENT ONSET'].append(compile_raster(list(df['cursor_vel_traj'][df['date']==date]), np.array(df['mov_onset_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "\n",
    "    rasters['hand_pos']['TARGET ONSET'].append(compile_raster(list(df['hand_traj'][df['date']==date]), np.array(df['delay_start_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['hand_pos']['GO CUE'].append(compile_raster(list(df['hand_traj'][df['date']==date]), np.array(df['go_cue_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['hand_pos']['MOVEMENT ONSET'].append(compile_raster(list(df['hand_traj'][df['date']==date]), np.array(df['mov_onset_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    \n",
    "    rasters['hand_velo']['TARGET ONSET'].append(compile_raster(list(df['hand_vel_traj'][df['date']==date]), np.array(df['delay_start_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['hand_velo']['GO CUE'].append(compile_raster(list(df['hand_vel_traj'][df['date']==date]), np.array(df['go_cue_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    rasters['hand_velo']['MOVEMENT ONSET'].append(compile_raster(list(df['hand_vel_traj'][df['date']==date]), np.array(df['mov_onset_kin_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=samplerate)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89169b75-6944-4df4-a4c6-0b264158a053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:03:20.194082Z",
     "start_time": "2024-05-03T20:00:43.764903Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrasters = 5 # Rasters of how many units to plot\n",
    "for idate, date in enumerate(dates):\n",
    "    fig, ax = plt.subplots(1,nrasters, figsize=(nrasters*3,2))\n",
    "    [ax[irast].pcolor(trial_time_axis, np.arange(rasters['neural']['TARGET ONSET'][idate].shape[1]), rasters['neural']['TARGET ONSET'][idate][:,:,irast].T, cmap='gray_r') for irast in range(5)]\n",
    "    plt.suptitle(f\"{date} - Peripheral target on\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,nrasters, figsize=(nrasters*3,2))\n",
    "    [ax[irast].pcolor(trial_time_axis, np.arange(rasters['neural']['GO CUE'][idate].shape[1]), rasters['neural']['GO CUE'][idate][:,:,irast].T, cmap='gray_r') for irast in range(5)]\n",
    "    plt.suptitle(f\"{date} - Go Cue\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,nrasters, figsize=(nrasters*3,2))\n",
    "    [ax[irast].pcolor(trial_time_axis, np.arange(rasters['neural']['MOVEMENT ONSET'][idate].shape[1]), rasters['neural']['MOVEMENT ONSET'][idate][:,:,irast].T, cmap='gray_r') for irast in range(5)]\n",
    "    plt.suptitle(f\"{date} - Movement\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32377b4a-0496-4bd9-84e5-174e9c5dcf56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:03:51.956576Z",
     "start_time": "2024-05-03T20:03:20.195896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot rasters of cursor pos (Plot all trials for each date)\n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4))\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['cursor_pos']['TARGET ONSET'][idate][:,itrial,:] for itrial in range(rasters['cursor_pos']['TARGET ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4))\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['cursor_pos']['MOVEMENT ONSET'][idate][:,itrial,:] for itrial in range(rasters['cursor_pos']['MOVEMENT ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4))\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['cursor_velo']['MOVEMENT ONSET'][idate][:,itrial,:] for itrial in range(rasters['cursor_velo']['MOVEMENT ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cacfcf-5e8d-4290-b25e-9fbd3abb59b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:04:47.904936Z",
     "start_time": "2024-05-03T20:03:51.958096Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot rasters of hand pos (Plot all trials for each date)\n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4), subplot_kw={'projection':'3d'})\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['hand_pos']['TARGET ONSET'][idate][:,itrial,:] for itrial in range(rasters['hand_pos']['TARGET ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4), subplot_kw={'projection':'3d'})\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['hand_pos']['MOVEMENT ONSET'][idate][:,itrial,:] for itrial in range(rasters['hand_pos']['MOVEMENT ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(1,len(dates), figsize=(len(dates)*1.5, 4), subplot_kw={'projection':'3d'})\n",
    "for idate, date in enumerate(dates):\n",
    "    traj = [rasters['hand_velo']['MOVEMENT ONSET'][idate][:,itrial,:] for itrial in range(rasters['hand_velo']['MOVEMENT ONSET'][idate].shape[1])]\n",
    "    # print(traj.shape)\n",
    "    aopy.visualization.color_trajectories(traj, np.array(df['target_idx'][df['date']==date]), colors=colors, ax=ax[idate])\n",
    "    ax[idate].set(title=str(date))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4b450-616b-4331-a4ba-a5a1125b43eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:04:47.911750Z",
     "start_time": "2024-05-03T20:04:47.906575Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ks_preproc_path\n",
    "print( os.path.join(data_path_preproc, f\"kilosort/{date}_Neuropixel_ks_{subject}_site{list(df['recording_site'][df['date']==date])[0]}_bottom_port1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50826ac-c1bc-40d2-beef-329d95400719",
   "metadata": {},
   "source": [
    "# Load neuropixel spike band power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35f76c-e70b-4846-ab64-45ad57af8fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "if subject == 'affi':\n",
    "    df['recording_site'][(df['recording_site']==19)*(df['date']==datetime.date(2023,11,1))] = 73\n",
    "elif subject == 'beignet':\n",
    "    df['recording_site'][(df['recording_site']==55)*(df['date']==dates[2])] = 56\n",
    "    df['recording_site'][(df['recording_site']==55)*(df['date']==dates[4])] = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61627b-7298-4166-bd1c-3f78fc5d565f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T20:04:47.923354Z",
     "start_time": "2024-05-03T20:04:47.913292Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# df['recording_site'][(df['recording_site']==19)*(df['date']=='2023-11-01')] = 73\n",
    "# ks_combined_tes = {dates[0]: [9922, 9924, 9925],     # (2023, 7, 13)\n",
    "#                    dates[1]: [9928, 9929],           # (2023, 7, 14)\n",
    "#                    dates[2]: [9940],                 # (2023, 7, 18)\n",
    "#                    dates[3]: [9958],                 # (2023, 7, 19)\n",
    "#                    dates[4]: [10799, 10800, 10802],  # (2023, 8, 28)\n",
    "#                    dates[5]: [10810, 10812],         # (2023, 8, 29)\n",
    "#                    dates[6]: [10818, 10820],         # (2023, 8, 30)\n",
    "#                    dates[7]: [10824, 10827, 10828],  # (2023, 8, 31)\n",
    "#                    dates[8]: [10835],                # (2023, 9, 1)\n",
    "#                    dates[9]: [12269, 12270],         # (2023, 11, 16)\n",
    "#                    dates[10]: [13122],               # (2023, 12, 28)\n",
    "#                    dates[11]: [13239],               # (2023, 1, 3)\n",
    "#                    dates[12]: [13256],               # (2023, 1, 4)\n",
    "#                    dates[13]: [14116],               # (2023, 2, 1)\n",
    "#                    dates[14]: [14139, 14141]}        # (2023, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1f301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "dtype = 'int16'\n",
    "nch = 384\n",
    "samplerate_dwns = 10000\n",
    "bands = [(300,3000)]\n",
    "n = .01\n",
    "w = 250\n",
    "step_size = 0.005\n",
    "ks_folder_name_cutoff = date(2023, 8, 15)\n",
    "n,p,k = aopy.precondition.base.convert_taper_parameters(n,w)\n",
    "print(n,p,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc29215",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all apband saved data\n",
    "if subject == 'beignet':\n",
    "    aopy.utils.release_memory_limit()\n",
    "    apband_spec_segs = []\n",
    "    for idate, date in enumerate(tqdm(dates)):\n",
    "        nte_id = np.unique(df['te_id'][df['date']==date])\n",
    "        for ite_id, te_id_temp in enumerate(nte_id):\n",
    "                apband_spec_segs_teid = aopy.data.base.pkl_read(f'ap_band_power_te{te_id_temp}', ap_band_power_save_dir)\n",
    "                apband_spec_segs.extend(apband_spec_segs_teid)\n",
    "                print(f\"Loading ap band power from te{te_id_temp}\")\n",
    "\n",
    "    df['ap_band_power_segs'] = apband_spec_segs\n",
    "else:\n",
    "    df['ap_band_power_segs'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a434828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all LFP power saved data\n",
    "lfp_power_save_dir = f\"/media/moor-data/postprocessed/{subject}/neuropixel_lfp_power\"\n",
    "aopy.utils.release_memory_limit()\n",
    "lfp_power_segs = []\n",
    "for idate, date in enumerate(tqdm(dates)):\n",
    "    nte_id = np.unique(df['te_id'][df['date']==date])\n",
    "    for ite_id, te_id_temp in enumerate(nte_id):\n",
    "            lfp_power_segs_teid, lfp_power_metadata = aopy.data.base.pkl_read(f'lfp_power_te{te_id_temp}', lfp_power_save_dir)\n",
    "            lfp_power_segs.extend(lfp_power_segs_teid)\n",
    "            print(f\"Loading LFP power from te{te_id_temp}\")\n",
    "\n",
    "lfp_df = pds.DataFrame() # Don't save lfp power segments in DF because it'll take up too much memory\n",
    "lfp_df['lfp_power_segs'] = lfp_power_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9902b-8e91-4b62-8912-85094e937308",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.314Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile SBP rasters for future analysis\n",
    "# rasters['sbp'] = {}\n",
    "# rasters['sbp']['TARGET ONSET'], rasters['sbp']['GO CUE'], rasters['sbp']['MOVEMENT ONSET'] = [], [], []\n",
    "# for idate, date in enumerate(tqdm(dates)):\n",
    "#     rasters['sbp']['TARGET ONSET'].append(compile_raster(list(df['ap_band_power_segs'][df['date']==date]), np.array(df['delay_start_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])\n",
    "#     rasters['sbp']['GO CUE'].append(compile_raster(list(df['ap_band_power_segs'][df['date']==date]), np.array(df['go_cue_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])\n",
    "#     rasters['sbp']['MOVEMENT ONSET'].append(compile_raster(list(df['ap_band_power_segs'][df['date']==date]), np.array(df['mov_onset_neural_idx'][df['date']==date]), tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f51a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile LFP rasters for future analysis\n",
    "# nbands = len(lfp_power_metadata['frequency_band'])\n",
    "# time_offset = lfp_power_metadata['time_axis'][0][0] + 0.5/2\n",
    "# time_idx_offset = int(np.round(time_offset*lfp_power_metadata['samplerate']))\n",
    "rasters_lfp = {}\n",
    "# for iband in range(nbands):\n",
    "#     rasters_lfp[iband] = {}\n",
    "#     rasters_lfp[iband]['TARGET ONSET'], rasters_lfp[iband]['GO CUE'], rasters_lfp[iband]['MOVEMENT ONSET'] = [], [], []\n",
    "#     for idate, date in enumerate(tqdm(dates)):\n",
    "#         band_specific_power = [list(lfp_df['lfp_power_segs'][df['date']==date])[itr][iband,:,:] for itr in range(len(list(lfp_df['lfp_power_segs'][df['date']==date])))]\n",
    "#         rasters_lfp[iband]['TARGET ONSET'].append(compile_raster(band_specific_power, np.array(df['delay_start_neural_idx'][df['date']==date])-time_idx_offset, tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])\n",
    "#         rasters_lfp[iband]['GO CUE'].append(compile_raster(band_specific_power, np.array(df['go_cue_neural_idx'][df['date']==date])-time_idx_offset, tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])\n",
    "#         rasters_lfp[iband]['MOVEMENT ONSET'].append(compile_raster(band_specific_power, np.array(df['mov_onset_neural_idx'][df['date']==date])-time_idx_offset, tbefore=tbefore_mc, tafter=tafter_mc, samplerate=(1/spike_bin_width_mc), unit_data=False)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26538a-44d7-4541-98d9-0d8a3d208892",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ba19c-6c89-4fae-a6df-50aeaaf054f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # TODO replace this by querying database instead\n",
    "# if recording_site[2] == 55 and recording_site[4] == 55:\n",
    "#     recording_site[4] = 47\n",
    "#     recording_site[2] = 56\n",
    "    \n",
    "# TODO replace this by querying database instead\n",
    "recording_sites = np.array([np.array(df['recording_site'][df['date']==date])[0] for date in dates])\n",
    "implant = np.array([np.array(df['implant_name'][df['date']==date])[0] for date in dates])\n",
    "print(dates)\n",
    "print(recording_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fecc80-c952-4cea-a7f3-70055c0c7de9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing_metadata = {}\n",
    "preprocessing_metadata['spike_bin_width'] = spike_bin_width_mc\n",
    "preprocessing_metadata['tbefore'] = tbefore_mc\n",
    "preprocessing_metadata['tafter'] = tafter_mc\n",
    "preprocessing_metadata['trial_time_axis'] = trial_time_axis\n",
    "preprocessing_metadata['nrecs'] = len(dates)\n",
    "preprocessing_metadata['recording_sites'] = recording_sites\n",
    "preprocessing_metadata['implant'] = implant\n",
    "preprocessing_metadata['neural_samplerate'] = int(1/spike_bin_width_mc)\n",
    "preprocessing_metadata['kin_samplerate'] = samplerate\n",
    "if subject == 'beignet':\n",
    "    preprocessing_metadata['ch_xpos'] = lfp_power_metadata['ch_xpos']\n",
    "    preprocessing_metadata['ch_ypos'] = lfp_power_metadata['ch_ypos']\n",
    "    preprocessing_metadata['lfp_bands'] = lfp_power_metadata['frequency_band']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fa130-80af-4a23-bc7e-99ebc8d8cb4b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "aopy.data.base.pkl_write(f\"{subject}_np_preprocessed\", (df, rasters, preprocessing_metadata), save_dir)\n",
    "aopy.data.base.pkl_write(f\"{subject}_np_preprocessed_lfp\", (df, rasters_lfp, preprocessing_metadata), save_dir)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5626c-0f6e-4b00-843b-11aa5f6b3829",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T18:35:59.326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test1, test2, test3 = aopy.data.base.pkl_read(f\"{subject}_np_preprocessed\", save_dir)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8202b-4522-47c6-b3f1-5591739db9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:np_targeting]",
   "language": "python",
   "name": "conda-env-np_targeting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
