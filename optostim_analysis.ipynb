{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4026da-4e56-4c7a-ae69-18f2e0d29925",
   "metadata": {
    "tags": []
   },
   "source": [
    "This script analyzes optostim neuropixel data and looks for significant responses during stimulation compared to baseline.\n",
    "\n",
    "1. Loads relevant data\n",
    "    - Preprocessed data from server\n",
    "    - ECoG latency by stim site\n",
    "2. Calculates significant responses\n",
    "    - two-tailed t-test between FR during stim vs. before\n",
    "3. Plots PSTH and rasters for significantly modulated units\n",
    "4. Finds and plots waveforms of responsive units\n",
    "5. Plots the LFP response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dda4569-b3fd-4c34-ae7c-f3fd225d5fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T07:57:31.797479Z",
     "iopub.status.busy": "2023-11-18T07:57:31.797155Z",
     "iopub.status.idle": "2023-11-18T07:57:35.169651Z",
     "shell.execute_reply": "2023-11-18T07:57:35.168889Z",
     "shell.execute_reply.started": "2023-11-18T07:57:31.797450Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aopy\n",
    "import os\n",
    "import pandas as pd\n",
    "from db import dbfunctions as db\n",
    "from ipywidgets import interactive, widgets\n",
    "import scipy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from itertools import compress\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import math\n",
    "from scipy.fft import fft\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bfd627-f390-417a-8a3b-75508fabf988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T07:57:35.862116Z",
     "iopub.status.busy": "2023-11-18T07:57:35.861453Z",
     "iopub.status.idle": "2023-11-18T07:57:35.869440Z",
     "shell.execute_reply": "2023-11-18T07:57:35.868790Z",
     "shell.execute_reply.started": "2023-11-18T07:57:35.862086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "ecog_signal_path = \"/home/aolab/gdrive/Lab equipment/electrophysiology/210910_ecog_signal_path.xlsx\"\n",
    "elec_to_pos = \"/home/aolab/gdrive/Lab equipment/electrophysiology/our signal path definitions/244ch_viventi_ecog_elec_to_pos.xlsx\"\n",
    "data_path_preproc = '/media/moor-data/preprocessed.new/'\n",
    "data_path_raw = '/media/moor-data/raw/'\n",
    "# save_dir = \"/home/aolab/gdrive/People/RyanCanfield/Results/beignet_analysis/optostim_population_dynamics\"\n",
    "\n",
    "# General data parameters\n",
    "subject = 'beignet'\n",
    "task_coords = 'yzx'\n",
    "task_perturb = None\n",
    "task_rotation = 0\n",
    "\n",
    "# Neuropixel data parameters\n",
    "implant_name = ['NP_Insert72', 'NP_Insert137']\n",
    "start_date = '2023-07-13'\n",
    "end_date = date.today()\n",
    "elec_config = 'bottom'\n",
    "spike_bin_width_mc = 0.005 #[s]\n",
    "\n",
    "# Alignment parameters\n",
    "tbefore = 0.25\n",
    "tafter = 0.25\n",
    "min_trial_prop = 0.75\n",
    "min_fr = 2\n",
    "\n",
    "# Visualization parameters\n",
    "colors = sn.color_palette(n_colors=9)\n",
    "recording_brain_areas={'M1': [30, 55, 47, 40], 'PM':[11, 9, 18]}\n",
    "day_colors=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667e5729-a8a3-4805-8952-9d6ac5bebacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T07:57:36.778430Z",
     "iopub.status.busy": "2023-11-18T07:57:36.777824Z",
     "iopub.status.idle": "2023-11-18T07:57:36.796502Z",
     "shell.execute_reply": "2023-11-18T07:57:36.795754Z",
     "shell.execute_reply.started": "2023-11-18T07:57:36.778405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_autocorr_func(data, lags=None):\n",
    "    '''\n",
    "    Args:\n",
    "        data (ntime, ...):\n",
    "        lags (nlag): Indicies of lags to analyze. If None, compute autocorrelation at each possible lag.\n",
    "    '''\n",
    "    \n",
    "    ntime = data.shape[0]\n",
    "    if lags is None:\n",
    "        lags = np.arange(-ntime+1, ntime-1)\n",
    "    nlags = len(lags)\n",
    "    \n",
    "    autocorr_func = np.zeros(nlags)*np.nan\n",
    "    for ilag, lag in enumerate(lags):\n",
    "        # print(data.shape, np.roll(data,lag,axis=0).shape)\n",
    "        # autocorr_func.append(np.apply_along_axis(np.correlate, 0, data, np.roll(data,lag,axis=0)))\n",
    "        # print(data.shape, np.roll(data,lag,axis=0).shape)\n",
    "        autocorr_func[ilag] = np.correlate(data, np.roll(data,lag,axis=0))\n",
    "    return autocorr_func, lags\n",
    "\n",
    "def load_parsed_ksdata(kilosort_dir, data_dir):\n",
    "    '''\n",
    "    load kilosort data (spike indices, clusters, and label) parsed into the task entries\n",
    "    This data is not still synchronized\n",
    "    \n",
    "    Args:\n",
    "        kilosort_dir (str): kilosort directory (ex. '/data/preprocessed/kilosort')\n",
    "        data_dir (str): data directory that contains parsed data (ex. '2023-06-30_Neuropixel_ks_affi_bottom_port1_9847')\n",
    "        \n",
    "    Returns:\n",
    "        spike_indices (nspikes): spike indices detected by kilosort (not spike times)\n",
    "        spike_clusters (nspikes): unit label detected  by kilsort\n",
    "    '''\n",
    "    \n",
    "    # Path for loading spikes and clusters\n",
    "    data_path = os.path.join(kilosort_dir, data_dir)\n",
    "    spike_path = os.path.join(data_path,'spike_indices_entry.npy')\n",
    "    cluster_path = os.path.join(data_path,'spike_clusters_entry.npy')\n",
    "    label_path = os.path.join(data_path,'ks_label.npy')\n",
    "\n",
    "    # Load spikes and clusters\n",
    "    spike_indices = np.load(spike_path)\n",
    "    spike_clusters = np.load(cluster_path)\n",
    "    ks_label = np.load(label_path)\n",
    "    \n",
    "    return spike_indices, spike_clusters, ks_label\n",
    "\n",
    "def classify_ks_unit(spike_times, spike_label):\n",
    "    '''\n",
    "    Classify unit activity identified by kilosort into each single unit\n",
    "    \n",
    "    Args:\n",
    "        spike_times (nspikes): spike times generated by kilosort\n",
    "        spike_label (nspikes): cluster labels of each spike generated by kilosort\n",
    "        \n",
    "    Returns:\n",
    "        spike_times_unit (dict): spike times for each unit\n",
    "    '''\n",
    "    \n",
    "    spike_times_unit = {}\n",
    "    \n",
    "    for unit_label in np.unique(spike_label):\n",
    "        spike_times_unit[f'{unit_label}'] = spike_times[spike_label==unit_label.astype(int)]\n",
    "    \n",
    "    return spike_times_unit\n",
    "\n",
    "def calc_ks_waveforms(raw_data, sample_rate, spike_times_unit, templates, channel_pos, waveforms_nch=10, time_before=1000., time_after=1000.):\n",
    "    '''\n",
    "    Calculate waveforms, waveform channels, and positions of units, using templates from kilosort\n",
    "    \n",
    "    args:\n",
    "        raw_data (nt,nch): time series neural data to detect spikes and extract waveforms from.\n",
    "        sample_rate (float): sampling rate (Hz)\n",
    "        spike_times_unit (dict): spike times for each unit identified by kilosort\n",
    "        templates (n_unit, n_points, nch): templates that kilosort used to detect spikes\n",
    "        channel_pos (nch, 2): channel positions\n",
    "        waveforms_nch (int, optional): the number of channels with large amplitude of templates\n",
    "        time_before (float, optional): time [us] to include before the start of each trial\n",
    "        time_after (float, optional): time [us] to include after the start of each trial\n",
    "    \n",
    "    returns\n",
    "        tuple: tuple containing:\n",
    "            | **unit_waveforms (dict):** waveforms for each unit. The shape is (nspikes,  m_points, waveforms_nch)\n",
    "            | **unit_waveforms_ch (n_unit, waveforms_nch):** large amplitude channels in templates\n",
    "            | **unit_pos (dict):** channel positions of each unit\n",
    "    '''\n",
    "    \n",
    "    time_before *= 1e-6\n",
    "    time_after *= 1e-6\n",
    "    nch = channel_pos.shape[0]\n",
    "    duration = int((time_before + time_after)*sample_rate)\n",
    "    \n",
    "    unit_waveforms_ch = {}\n",
    "    unit_waveforms = {}\n",
    "    unit_pos = {}\n",
    "\n",
    "    for iunit, unit in enumerate(spike_times_unit.keys()):\n",
    "        # Look at high amplitude channels in templates\n",
    "        amp_template_ch = np.zeros(nch)\n",
    "        for ich in range(nch):\n",
    "            amp_template_ch[ich] = np.max(templates[int(unit),:,ich])-np.min(templates[int(unit),:,ich]) # don't use iunit instead of int(unit)\n",
    "\n",
    "        # Sort high amplitude channels and save channels and their positions\n",
    "        large_amp_ch = np.argsort(amp_template_ch)[::-1][:waveforms_nch]\n",
    "        unit_waveforms_ch[f'{unit}'] = large_amp_ch\n",
    "        unit_pos[f'{unit}'] = channel_pos[large_amp_ch[0],:]\n",
    "\n",
    "        # Get waveforms in high amplitude channels for each spike\n",
    "        unit_times = spike_times_unit[f'{unit}']\n",
    "        waveforms = np.zeros((unit_times.shape[0],duration,waveforms_nch))*np.nan\n",
    "        for ispike, unit_time in enumerate(unit_times):\n",
    "            start = int((unit_time - time_before)*sample_rate)\n",
    "            end = start + duration\n",
    "\n",
    "            if np.logical_and(end < raw_data.shape[0], start >= 0): # Ensure there are enough data points to grab the waveform\n",
    "                for ich, ch in enumerate(large_amp_ch):\n",
    "                    waveforms[ispike,:,ich] = raw_data[start:end,ch]\n",
    "                    \n",
    "        unit_waveforms[f'{unit}'] = waveforms\n",
    "    \n",
    "    return unit_waveforms, unit_waveforms_ch, unit_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ed3cf7-c9a8-4f83-9207-c53d8af77699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T07:57:37.243465Z",
     "iopub.status.busy": "2023-11-18T07:57:37.242798Z",
     "iopub.status.idle": "2023-11-18T07:57:37.393849Z",
     "shell.execute_reply": "2023-11-18T07:57:37.393057Z",
     "shell.execute_reply.started": "2023-11-18T07:57:37.243439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-28 13:49:56.350383: beignet on laser only task, id=10798, 2023-08-28 13:51:04.406791: beignet on laser only task, id=10799, 2023-08-28 14:56:47.537136: beignet on laser only task, id=10803, 2023-08-28 15:02:15.970548: beignet on laser only task, id=10804, 2023-08-28 15:09:03.965473: beignet on laser only task, id=10805, 2023-08-28 15:14:22.097289: beignet on laser only task, id=10806, 2023-08-29 14:56:56.049109: beignet on laser only task, id=10810, 2023-08-29 16:25:27.846484: beignet on laser only task, id=10813, 2023-08-29 16:43:03.703551: beignet on laser only task, id=10814, 2023-08-30 11:35:11.143187: beignet on laser only task, id=10818, 2023-08-30 13:08:16.278506: beignet on laser only task, id=10821, 2023-08-30 13:26:00.981570: beignet on laser only task, id=10822, 2023-08-30 13:44:10.289583: beignet on laser only task, id=10823, 2023-08-31 12:55:53.587739: beignet on laser only task, id=10826, 2023-08-31 12:57:02.026928: beignet on laser only task, id=10827, 2023-08-31 14:30:05.368585: beignet on laser only task, id=10829, 2023-08-31 14:54:44.260855: beignet on laser only task, id=10830, 2023-11-16 13:57:42.988804: beignet on laser only task, id=12270, 2023-11-16 14:45:37.157039: beignet on laser only task, id=12271]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Load neuropixel center-out task data\n",
    "opto_entries =  db.get_task_entries(subject__name=subject, task__name='laser only', date=(start_date, end_date))\n",
    "opto_entries = [me for me in opto_entries if 'neuropixel_port1_drive_type' in me.task_params and me.task_params['neuropixel_port1_drive_type'] in implant_name\n",
    "                and me.entry_name != 'flash']\n",
    "print(opto_entries)\n",
    "print(len(opto_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da38e9f-9aed-42fb-beeb-35ecf6e9be26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T07:57:43.523264Z",
     "iopub.status.busy": "2023-11-18T07:57:43.522748Z",
     "iopub.status.idle": "2023-11-18T07:57:43.528003Z",
     "shell.execute_reply": "2023-11-18T07:57:43.527290Z",
     "shell.execute_reply.started": "2023-11-18T07:57:43.523235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_axis = np.linspace(-tbefore, tafter, int((tafter+tbefore)/spike_bin_width_mc))\n",
    "ntime = len(time_axis)\n",
    "# ntime = int((tafter + tbefore)//spike_bin_width_mc)+1\n",
    "trial_time_axis = np.arange(-tbefore, tafter, spike_bin_width_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68fbc2ab-eab9-4aeb-8acf-451b4d51f4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T08:02:52.839015Z",
     "iopub.status.busy": "2023-11-18T08:02:52.838230Z",
     "iopub.status.idle": "2023-11-18T08:38:43.270285Z",
     "shell.execute_reply": "2023-11-18T08:38:43.268858Z",
     "shell.execute_reply.started": "2023-11-18T08:02:52.838987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d75b7722e749029e3ddccf7d7f00e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3183088/1256329655.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  autocorr_func[ilag] = np.correlate(data, np.roll(data,lag,axis=0))\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "spike_times = []\n",
    "unit_labels = []\n",
    "laser_times = []\n",
    "laser_widths = []\n",
    "spike_segs = []\n",
    "spike_align = []\n",
    "spike_labels = []\n",
    "recording_site = []\n",
    "stim_site = []\n",
    "good_opto_entries = []\n",
    "autocorr_func = []\n",
    "for ioe, oe in enumerate(tqdm(opto_entries)):\n",
    "\n",
    "    ########################################################\n",
    "    ### Load spike times across days\n",
    "    ########################################################\n",
    "    session_number = 0\n",
    " \n",
    "    # Load data\n",
    "    exp_data, exp_metadata = aopy.data.load_preproc_exp_data(data_path_preproc, subject, oe.id, oe.date.date())\n",
    "    filename_opto = aopy.data.get_preprocessed_filename(subject, oe.id, oe.date.date(), 'ap')\n",
    "    try:\n",
    "        ap_data = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_opto, 'ap')\n",
    "        ap_metadata = aopy.data.load_hdf_group(os.path.join(data_path_preproc, subject), filename_opto, 'metadata')\n",
    "        laser_info = aopy.preproc.bmi3d.get_laser_trial_times(data_path_preproc, subject, oe.id, oe.date.date())\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    ########################################################\n",
    "    unit_labels.append(ap_data['unique_label'])\n",
    "    spike_times.append(ap_data['unit']) # Assumes spike labels are consistent across recording sessions (works if recorded on the same day, but otherwise it does not)\n",
    "    laser_times.append(laser_info[0])\n",
    "    laser_widths.append(laser_info[1])\n",
    "    stim_site.append(exp_metadata['stimulation_site'])\n",
    "    recording_site.append(exp_metadata['neuropixel_port1_site'])\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    spike_segs_day = {}\n",
    "    spike_align_day = np.zeros((ntime, len(laser_info[0]), len(ap_data['unique_label']))) # (ntime, ntrials, nunits)\n",
    "    autocorr_func_day = []\n",
    "    for iunit, unitid in enumerate(ap_data['unique_label']):\n",
    "        binned_spikes, time_bins = aopy.precondition.bin_spike_times(ap_data['unit'][str(unitid)], 0, laser_info[0][-1]+10, spike_bin_width_mc)\n",
    "        autocorr_func_day.append(calc_autocorr_func(ap_data['unit'][str(unitid)], lags=None)[0])\n",
    "        \n",
    "        # Trial align \n",
    "        spike_align_day[:,:,iunit] = aopy.preproc.trial_align_data(binned_spikes, laser_info[0], tbefore, tafter, 1/spike_bin_width_mc)[:,0,:]\n",
    "\n",
    "\n",
    "    spike_segs.append(spike_segs_day)\n",
    "    spike_align.append(spike_align_day)\n",
    "    good_opto_entries.append(oe)\n",
    "    autocorr_func.append(autocorr_func_day)\n",
    "    # print(100*ioe/len(opto_entries), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc1fad-cd10-48a6-8af3-5d8a1c192d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which units are stable by being active on a high proportion of trials and above a low minimum FR\n",
    "\n",
    "stable_unit_lbl = []\n",
    "stable_unit_mask = []\n",
    "stable_unit_idx = []\n",
    "target_idx_good = []\n",
    "target_idx_ordered_mask = []\n",
    "# Get stable unit idx and labels\n",
    "for ie, entry in enumerate(good_opto_entries):\n",
    "    min_trials = len(laser_times[ie])*min_trial_prop\n",
    "    stable_unit_lbl.append(unit_labels[ie][np.where(np.logical_and(np.sum(np.max(spike_align[ie]>0, axis=0), axis=0)>min_trials, np.mean(spike_align[ie], axis=(0,1))>min_fr))[0]])\n",
    "    stable_unit_mask.append(np.logical_and(np.sum(np.max(spike_align[ie]>0, axis=0), axis=0)>min_trials, np.mean(spike_align[ie], axis=(0,1))>min_fr))\n",
    "    stable_unit_idx.append(np.where(stable_unit_mask[ie])[0])\n",
    "nstable_unit_idx = [len(stable_unit_idx[id]) for id in range(len(good_opto_entries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99e1b9-e65b-47c8-b5b6-135bb8e18214",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 2\n",
    "# Calculate significance of response\n",
    "laser_start_idx = [(np.zeros(len(laser_times[ioe]))+np.where(trial_time_axis>=0)[0][0]).astype(int)+offset for ioe in range(len(good_opto_entries))]\n",
    "laser_stop_idx = [laser_start_idx[ioe]+np.round(laser_widths[ioe]/spike_bin_width_mc).astype(int)-(2*offset) for ioe in range(len(good_opto_entries))]\n",
    "baseline_start_idx = [(np.zeros(len(laser_times[ioe]))+np.where(trial_time_axis>=0)[0][0]).astype(int)-(laser_stop_idx[ioe]-laser_start_idx[ioe])-offset for ioe in range(len(good_opto_entries))]\n",
    "baseline_stop_idx = [(np.zeros(len(laser_times[ioe]))+np.where(trial_time_axis>=0)[0][0]).astype(int)-offset for ioe in range(len(good_opto_entries))]\n",
    "\n",
    "unit_resp_sig = []\n",
    "for ioe in range(len(good_opto_entries)):\n",
    "    print(ioe)\n",
    "    temp_unit_sig = np.zeros(nstable_unit_idx[ioe])*np.nan\n",
    "    for iunit, unit_lbl in enumerate(stable_unit_idx[ioe]):\n",
    "        null_points = []\n",
    "        alt_points = []\n",
    "        [null_points.extend(spike_align[ioe][baseline_start_idx[ioe][itrial]:baseline_stop_idx[ioe][itrial],itrial,unit_lbl]) for itrial in range(len(laser_times[ioe]))]\n",
    "        [alt_points.extend(spike_align[ioe][laser_start_idx[ioe][itrial]:laser_stop_idx[ioe][itrial],itrial,unit_lbl]) for itrial in range(len(laser_times[ioe]))]\n",
    "        _, temp_unit_sig[iunit] = scipy.stats.ttest_ind(np.array(null_points), np.array(alt_points))\n",
    "    \n",
    "    unit_resp_sig.append(temp_unit_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073588b-050f-4d10-847d-f4d15caa6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control for multiple comparisons using false discovery rate\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "resp_unit_idx = [stable_unit_idx[ioe][fdrcorrection(unit_resp_sig[ioe])[0]] for ioe in range(len(good_opto_entries))]\n",
    "nresp_unit = [len(resp_unit_idx[ioe]) for ioe in range(len(good_opto_entries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172b382-2062-4a58-8c0d-649f177d1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ioe in range(len(good_opto_entries)):\n",
    "# Plot rasters aligned to go cue organized by trial\n",
    "    ncol = 7\n",
    "    nrow = (len(resp_unit_idx[ioe])//ncol)+1\n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(27, nrow*3))\n",
    "    for iplot, iunit in enumerate(resp_unit_idx[ioe]):\n",
    "        irow = iplot//ncol\n",
    "        icol = iplot % ncol\n",
    "        \n",
    "        try:\n",
    "            # unit2plot = np.where(unit_labels[idate]==[iunit])[0][0]\n",
    "            ax[irow, icol].plot(time_axis, np.mean(spike_align[ioe][:,:,iunit], axis=1))\n",
    "            ax[irow, icol].plot([time_axis[int(np.median(laser_start_idx[ioe]))], time_axis[int(np.median(laser_start_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[irow, icol].plot([time_axis[int(np.median(laser_stop_idx[ioe]))], time_axis[int(np.median(laser_stop_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[irow, icol].plot([time_axis[int(np.median(baseline_start_idx[ioe]))], time_axis[int(np.median(baseline_start_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'g--', linewidth=2)\n",
    "            ax[irow, icol].plot([time_axis[int(np.median(baseline_stop_idx[ioe]))], time_axis[int(np.median(baseline_stop_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'g--', linewidth=2)\n",
    "            # ax[irow, icol].plot([0,0], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            # ax[irow, icol].plot([np.median(laser_widths[ioe]),np.median(laser_widths[ioe])], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[irow, icol].set(xlabel='Time [s]', ylabel='Firing Rate', title=f'Rec {recording_site[ioe]} - Unit {iunit}')\n",
    "        except:\n",
    "            ax[icol].plot(time_axis, np.mean(spike_align[ioe][:,:,iunit], axis=1))\n",
    "            ax[icol].plot([time_axis[int(np.median(laser_start_idx[ioe]))], time_axis[int(np.median(laser_start_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[icol].plot([time_axis[int(np.median(laser_stop_idx[ioe]))], time_axis[int(np.median(laser_stop_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[icol].plot([time_axis[int(np.median(baseline_start_idx[ioe]))], time_axis[int(np.median(baseline_start_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'g--', linewidth=2)\n",
    "            ax[icol].plot([time_axis[int(np.median(baseline_stop_idx[ioe]))], time_axis[int(np.median(baseline_stop_idx[ioe]))]], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'g--', linewidth=2)\n",
    "            # ax[icol].plot([0,0], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            # ax[icol].plot([np.median(laser_widths[ioe]),np.median(laser_widths[ioe])], [0,np.max(np.mean(spike_align[ioe][:,:,iunit], axis=1))], 'r--', linewidth=2)\n",
    "            ax[icol].set(xlabel='Time [s]', ylabel='Firing Rate', title=f'Rec {recording_site[ioe]} - Unit {iunit}')\n",
    "            \n",
    "    plt.suptitle(f'Recording: {ioe} - Site: {recording_site[ioe]}')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca910b07-e400-4523-95c2-c172ada67bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:np_targeting]",
   "language": "python",
   "name": "conda-env-np_targeting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
