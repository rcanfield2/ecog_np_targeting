{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbacf75-e95d-4af4-b6fa-2a873142d9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.752952Z",
     "start_time": "2024-05-03T16:03:26.064649Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:19.290911Z",
     "iopub.status.busy": "2024-07-26T21:44:19.290450Z",
     "iopub.status.idle": "2024-07-26T21:44:22.052475Z",
     "shell.execute_reply": "2024-07-26T21:44:22.051248Z",
     "shell.execute_reply.started": "2024-07-26T21:44:19.290859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aopy\n",
    "import os\n",
    "import pandas as pds\n",
    "from db import dbfunctions as db\n",
    "from ipywidgets import interactive, widgets\n",
    "import scipy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from itertools import compress\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import math\n",
    "import seaborn as sn\n",
    "from scipy.fft import fft\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c230f6b9-f69f-42bf-9e1e-5c663f4106bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.054009Z",
     "iopub.status.busy": "2024-07-26T21:44:22.053760Z",
     "iopub.status.idle": "2024-07-26T21:44:22.060729Z",
     "shell.execute_reply": "2024-07-26T21:44:22.059996Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.053994Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aopy.utils.get_memory_available_gb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28467525-3231-4f82-bbde-4dc92226ba60",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e750728-644f-4d1f-8809-47dddee54df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.758207Z",
     "start_time": "2024-05-03T16:03:36.755383Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.061472Z",
     "iopub.status.busy": "2024-07-26T21:44:22.061334Z",
     "iopub.status.idle": "2024-07-26T21:44:22.065044Z",
     "shell.execute_reply": "2024-07-26T21:44:22.064316Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.061459Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "base_save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/\"\n",
    "np_preproc_data_folder = 'np_analysis_preproc_data'\n",
    "ecog_dec_acc_file_name = 'ecog_decoding_maps/npinsert_ecog_decoding_all'\n",
    "\n",
    "subject = 'beignet'\n",
    "align_events = ['TARGET ONSET', 'GO CUE', 'MOVEMENT ONSET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e822435-d292-4428-8ac6-aa5ac8aaec1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.763714Z",
     "start_time": "2024-05-03T16:03:36.760090Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.065666Z",
     "iopub.status.busy": "2024-07-26T21:44:22.065541Z",
     "iopub.status.idle": "2024-07-26T21:44:22.071082Z",
     "shell.execute_reply": "2024-07-26T21:44:22.070271Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.065654Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoding calculation parameters\n",
    "tbefore = 0.5\n",
    "tafter = 1\n",
    "nlda_lags = 1\n",
    "niter_match = 50\n",
    "min_trial_prop = .85\n",
    "ntrial_bin_size = 96\n",
    "nfolds = 4\n",
    "\n",
    "# Visualization parameters\n",
    "colors = sn.color_palette(n_colors=9)\n",
    "recording_brain_areas={'M1': [30, 56, 47, 40, 121, 48, 120, 98], 'PM':[11, 9, 18, 22, 10, 45]}\n",
    "day_colors = ['dodgerblue', 'indigo', 'violet', 'lightblue', 'mediumorchid',\n",
    "              'purple', 'steelblue', 'dodgerblue', 'lightblue', 'red', 'black', 'green', 'purple', 'cyan', 'gray', 'yellow'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bf9fd1-9c1a-4b38-bd17-0a2ca528a169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.071664Z",
     "iopub.status.busy": "2024-07-26T21:44:22.071520Z",
     "iopub.status.idle": "2024-07-26T21:44:22.075726Z",
     "shell.execute_reply": "2024-07-26T21:44:22.074993Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.071650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize']=24\n",
    "plt.rcParams['ytick.labelsize']=24\n",
    "plt.rcParams['axes.labelsize']=28\n",
    "plt.rcParams['axes.spines.top']=False\n",
    "plt.rcParams['axes.titlesize'] = 28\n",
    "plt.rcParams['axes.spines.right']=False\n",
    "plt.rcParams['lines.linewidth']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd9b7ad-eec0-4c49-801f-0df15b0df5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.783954Z",
     "start_time": "2024-05-03T16:03:36.765800Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.076509Z",
     "iopub.status.busy": "2024-07-26T21:44:22.076363Z",
     "iopub.status.idle": "2024-07-26T21:44:22.189652Z",
     "shell.execute_reply": "2024-07-26T21:44:22.188797Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.076495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smooth_timeseries_gaus(timeseries_data, samplerate, width, nstd=3, conv_mode='same'):\n",
    "    '''\n",
    "    Smooths across 2 \n",
    "    \n",
    "    Args:\n",
    "        timeseries_data (ntime, ...)\n",
    "        samplerate (int): Sample rate of timeseries\n",
    "        width (float): Width of the gaussian in time [ms] from -nstd to +nstd\n",
    "        nstd (float/int): Number of standard deviations to be used in the filter calculation.\n",
    "        conv_mode (str): Sets the size of the output. Takes eithe 'full', 'valid', or 'same'. See scipy.signal.convolve for full documentationat\n",
    "        \n",
    "    Returns: \n",
    "        smoothed_timeseries\n",
    "    '''\n",
    "    sample_std = (width/nstd)*(samplerate/(1000)) # Convert from s to ms\n",
    "    x = np.arange(-sample_std*nstd, nstd*sample_std+1)\n",
    "    gaus_filter = (1/(sample_std*np.sqrt(2*np.pi)))*np.exp(-(x**2)/(2*sample_std**2))\n",
    "    return np.apply_along_axis(scipy.signal.convolve, 0, timeseries_data, gaus_filter, mode=conv_mode, method='direct')\n",
    "def load_hdf_group(data_dir, hdf_filename, group=\"/\"):\n",
    "    '''\n",
    "    Loads any datasets from the given hdf group into a dictionary. Also will\n",
    "    recursively load other groups if any exist under the given group\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): folder where data is located\n",
    "        hdf_filename (str): name of hdf file\n",
    "        group (str): name of the group to load\n",
    "    \n",
    "    Returns:\n",
    "        dict: all the datasets contained in the given group\n",
    "    '''\n",
    "    full_file_name = os.path.join(data_dir, hdf_filename)\n",
    "    hdf = h5py.File(full_file_name, 'r')\n",
    "    if group not in hdf:\n",
    "        raise ValueError('No such group in file {}'.format(hdf_filename))\n",
    "\n",
    "    # Recursively load groups until datasets are reached\n",
    "    def _load_hdf_group(hdf):\n",
    "        keys = hdf.keys()\n",
    "        data = dict()\n",
    "        for k in keys:\n",
    "            if isinstance(hdf[k], h5py.Group):\n",
    "                data[k] = _load_hdf_group(hdf[k])\n",
    "            else:\n",
    "                k_, v = _load_hdf_dataset(hdf[k], k)\n",
    "                data[k_] = v\n",
    "        return data\n",
    "\n",
    "    data = _load_hdf_group(hdf[group])\n",
    "    hdf.close()\n",
    "    return data\n",
    "\n",
    "def _load_hdf_dataset(dataset, name):\n",
    "    '''\n",
    "    Internal function for loading hdf datasets. Decodes json and unicode data automatically.\n",
    "\n",
    "    Args:\n",
    "        dataset (hdf object): dataset to load\n",
    "        name (str): name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing:\n",
    "            | **name (str):** name of the dataset (might be modified)\n",
    "            | **data (object):** loaded data\n",
    "    '''\n",
    "    data = dataset[()]\n",
    "    if '_json' in name:\n",
    "        import json\n",
    "        name = name.replace('_json', '')\n",
    "        data = json.loads(data)\n",
    "    try:\n",
    "        data = data.decode('utf-8')\n",
    "    except:\n",
    "        pass\n",
    "    return name, data\n",
    "\n",
    "def get_rotations(data_in, condition_labels, separate_conditions=True, pcs=None):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "        data_in (ntime, nfeatures, ntrials):\n",
    "        condition_labels (ntrials)\n",
    "        separate_conditions (bool): to mean average at each time point\n",
    "    \n",
    "    Returns:\n",
    "        tavg_proj_data (ntime, nfeat, ncond)\n",
    "        indiv_proj_data (ntime, nfeat, ntrials)\n",
    "        pca_components (nweights, nfeat)\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    ntime, nfeat, ntrials = data_in.shape\n",
    "    ncond = len(np.unique(condition_labels))\n",
    "    \n",
    "    if ntime*ncond < nfeat:\n",
    "        print('You need more samples than features')\n",
    "    \n",
    "    # Zscore activity from each neuron.\n",
    "    for ifeat in range(nfeat):\n",
    "        data_in[:,ifeat,:] = scipy.stats.zscore(data_in[:,ifeat,:], axis=None) # Ensure activity has the same range for each channel\n",
    "    \n",
    "    # Trial average for each condition\n",
    "    tavg_data = np.zeros((ntime,nfeat,ncond))\n",
    "    for icond, cond in enumerate(np.unique(condition_labels)):\n",
    "        tavg_data[:,:,icond] = np.mean(data_in[:,:,condition_labels==cond], axis=2)\n",
    "    \n",
    "    # Center at each time point for each channel across conditions\n",
    "    if separate_conditions:\n",
    "        cond_data = tavg_data - np.nanmean(tavg_data, axis=2)[:,:,None] # Center data across conditions\n",
    "    else:\n",
    "        cond_data = tavg_data\n",
    "    \n",
    "    # Concatenate data into the shape (ct X n)\n",
    "    reorg_data = np.zeros((ntime*ncond, nfeat))\n",
    "    for ifeat in range(nfeat):\n",
    "        reorg_data[:,ifeat] = cond_data[:,ifeat,:].flatten()\n",
    "    \n",
    "    # Calculate PCs and fit to conditioned data\n",
    "    print(reorg_data.shape)\n",
    "    pca = PCA().fit(reorg_data)\n",
    "    \n",
    "    # Project data from each condition onto PCs\n",
    "    tavg_proj_data = np.zeros((ntime, nfeat, ncond))*np.nan\n",
    "    for itarget in range(ncond):\n",
    "        tavg_proj_data[:,:,itarget] = pca.transform(cond_data[:,:,itarget])\n",
    "        \n",
    "    # Project data from each trial onto PCs\n",
    "    indiv_proj_data = np.zeros((ntime, nfeat, ntrials))\n",
    "    for itrial in range(ntrials):\n",
    "        indiv_proj_data[:,:,itrial] = pca.transform(data_in[:,:,itrial])\n",
    "    \n",
    "    return tavg_proj_data, indiv_proj_data, pca.components_\n",
    "\n",
    "import copy\n",
    "def estimate_PR(data, ddof=1, sqrt_transform=False, normalize=False):\n",
    "    '''\n",
    "    This function calculates participation ratio for given data. Participation ratio counts the effective dimensions of the spread of data by taking the ratio of the square of the first and second moments of the eigenvalue probability density function. Refer: Recanatesi S, Dimensionality in recurrent spiking networks: Global trends in activity and local origins in connectivity. PLoS Comput Biol. 2019\n",
    "    \n",
    "      Args:\n",
    "        data (2D Numpy array): Neural data in format (n_timepoints, n_units)\n",
    "        ddof : (int) :Number of degrees of freedom to use when computing PR_norm (default: 1).\n",
    "        sqrt_transform : (bool) : Whether to apply a square root transform to remove poisson dependence on spike count data before computing PR_norm (default: False).\n",
    "        normalize bool : Whether to compute the normalized PR or the participation ratio itself(default: False)\n",
    "      Returns:\n",
    "          PR (float): dimensionality in terms of participation ratio, normalized to the number of units if normalize is True.\n",
    "  '''\n",
    "    n_time_bins, n_units = data.shape\n",
    "    X = copy.copy(data)  # local copy, because data is mutable. for square root transform\n",
    "\n",
    "    if sqrt_transform:\n",
    "        X = np.sqrt(X + 0.375)  # see Kihlberg, 1972; 0.386 could also be a good value\n",
    "\n",
    "    X = X - np.mean(X, axis=0, keepdims=True)  # center data\n",
    "    C = 1. / (n_time_bins - ddof) * X.T @ X\n",
    "    eigenvalues = np.linalg.eigvals(C)\n",
    "    PR = (np.sum(eigenvalues)) ** 2 / np.sum(eigenvalues ** 2)\n",
    "\n",
    "    return (PR - 1) / (X.shape[1] - 1) if normalize else PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464972e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.790665Z",
     "start_time": "2024-05-03T16:03:36.785254Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.191533Z",
     "iopub.status.busy": "2024-07-26T21:44:22.191387Z",
     "iopub.status.idle": "2024-07-26T21:44:22.197119Z",
     "shell.execute_reply": "2024-07-26T21:44:22.196401Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.191520Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subspace angles\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def subspace_angles(A, B, angle_in_degrees = True):\n",
    "    \"\"\"Compute the subspace angles between two subspaces.\"\"\"\n",
    "    # Compute the Singular Value Decomposition (SVD) of A^T * B\n",
    "    U, S, Vh = np.linalg.svd(np.dot(A.T, B))\n",
    "    \n",
    "    # Compute the principal angles from the singular values\n",
    "    principal_angles = np.arccos(np.minimum(S, 1.0))\n",
    "    mean_principal_angle = np.mean(principal_angles)\n",
    "    \n",
    "    return np.degrees(mean_principal_angle) if angle_in_degrees else mean_principal_angle \n",
    "\n",
    "from scipy.linalg import subspace_angles\n",
    "\n",
    "def orientation_similarity(subspace1, subspace2):\n",
    "    \"\"\"Compute orientation similarity between two subspaces. Value ranges from 0 to 1.\n",
    "     Identical subspace will have Sori = 1, while orthogonal spaces will have Sori = 0.\n",
    "     \"\"\"\n",
    "    # Calculate principal angles between subspaces\n",
    "    angles = subspace_angles(subspace1, subspace2)\n",
    "    # print(angles)\n",
    "\n",
    "    # Calculate the mean cosine of these angles\n",
    "    similarity = np.mean(np.cos(angles))\n",
    "    # print(np.cos(angles))\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def get_PCA_subspace(data): \n",
    "    \"\"\"\n",
    "    Compute the principal component subspace of the given data.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): Input data array with shape (n_samples, n_features).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The principal component subspace with shape (n_features, n_components),\n",
    "                   where n_components is the number of principal components.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    X = data - np.mean(data, axis = 0)\n",
    "\n",
    "    # Create a PCA instance and fit to the data\n",
    "    pca = PCA()  # Here, we are getting all components, but you can specify fewer if desired.\n",
    "    pca.fit_transform(X)\n",
    "\n",
    "    # Extract the subspace\n",
    "    subspace = pca.components_.T \n",
    "\n",
    "    return subspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282b3f2-3af8-4d1f-b5ca-c076fc97fcb3",
   "metadata": {},
   "source": [
    "# Load relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236261de-598d-4327-b612-91dbfe77df98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:36.880697Z",
     "start_time": "2024-05-03T16:03:36.791916Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.197769Z",
     "iopub.status.busy": "2024-07-26T21:44:22.197637Z",
     "iopub.status.idle": "2024-07-26T21:44:22.221008Z",
     "shell.execute_reply": "2024-07-26T21:44:22.220230Z",
     "shell.execute_reply.started": "2024-07-26T21:44:22.197756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/moor-data/results/Ryan/neuropixel_targeting/ecog_decoding_maps/npinsert_ecog_decoding_all\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(base_save_dir, ecog_dec_acc_file_name))\n",
    "ecog_dec_acc_file_name = 'ecog_decoding_maps/npinsert_ecog_decoding'\n",
    "ecog_dec_acc_file_name_x = 'ecog_decoding_maps/npinsert_ecog_decoding_x'\n",
    "ecog_dec_acc_file_name_y = 'ecog_decoding_maps/npinsert_ecog_decoding_y'\n",
    "ecog_dec_acc = load_hdf_group(base_save_dir, ecog_dec_acc_file_name)\n",
    "ecog_dec_acc_x = load_hdf_group(base_save_dir, ecog_dec_acc_file_name_x)\n",
    "ecog_dec_acc_y = load_hdf_group(base_save_dir, ecog_dec_acc_file_name_y)\n",
    "day_colors = ecog_dec_acc[subject]['day_colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed3245-97ce-4d04-a79f-1b0bbb294ca1",
   "metadata": {},
   "source": [
    "## Load preprocessed neuropixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb431c94-22a8-49db-b93c-706f3e58acde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:10:29.733830Z",
     "start_time": "2024-05-03T16:03:36.881982Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T21:44:22.221661Z",
     "iopub.status.busy": "2024-07-26T21:44:22.221527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "aopy.utils.release_memory_limit()\n",
    "df, rasters, preproc_metadata = aopy.data.base.pkl_read(f\"{subject}_np_preprocessed\", os.path.join(base_save_dir, np_preproc_data_folder))\n",
    "print(f\"{np.round((time.time()-start)/60)} min to load preprocessed data\")\n",
    "nrecs = preproc_metadata['nrecs']\n",
    "recording_site = preproc_metadata['recording_sites'] # will be the same for all align events\n",
    "implants = ['NPinsert72' if preproc_metadata['implant'][irec] == 'NP_Insert72' else 'NPinsert137' for irec in range(len(preproc_metadata['implant']))] #Rename because name in bmi3d is slightly different (TODO)\n",
    "dates = np.unique(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bccf9f",
   "metadata": {},
   "source": [
    "## Load ECoG decoding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0fa74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_units, column_units, depth_units, depth_group_info_by_site, pseudopopulation_metadata, unit_df = aopy.data.base.pkl_read(f\"{subject}_np_psuedopopulations\",  os.path.join(base_save_dir, np_preproc_data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b71976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/np_analysis_preproc_data\"\n",
    "np_decoding, _ = aopy.data.base.pkl_read(f\"{subject}_np_decoding_accuracy\", save_dir)\n",
    "max_np_decoding = [np.max(np.mean(np_decoding[irec], axis=1)) for irec in range(len(np_decoding))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b68cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define ecog decoding accuracy as one variable to make it easier to do further analysis\n",
    "pp_column_sites = [column_units[igroup]['rec_site'][0] for igroup in range(len(column_units))]\n",
    "pp_column_implants = [column_units[igroup]['implant'][0] for igroup in range(len(column_units))]\n",
    "ecog_dec_acc_rec_site, ecog_dec_acc_rec_site_pp = {}, {}\n",
    "ecog_dec_acc_rec_site_x = {}\n",
    "ecog_dec_acc_rec_site_y = {}\n",
    "for align_event in align_events:\n",
    "    ecog_dec_acc_rec_site[align_event] = [ecog_dec_acc[subject][f\"{implants[irec]}_interp\"][rec_site-1] for irec, rec_site in enumerate(recording_site)]\n",
    "    ecog_dec_acc_rec_site_pp[align_event] = [ecog_dec_acc[subject][f\"{pp_column_implants[irec]}_interp\"][rec_site-1] for irec, rec_site in enumerate(pp_column_sites)]\n",
    "    ecog_dec_acc_rec_site_x[align_event] = [ecog_dec_acc_x[subject][f\"{implants[irec]}_interp\"][rec_site-1] for irec, rec_site in enumerate(recording_site)]\n",
    "    ecog_dec_acc_rec_site_y[align_event] = [ecog_dec_acc_y[subject][f\"{implants[irec]}_interp\"][rec_site-1] for irec, rec_site in enumerate(recording_site)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a89e90-aa34-42e2-abba-694030b29a0b",
   "metadata": {},
   "source": [
    "## Identify stable units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10963e55-60bd-4ff0-9cb4-c468f742f7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:10:29.851862Z",
     "start_time": "2024-05-03T16:10:29.738625Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if subject == 'beignet':\n",
    "    qc_results, ksdrift = aopy.data.base.pkl_read(f\"{subject}_QCunits\", os.path.join(base_save_dir, np_preproc_data_folder))\n",
    "elif subject == 'affi':\n",
    "    qc_results = aopy.data.base.pkl_read(f\"{subject}_QCunits\", os.path.join(base_save_dir, np_preproc_data_folder))\n",
    "stable_unit_labels = [qc_results['final_good_unit_labels'][irec] for irec in range(nrecs)]\n",
    "stable_unit_idx = [qc_results['final_good_unit_idx'][irec] for irec in range(nrecs)]\n",
    "nstable_unit = np.array([len(qc_results['final_good_unit_idx'][irec]) for irec in range(nrecs)])\n",
    "neuron_pos = [qc_results['position'][irec] for irec in range(nrecs)]\n",
    "\n",
    "# stable_unit_labels = [qc_results['manual_good_unit_labels'][irec] for irec in range(nrecs)]\n",
    "# stable_unit_idx = [qc_results['manual_good_unit_idx'][irec] for irec in range(nrecs)]\n",
    "# nstable_unit = np.array([len(qc_results['manual_good_unit_idx'][irec]) for irec in range(nrecs)])\n",
    "# neuron_pos = [qc_results['manual_position'][irec] for irec in range(nrecs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6cf04d-8424-4cfd-8e92-d8d88cca7190",
   "metadata": {},
   "source": [
    "## Zscore FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f037f27-6edd-475c-94d5-c18c8c427943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:20.740148Z",
     "start_time": "2024-05-03T16:10:29.857320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Zscore the activity of each neuron (even unstable) across all trials\n",
    "frs = {}\n",
    "fr_zscore = {}\n",
    "new_bin_fs = 50\n",
    "fr_stats = {'mean_fr': {}, 'var_fr': {}, 'mean_fr_sqrt': {}, 'var_fr_sqrt': {}}\n",
    "for align_event in tqdm(align_events):\n",
    "    temp_spike_data = [rasters['neural'][align_event][irec][:,np.array(df['good_trial'][df['date']==dates[irec]]),:][:,:,stable_unit_idx[irec]] for irec in range(nrecs)] # Shape (ntime, ntrial, nunit)    \n",
    "    # temp_spike_data = [rasters['sbp'][align_event][irec][:,np.array(df['good_trial'][df['date']==dates[irec]]),:] for irec in range(nrecs)] # Shape (ntime, ntrial, nunit)    \n",
    "    fr_stats['mean_fr'][align_event] = []\n",
    "    fr_stats['var_fr'][align_event] = []\n",
    "    fr_stats['mean_fr_sqrt'][align_event] = []\n",
    "    fr_stats['var_fr_sqrt'][align_event] = []\n",
    "    fr_stats['mean_fr'][align_event].extend([np.mean(temp_spike_data[irec], axis=(0,1)) for irec in range(nrecs)])\n",
    "    fr_stats['var_fr'][align_event].extend([np.var(temp_spike_data[irec], axis=(0,1)) for irec in range(nrecs)])\n",
    "    fr_stats['mean_fr_sqrt'][align_event].extend([np.mean(np.sqrt(temp_spike_data[irec]+.375), axis=(0,1)) for irec in range(nrecs)])\n",
    "    fr_stats['var_fr_sqrt'][align_event].extend([np.var(np.sqrt(temp_spike_data[irec]+.375), axis=(0,1)) for irec in range(nrecs)])\n",
    "    \n",
    "    frs[align_event] = {'align_spikes': [], 'align_spikes_dwns': []}\n",
    "    fr_zscore[align_event] = {'align_spikes_zscore': [], 'align_spikes_zscore_dwns': []}\n",
    "    [fr_zscore[align_event]['align_spikes_zscore'].append((temp_spike_data[irec]-np.mean(temp_spike_data[irec], axis=(0,1)))/np.std(temp_spike_data[irec], axis=(0,1))) for irec in range(nrecs)]\n",
    "    [frs[align_event]['align_spikes'].append(temp_spike_data[irec]) for irec in range(nrecs)]\n",
    "\n",
    "    for irec in range(nrecs):\n",
    "        temp_resampled_spike_data = aopy.precondition.base.downsample(temp_spike_data[irec], preproc_metadata['neural_samplerate'], new_bin_fs)\n",
    "        frs[align_event]['align_spikes_dwns'].append(temp_resampled_spike_data)\n",
    "        fr_zscore[align_event]['align_spikes_zscore_dwns'].append((temp_resampled_spike_data-np.mean(temp_resampled_spike_data, axis=(0,1)))/np.std(temp_resampled_spike_data, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b7111-275c-46c5-b89a-1720bf812099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:21.066149Z",
     "start_time": "2024-05-03T16:17:20.745989Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,3))\n",
    "aopy.visualization.plot_boxplots(fr_stats['mean_fr'][align_events[-1]], np.arange(nrecs), ax = ax)\n",
    "ax.set(xlabel='Recording Site', ylabel='Mean FR')\n",
    "ax.set_xticks(np.arange(nrecs), recording_site)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff1bef-1717-47e6-89b8-5067f8f97495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:24.875838Z",
     "start_time": "2024-05-03T16:17:21.068390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*3, 3))\n",
    "for irec in range(nrecs):\n",
    "    ax[irec].plot(fr_stats['mean_fr'][align_events[-1]][irec], fr_stats['var_fr'][align_events[-1]][irec], '.')\n",
    "    ax[irec].set(xlabel='FR Mean', ylabel='FR Var', title=f\"Site: {recording_site[irec]}\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Neural data with sqrt transform applied\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*3, 3))\n",
    "for irec in range(nrecs):\n",
    "    ax[irec].plot(fr_stats['mean_fr_sqrt'][align_events[-1]][irec], fr_stats['var_fr_sqrt'][align_events[-1]][irec], '.')\n",
    "    ax[irec].set(xlabel='FR Mean - sqrt transform', ylabel='FR Var - sqrt transform', title=f\"Site: {recording_site[irec]}\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c2f4d-d72a-476e-becf-76a776534ec0",
   "metadata": {},
   "source": [
    "# Calculate dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664a793-efec-446d-b7a3-deef55c0f348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:24.880537Z",
     "start_time": "2024-05-03T16:17:24.877545Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_pop_dynamics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f704d1-ebac-4f72-b99f-22ce57809d4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:25.135387Z",
     "start_time": "2024-05-03T16:17:25.135374Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate spike data for across all trials for each recording\n",
    "new_bin_fs = 20\n",
    "conc_spikes, conc_spikes_dwns, conc_spikes_smooth, conc_spikes_dwns_smooth = [], [], [], []\n",
    "conc_spikes_trial_sep = []\n",
    "zconc_spikes_trial_sep = []\n",
    "zconc_spikes, zconc_spikes_dwns, zconc_spikes_dwns_smooth = [], [], []\n",
    "zconc_spikes_smooth = []\n",
    "for idate, date in enumerate(tqdm(dates[:])):    \n",
    "    conc_spikes_day = []\n",
    "    conc_spikes_day_smooth = []\n",
    "    temp_spike_segs = list(df['spike_segs'][df[(df['date']==date)*(df['good_trial'])].index])   \n",
    "    for itrial in range(len(temp_spike_segs)):\n",
    "        temp_spike_labels = list(temp_spike_segs[itrial].keys())\n",
    "        temp_ntime = len(temp_spike_segs[itrial][temp_spike_labels[0]]) # For each trial the spike segments are the same length\n",
    "        trial_binned_spikes = np.zeros((temp_ntime, len(temp_spike_labels)))*np.nan\n",
    "        for ilabel, label in enumerate(temp_spike_labels):\n",
    "            trial_binned_spikes[:,ilabel] = temp_spike_segs[itrial][label]\n",
    "        \n",
    "        conc_spikes_day.append(trial_binned_spikes)\n",
    "\n",
    "# for idate, date in enumerate(tqdm(dates[:])):    \n",
    "#     conc_spikes_day = []\n",
    "#     conc_spikes_day_smooth = []\n",
    "#     temp_spike_segs = list(df['ap_band_power_segs'][df[(df['date']==date)*(df['good_trial'])].index])\n",
    "#     for itrial in range(len(temp_spike_segs)):\n",
    "#         # temp_spike_labels = np.arange(temp_spike_segs[itrial].shape[1])\n",
    "#         # temp_ntime = temp_spike_segs[itrial].shape[0] # For each trial, the spike segments for each unit are the same length\n",
    "#         # trial_binned_spikes = np.zeros((temp_ntime, len(temp_spike_labels)))*np.nan\n",
    "#         # for ilabel in temp_spike_labels:\n",
    "#         #     trial_binned_spikes[:,ilabel] = temp_spike_segs[itrial][label]\n",
    "        \n",
    "#         conc_spikes_day.append(temp_spike_segs[itrial])\n",
    "        \n",
    "    conc_spikes.append(np.concatenate(conc_spikes_day))\n",
    "    conc_spikes_dwns.append(aopy.precondition.base.downsample(np.concatenate(conc_spikes_day), preproc_metadata['neural_samplerate'], new_bin_fs))\n",
    "    conc_spikes_smooth.append(smooth_timeseries_gaus(np.concatenate(conc_spikes_day), 1/preproc_metadata['spike_bin_width'], 300))\n",
    "    conc_spikes_dwns_smooth.append(smooth_timeseries_gaus(aopy.precondition.base.downsample(np.concatenate(conc_spikes_day), preproc_metadata['neural_samplerate'], new_bin_fs), 1/preproc_metadata['spike_bin_width'], 300))\n",
    "    conc_spikes_trial_sep.append(conc_spikes_day)\n",
    "    zconc_spikes_trial_sep.append([(conc_spikes_day[itr] - np.mean(np.concatenate(conc_spikes_day), axis=0))/np.std(np.concatenate(conc_spikes_day), axis=0) for itr in range(len(conc_spikes_day))])\n",
    "    temp_zconc = (np.concatenate(conc_spikes_day) - np.mean(np.concatenate(conc_spikes_day), axis=0))/np.std(np.concatenate(conc_spikes_day), axis=0)\n",
    "    temp_zconc_dwns = (aopy.precondition.base.downsample(np.concatenate(conc_spikes_day), preproc_metadata['neural_samplerate'], new_bin_fs) - np.mean(aopy.precondition.base.downsample(np.concatenate(conc_spikes_day), preproc_metadata['neural_samplerate'], new_bin_fs), axis=0))/np.std(aopy.precondition.base.downsample(np.concatenate(conc_spikes_day), preproc_metadata['neural_samplerate'], new_bin_fs), axis=0)\n",
    "    zconc_spikes.append(temp_zconc)\n",
    "    zconc_spikes_dwns.append(temp_zconc_dwns)\n",
    "    zconc_spikes_smooth.append(smooth_timeseries_gaus(temp_zconc, 1/preproc_metadata['spike_bin_width'], 150))\n",
    "    zconc_spikes_dwns_smooth.append(smooth_timeseries_gaus(temp_zconc_dwns, new_bin_fs, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f3182-fa24-43d8-a89c-9ccb51863c7b",
   "metadata": {},
   "source": [
    "## Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c4ee2-26d9-4ea7-821a-fd220313f975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:25.137117Z",
     "start_time": "2024-05-03T16:17:25.137106Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_pop_dynamics['dimensionality']={}\n",
    "np_pop_dynamics['dimensionality']['PR'], np_pop_dynamics['dimensionality']['PR_norm'] = [], []\n",
    "np_pop_dynamics['dimensionality']['PCA_exp_var'], np_pop_dynamics['dimensionality']['PCA_ndims'], np_pop_dynamics['dimensionality']['PCA_ndims_norm'] = [], [], []\n",
    "for idate, date, in enumerate(tqdm(dates)):\n",
    "    # Participation Ratio\n",
    "    np_pop_dynamics['dimensionality']['PR'].append(estimate_PR(conc_spikes_dwns_smooth[idate][:,stable_unit_idx[idate]], sqrt_transform=True))\n",
    "    np_pop_dynamics['dimensionality']['PR_norm'].append(estimate_PR(conc_spikes_dwns_smooth[idate][:,stable_unit_idx[idate]], normalize=True, sqrt_transform=True))\n",
    "\n",
    "    # PCA\n",
    "    exp_var, ndims, _ = aopy.analysis.get_pca_dimensions(np.sqrt(conc_spikes_dwns_smooth[idate][:,stable_unit_idx[idate]] + 0.375))\n",
    "    np_pop_dynamics['dimensionality']['PCA_exp_var'].append(np.array(exp_var))\n",
    "    np_pop_dynamics['dimensionality']['PCA_ndims'].append(ndims)\n",
    "    np_pop_dynamics['dimensionality']['PCA_ndims_norm'].append((ndims - 1) / (conc_spikes_dwns_smooth[idate].shape[1] - 1))\n",
    "\n",
    "# Use rasters aligned to specific task events\n",
    "for align_event in align_events:\n",
    "    np_pop_dynamics['dimensionality'][align_event] = {}\n",
    "    np_pop_dynamics['dimensionality'][align_event]['PR'] = []\n",
    "    np_pop_dynamics['dimensionality'][align_event]['PR_norm'] = []\n",
    "    np_pop_dynamics['dimensionality'][align_event]['PCA_exp_var'] = []\n",
    "    np_pop_dynamics['dimensionality'][align_event]['PCA_ndims'] = []\n",
    "    for idate, date, in enumerate(tqdm(dates)):\n",
    "        # Participation Ratio\n",
    "        np_pop_dynamics['dimensionality'][align_event]['PR'].append(estimate_PR(np.vstack(fr_zscore[align_event]['align_spikes_zscore'][idate])))\n",
    "        np_pop_dynamics['dimensionality'][align_event]['PR_norm'].append(estimate_PR(np.vstack(fr_zscore[align_event]['align_spikes_zscore'][idate]), normalize=True))\n",
    "\n",
    "        # PCA\n",
    "        exp_var, ndims, _ = aopy.analysis.get_pca_dimensions(np.vstack(fr_zscore[align_event]['align_spikes_zscore'][idate]))\n",
    "        np_pop_dynamics['dimensionality'][align_event]['PCA_exp_var'].append(np.array(exp_var))\n",
    "        np_pop_dynamics['dimensionality'][align_event]['PCA_ndims'].append(ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a837d-1b37-4069-bd29-c7804f0920e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:25.138177Z",
     "start_time": "2024-05-03T16:17:25.138166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,3)) # All spikes - want to also use data aligned to behavior.\n",
    "ax[0].plot(np_pop_dynamics['dimensionality']['PR'])\n",
    "ax[1].plot(np_pop_dynamics['dimensionality']['PR_norm'])\n",
    "[ax[ia].set_xticks(np.arange(len(recording_site)), recording_site) for ia in range(len(ax))]\n",
    "ax[0].set(xlabel='Recording', ylabel='PR')\n",
    "ax[1].set(xlabel='Recording', ylabel='PR_norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cf1c6-c11f-4fd2-821f-787ec480bac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:25.139144Z",
     "start_time": "2024-05-03T16:17:25.139133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(15,4)) # All spikes - want to also use data aligned to behavior.\n",
    "# [ax[0].plot(0, np_pop_dynamics['dimensionality']['PR_norm'][irec], '.', color=day_colors[irec], markersize=14) for irec in range(nrecs) if recording_site[irec] in recording_brain_areas['PM']]\n",
    "# [ax[0].plot(1, np_pop_dynamics['dimensionality']['PR_norm'][irec], '.',color=day_colors[irec], markersize=14) for irec in range(nrecs) if recording_site[irec] in recording_brain_areas['M1']]\n",
    "[ax[0].plot(ecog_dec_acc[subject]['rec_locations'][irec,0], np_pop_dynamics['dimensionality']['PR_norm'][irec], '.',color=day_colors[irec], markersize=14) for irec in range(nrecs)]\n",
    "ax[0].set(xlabel='X pos', ylabel='PR Norm')\n",
    "\n",
    "[ax[1].plot(ecog_dec_acc_rec_site[align_events[-1]][irec], np_pop_dynamics['dimensionality']['PR_norm'][irec], '.', markersize=14, color=day_colors[irec]) for irec in range(nrecs)]\n",
    "ax[1].set(xlabel='ECoG Weight', ylabel='PR Norm')\n",
    "\n",
    "[ax[2].plot(max_np_decoding[irec], np_pop_dynamics['dimensionality']['PR_norm'][irec], '.', markersize=14, color=day_colors[irec]) for irec in range(nrecs)]\n",
    "ax[2].set(xlabel='Neuropixel Decoding', ylabel='PR Norm')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820eb7f-8a32-499f-86e2-3f4a4d0fc89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:17:25.140046Z",
     "start_time": "2024-05-03T16:17:25.140036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(12,3))\n",
    "[ax[0].plot(np.cumsum(np_pop_dynamics['dimensionality']['PCA_exp_var'][idate])/np.sum(np_pop_dynamics['dimensionality']['PCA_exp_var'][idate]), color=day_colors[idate]) for idate in range(len(dates))]\n",
    "ax[0].set(xlim=(0,30))\n",
    "ax[0].set(xlabel='Dimension', ylabel='Explained Variance')\n",
    "\n",
    "ax[1].plot(np_pop_dynamics['dimensionality']['PCA_ndims'])\n",
    "ax[1].set_xticks(np.arange(len(recording_site)), recording_site)\n",
    "ax[1].set(xlabel='Recording', ylabel='Dimensionality')\n",
    "ax[2].plot(np_pop_dynamics['dimensionality']['PCA_ndims_norm'])\n",
    "ax[2].set_xticks(np.arange(len(recording_site)), recording_site)\n",
    "ax[2].set(xlabel='Recording', ylabel='Dimensionality Normalized')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3c5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(8,3)) # All spikes - want to also use data aligned to behavior.\n",
    "[ax[0].plot(0, np_pop_dynamics['dimensionality']['PCA_ndims_norm'][irec], '.', color=day_colors[irec], markersize=14) for irec in range(nrecs) if recording_site[irec] in recording_brain_areas['PM']]\n",
    "[ax[0].plot(1, np_pop_dynamics['dimensionality']['PCA_ndims_norm'][irec], '.',color=day_colors[irec], markersize=14) for irec in range(nrecs) if recording_site[irec] in recording_brain_areas['M1']]\n",
    "# [ax[ia].set_xticks(np.arange(len(recording_site)), recording_site) for ia in range(len(ax))]\n",
    "ax[0].set(ylabel='PCA Dimensionality Norm', xlim=(-1,2))\n",
    "ax[0].set_xticks([0,1], ['PM', 'M1'])\n",
    "\n",
    "[ax[1].plot(ecog_dec_acc_rec_site[align_events[-1]][irec], np_pop_dynamics['dimensionality']['PCA_ndims_norm'][irec], '.', markersize=14, color=day_colors[irec]) for irec in range(nrecs)]\n",
    "ax[1].set(xlabel='ECoG Weight', ylabel='PCA Dimensionality Norm')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f365f3-b0db-4caa-ae39-6db0936f2625",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb9673-dbaf-41db-83eb-665438c3f422",
   "metadata": {},
   "source": [
    "### Trial Averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba57f8-38ef-4af7-a0cb-1239a2281edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "align_event = align_events[-1]\n",
    "print(align_event)\n",
    "rotations = []\n",
    "for irec in tqdm(range(nrecs)):\n",
    "    temp_target_labels = np.array(df['target_idx'][df['good_trial']*(df['date']==dates[irec])])\n",
    "    temp_rotations = get_rotations(np.swapaxes(fr_zscore[align_event]['align_spikes_zscore_dwns'][irec], 1, 2), temp_target_labels)\n",
    "    rotations.append(temp_rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a4cbf-9269-4347-bcaf-8ffc4c705b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smooth_width = 100 #[ms]\n",
    "# Projection onto PC1, PC2\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    [ax[irec].plot(smooth_timeseries_gaus(rotations[irec][0][:,0,icond], new_bin_fs, smooth_width), smooth_timeseries_gaus(rotations[irec][0][:,1,icond], new_bin_fs, smooth_width), color=colors[icond]) for icond in range(rotations[irec][0].shape[2])]\n",
    "    ax[irec].set(xlim = (-2,2), ylim=(-2,2), xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947dfbc-2a30-469f-9a54-0f9fabbc86aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Projection onto PC2, PC3\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    [ax[irec].plot(smooth_timeseries_gaus(rotations[irec][0][:,1,icond], new_bin_fs, smooth_width), smooth_timeseries_gaus(rotations[irec][0][:,2,icond], new_bin_fs, smooth_width), color=colors[icond]) for icond in range(rotations[irec][0].shape[2])]\n",
    "    ax[irec].set(xlim = (-1.5,1.5), ylim=(-1.5,1.5), xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec5bfe-03a8-4273-96b5-017074a48e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Projection onto PC1, PC2, PC3\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4), subplot_kw={'projection':'3d'})\n",
    "for irec in range(nrecs):\n",
    "    [ax[irec].plot(smooth_timeseries_gaus(rotations[irec][0][:,0,icond], new_bin_fs, smooth_width), smooth_timeseries_gaus(rotations[irec][0][:,1,icond], new_bin_fs, smooth_width),smooth_timeseries_gaus(rotations[irec][0][:,2,icond], new_bin_fs, smooth_width), color=colors[icond]) for icond in range(rotations[irec][0].shape[2])]\n",
    "    ax[irec].set(xlim = (-1.5,1.5), ylim=(-1.5,1.5),zlim=(-1.5,1.5), xlabel='PC1', ylabel='PC2',zlabel='PC3', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891a7da-ff61-4872-8663-236dd38c5eff",
   "metadata": {},
   "source": [
    "### Single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3857f-9bec-4c16-8749-4db256daeb58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tidx = 30\n",
    "unique_targets = np.unique(df['target_idx'])\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    for itarg, targ in enumerate(unique_targets):\n",
    "        temp_std = np.sqrt(np.std(rotations[irec][1][tidx,0,(temp_target_labels==targ)])**2 + np.mean(rotations[irec][1][tidx,1,(temp_target_labels==targ)])**2) \n",
    "        ax[irec].plot(np.mean(rotations[irec][1][tidx,0,(temp_target_labels==targ)]), np.mean(rotations[irec][1][tidx,1,(temp_target_labels==targ)]), '.', color=colors[itarg], markersize=10)\n",
    "        ax[irec].plot(np.mean(rotations[irec][1][tidx,0,(temp_target_labels==targ)]), np.mean(rotations[irec][1][tidx,1,(temp_target_labels==targ)]), '.', color=colors[itarg], markersize=100*temp_std, alpha=0.4)\n",
    "        ax[irec].set(xlim = (-2,2), ylim=(-2,2), xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    for itarg, targ in enumerate(unique_targets):\n",
    "        ax[irec].plot(rotations[irec][1][tidx,0,(temp_target_labels==targ)], rotations[irec][1][tidx,1,(temp_target_labels==targ)], '.', color=colors[itarg])\n",
    "    # ax[irec].set(xlim = (-3,3), ylim=(-3,3), xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b253ec-f880-456e-b04a-226e02c3561e",
   "metadata": {},
   "source": [
    "### Concatenated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b7768-6878-4171-9892-b043c24ce429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit data on full concatenated spiking data\n",
    "zconc_pca = []\n",
    "for irec in tqdm(range(nrecs)):\n",
    "    zconc_pca.append(PCA().fit(zconc_spikes_smooth[irec][:,stable_unit_idx[irec]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44dd719-6bd3-4cc0-8d23-36f258ef0876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot all full single trial trajectories\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in tqdm(range(nrecs)):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[:,0], temp_proj_trial[:,1], color=colors[temp_target_labels[itrial]], linewidth=0.1)\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0aaad3-9120-4a34-be7a-362e61bf529b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot points at target onset\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    temp_pt_idxs = np.array(df['delay_start_neural_idx'][(df['date']==dates[irec])*df['good_trial']]).astype(int)\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[temp_pt_idxs[itrial],0], temp_proj_trial[temp_pt_idxs[itrial],1],'.', color=colors[temp_target_labels[itrial]])\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot points at target onset\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    temp_pt_idxs = np.array(df['delay_start_neural_idx'][(df['date']==dates[irec])*df['good_trial']]).astype(int)\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[temp_pt_idxs[itrial],1], temp_proj_trial[temp_pt_idxs[itrial],2],'.', color=colors[temp_target_labels[itrial]])\n",
    "        ax[irec].set(xlabel='PC2', ylabel='PC3', title=f\"Site: {recording_site[irec]}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be73f3-881a-4cb9-b1ec-e1044dc19e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:03:19.237772Z",
     "start_time": "2024-05-03T16:03:18.022199Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot points at go cue\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    temp_pt_idxs = np.array(df['go_cue_neural_idx'][(df['date']==dates[irec])*df['good_trial']]).astype(int)\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[temp_pt_idxs[itrial],0], temp_proj_trial[temp_pt_idxs[itrial],1],'.', color=colors[temp_target_labels[itrial]])\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d3bba-d729-44a4-8ca9-3a6d4cbfb01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot points at movement onset\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    temp_pt_idxs = np.array(df['mov_onset_neural_idx'][(df['date']==dates[irec])*df['good_trial']]).astype(int)\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        \n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[temp_pt_idxs[itrial],0], temp_proj_trial[temp_pt_idxs[itrial],1],'.', color=colors[temp_target_labels[itrial]])\n",
    "        ax[irec].set(xlabel='PC1', ylabel='PC2', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,nrecs, figsize=(nrecs*4,4))\n",
    "for irec in range(nrecs):\n",
    "    temp_target_labels = np.array(df['target_idx'][(df['date']==dates[irec])*df['good_trial']])\n",
    "    temp_pt_idxs = np.array(df['mov_onset_neural_idx'][(df['date']==dates[irec])*df['good_trial']]).astype(int)\n",
    "    for itrial in range(len(temp_target_labels)):\n",
    "        \n",
    "        temp_proj_trial = zconc_pca[irec].transform(zconc_spikes_trial_sep[irec][itrial][:,stable_unit_idx[irec]])\n",
    "        ax[irec].plot(temp_proj_trial[temp_pt_idxs[itrial],1], temp_proj_trial[temp_pt_idxs[itrial],2],'.', color=colors[temp_target_labels[itrial]])\n",
    "        ax[irec].set(xlabel='PC2', ylabel='PC3', title=f\"Site: {recording_site[irec]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3252113-5579-4c08-8223-45495fcea0a6",
   "metadata": {},
   "source": [
    "## Subspace alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795e3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_CCA(La, Lb):\n",
    "    '''\n",
    "    Implemented as described in Gallego 2020 (10.1038/s41593-019-0555-4)\n",
    "    Args:\n",
    "        La (ntime, nfeature): Latent dynamics from data A\n",
    "        Lb (ntime, nfeature): Latent dynamics from data B\n",
    "    '''\n",
    "    # Compute Qr decomp to extract the orthonormal basis for the column vectors in the latent dynamics\n",
    "    Qa, Ra = np.linalg.qr(La)\n",
    "    Qb, Rb = np.linalg.qr(Lb)\n",
    "\n",
    "    # Take inner product and perform SVD to get new manifold directions and correlations (S provdes the correlations)\n",
    "    U, S, V = np.linalg.svd(Qa.T @ Qb)\n",
    "\n",
    "    # Compute new manifold directions (Ma, Mb)\n",
    "    Ma = np.linalg.pinv(Ra) @ U\n",
    "    Mb = np.linalg.pinv(Rb) @ V\n",
    "\n",
    "    return Ma, Mb, S\n",
    "\n",
    "def calc_task_rel_dims(neural_data, kin_data, conc_proj_data=False, regularization=None, alpha=1):\n",
    "    '''\n",
    "    Calculates the task relevant dimensions by regressing neural activity against kinematic data using least squares.\n",
    "    If the input neural data is 3D, all trials will be concatenated to calculate the subspace. \n",
    "    Calculation is based on the approach used in Sun et al. 2022 https://doi.org/10.1038/s41586-021-04329-x\n",
    "    \n",
    "    .. math::\n",
    "    \n",
    "        R \\\\in \\\\mathbb{R}^{nt \\\\times nch}\n",
    "        M \\\\in \\\\mathbb{R}^{nt \\\\times nkin}\n",
    "        \\\\beta \\\\in \\\\mathbb{R}^{nch \\\\times nkin}\n",
    "        R = M\\\\beta^T\n",
    "        [\\\\beta_0 \\beta_x \\beta_y]^T = (M^T M)^{-1} M^T R\n",
    "\n",
    "    Args:\n",
    "        neural_data ((nt, nch) or list of (nt, nch)): Input neural data (:math:`R`) to regress against kinematic activity.\n",
    "        kin_data ((nt, ndim) or list of (nt, ndim)): Kinematic variables (:math:`M`), commonly position or instantaneous velocity. 'ndims' refers to the number of physical dimensions that define the kinematic data (i.e. X and Y)\n",
    "        conc_proj_data (bool): If the projected neural data should be concatenated.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing:\n",
    "            | **(nch, ndim):** Subspace (:math:`\\beta`) that best predicts kinematic variables. Note the first column represents the intercept, then the next dimensions represent the behvaioral variables\n",
    "            | **((nt, nch) or list of (nt, ndim)):** Neural data projected onto task relevant subspace\n",
    "\n",
    "    '''\n",
    "\n",
    "    # If a list of segments from trials, concatenate them into one larget timeseries\n",
    "    if type(neural_data) == list:\n",
    "        ntrials = len(neural_data)\n",
    "        min_time_per_trial = [np.min([len(neural_data[itrial]), len(kin_data[itrial])]) for itrial in range(ntrials)]\n",
    "        \n",
    "        conc_neural_data = np.vstack([neural_data[itrial][:min_time_per_trial[itrial]] for itrial in range(ntrials)]) #(nt, nch)\n",
    "        conc_kin_data_baseline = np.vstack([kin_data[itrial][:min_time_per_trial[itrial]] for itrial in range(ntrials)])\n",
    "        if conc_neural_data.shape[0] != conc_kin_data_baseline.shape[0]:\n",
    "            print(f\"Neural and kinematic data sizes are {np.abs(conc_neural_data.shape[0]-conc_kin_data_baseline.shape[0])} samples apart\")\n",
    "        \n",
    "        ntime = np.min([conc_neural_data.shape[0], conc_kin_data_baseline.shape[0]])\n",
    "        \n",
    "        # Set input neural data as a float\n",
    "        conc_neural_data = conc_neural_data.astype(float)[:ntime,:]\n",
    "\n",
    "        conc_kin_data = np.ones((ntime,kin_data[0].shape[1]+1))*np.nan\n",
    "        conc_kin_data[:,0] = 1\n",
    "        conc_kin_data[:,1:] = conc_kin_data_baseline\n",
    "\n",
    "        # Center neural data:\n",
    "        conc_neural_data -= np.nanmean(conc_neural_data, axis=0)\n",
    "\n",
    "        # Calculate task relevant subspace \n",
    "        # task_subspace = np.linalg.pinv(conc_kin_data.T @ conc_kin_data) @ conc_kin_data.T @ conc_neural_data\n",
    "        if regularization is None:        \n",
    "            # task_subspace = np.linalg.pinv(conc_neural_data.T @ conc_neural_data) @ conc_neural_data.T @ conc_kin_data\n",
    "            lin_reg_model = sklearn.linear_model.LinearRegression(fit_intercept=False).fit(conc_neural_data, conc_kin_data)\n",
    "            task_subspace = (lin_reg_model.coef_).T\n",
    "        elif regularization == 'lasso':\n",
    "            lasso_model = sklearn.linear_model.Lasso(alpha=alpha, max_iter=10000).fit(conc_neural_data, conc_kin_data)\n",
    "            task_subspace = (lasso_model.coef_).T\n",
    "        elif regularization == 'ridge':\n",
    "            ridge_model = sklearn.linear_model.Ridge(alpha=alpha, max_iter=10000).fit(conc_neural_data, conc_kin_data)\n",
    "            task_subspace = (ridge_model.coef_).T\n",
    "        elif regularization == 'elastic net':\n",
    "            elasticnet_model = sklearn.linear_model.ElasticNet(alpha=alpha, max_iter=10000).fit(conc_neural_data, conc_kin_data)\n",
    "            task_subspace = (elasticnet_model.coef_).T\n",
    "    \n",
    "    else:\n",
    "        # Save original neural data as a list\n",
    "        neural_data = [neural_data]\n",
    "        \n",
    "        # Set input neural data as a float\n",
    "        neural_data_centered = neural_data[0].astype(float)\n",
    "        \n",
    "        # Center neural data:\n",
    "        neural_data_centered -= np.nanmean(neural_data_centered, axis=0)\n",
    "        ntime = neural_data_centered.shape[0]\n",
    "        conc_kin_data = np.ones((ntime, kin_data.shape[1]+1))*np.nan\n",
    "        conc_kin_data[:,0] = 1\n",
    "        conc_kin_data[:,1:] = kin_data\n",
    "        \n",
    "        # Calculate task relevant subspace \n",
    "        if regularization is None:\n",
    "            task_subspace = np.linalg.pinv(neural_data_centered.T @ neural_data_centered) @ neural_data_centered.T @ conc_kin_data\n",
    "        elif regularization == 'lasso':\n",
    "            lasso_model = sklearn.linear_model.Lasso(alpha=alpha, max_iter=10000).fit(neural_data_centered, conc_kin_data)\n",
    "            task_subspace = (lasso_model.coef_).T\n",
    "        elif regularization == 'ridge':\n",
    "            ridge_model = sklearn.linear_model.Ridge(alpha=alpha, max_iter=10000).fit(neural_data_centered, conc_kin_data)\n",
    "            task_subspace = (ridge_model.coef_).T\n",
    "        elif regularization == 'elastic net':\n",
    "            elasticnet_model = sklearn.linear_model.ElasticNet(alpha=alpha, max_iter=10000).fit(neural_data_centered, conc_kin_data)\n",
    "            task_subspace = (elasticnet_model.coef_).T\n",
    "        ntrials = 1\n",
    "        \n",
    "    # Project neural data onto task subspace\n",
    "    projected_data = []\n",
    "    \n",
    "    for itrial in range(ntrials):\n",
    "        projected_data.append(neural_data[itrial] @ task_subspace)\n",
    "\n",
    "    if conc_proj_data:\n",
    "        return task_subspace, np.vstack(projected_data)\n",
    "    else:    \n",
    "        return task_subspace, projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71981c1e-e7d7-4e1e-b23e-57cf711f8e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tavg_time = .5 #[s]\n",
    "# neural_onset_idx_labels = ['delay_start_neural_idx', 'go_cue_neural_idx', 'mov_onset_neural_idx']\n",
    "# kin_onset_idx_labels = ['delay_start_kin_idx', 'go_cue_kin_idx', 'mov_onset_kin_idx']\n",
    "neural_onset_idx_labels = 'mov_onset_neural_idx'\n",
    "kin_onset_idx_labels = 'mov_onset_kin_idx'\n",
    "\n",
    "\n",
    "for idate, date in enumerate(tqdm(dates)):\n",
    "    neural_idx_start = int(preproc_metadata['tbefore']*preproc_metadata['neural_samplerate'])\n",
    "    neural_idx_stop = int((tavg_time*preproc_metadata['neural_samplerate'])) + neural_idx_start        \n",
    "    neural_data = rasters['neural'][align_event][idate][neural_idx_start:neural_idx_stop,np.array(df['good_trial'][df['date']==date])][:,:,stable_unit_idx[idate]]\n",
    "\n",
    "    kin_idx_start = int(preproc_metadata['tbefore']*preproc_metadata['kin_samplerate'])\n",
    "    kin_idx_stop = int((tavg_time*preproc_metadata['kin_samplerate'])) + kin_idx_start\n",
    "    kin_data = rasters['cursor_velo'][align_event][idate][kin_idx_start:kin_idx_stop,np.array(df['good_trial'][df['date']==date])]\n",
    "    hand_data = rasters['hand_velo'][align_event][idate][kin_idx_start:kin_idx_stop,np.array(df['good_trial'][df['date']==date])]\n",
    "\n",
    "    # test = calc_task_rel_dims(neural_data, kin_data, conc_proj_data=False, regularization=None, alpha=1)\n",
    "    # scores, test_move_tavg, test_pred_move_tavg, subspace =  xval_task_rel_dims(neural_data, kin_data, labels=np.array(df['target_idx'][(df['date']==date)*df['good_trial']])  ,regularization=None, nfolds=4, alpha=1, smooth_neural_data=False, tavg_neural_data=False, return_test_label_idx=False)\n",
    "    # scores_hand, test_move_tavg_hand, test_pred_move_tavg_hand, subspace_hand, test_label_idx_hand =  xval_task_rel_dims(neural_data, hand_data, labels=np.array(df['target_idx'][(df['date']==date)*df['good_trial']])  ,regularization=None, nfolds=4, alpha=1, smooth_neural_data=False, tavg_neural_data=True, return_test_label_idx=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a4309-a941-4ddf-988b-770dad56e89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(neural_data.shape)\n",
    "# print(kin_data.shape)\n",
    "# print(len(test_pred_move_tavg))\n",
    "# print(test_pred_move_tavg[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b5ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute CCs the same way as Gallego paper\n",
    "proj_data = []\n",
    "proj_trd_data = []\n",
    "centered_data = []\n",
    "# for irec in range(nrecs):\n",
    "for idate, date in enumerate(tqdm(dates)):\n",
    "    prep_data = smooth_timeseries_gaus(np.sqrt(np.vstack(frs[align_event]['align_spikes_dwns'][idate]) + 0.375), new_bin_fs, 150) \n",
    "    proj_data.append(PCA().fit_transform(prep_data))\n",
    "    # centered_prep_data = (prep_data.reshape(frs[align_event]['align_spikes_dwns'][irec].shape) - np.mean(prep_data.reshape(frs[align_event]['align_spikes_dwns'][irec].shape), axis=(0,1)))/np.std(prep_data.reshape(frs[align_event]['align_spikes_dwns'][irec].shape), axis=(0,1))\n",
    "    # centered_data.append(PCA().fit_transform(smooth_timeseries_gaus(np.sqrt(np.vstack(centered_prep_data) + 0.375), new_bin_fs, 150) ))\n",
    "    \n",
    "    \n",
    "    neural_idx_start = int(preproc_metadata['tbefore']*preproc_metadata['neural_samplerate'])\n",
    "    neural_idx_stop = int((tavg_time*preproc_metadata['neural_samplerate'])) + neural_idx_start        \n",
    "    neural_data = rasters['neural'][align_event][idate][neural_idx_start:neural_idx_stop,np.array(df['good_trial'][df['date']==date])][:,:,stable_unit_idx[idate]]\n",
    "\n",
    "    kin_idx_start = int(preproc_metadata['tbefore']*preproc_metadata['kin_samplerate'])\n",
    "    kin_idx_stop = int((tavg_time*preproc_metadata['kin_samplerate'])) + kin_idx_start\n",
    "    kin_data = rasters['cursor_velo'][align_event][idate][kin_idx_start:kin_idx_stop,np.array(df['good_trial'][df['date']==date])]\n",
    "    hand_data = rasters['hand_velo'][align_event][idate][kin_idx_start:kin_idx_stop,np.array(df['good_trial'][df['date']==date])]\n",
    "\n",
    "    proj_trd_data.append(calc_task_rel_dims(prep_data, np.vstack(kin_data)[::10,:], conc_proj_data=False, regularization=None, alpha=1)[1][0])\n",
    "    # proj_trd_data.append(calc_task_rel_dims(prep_data, kin_data, conc_proj_data=False, regularization=None, alpha=1)[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cad2b-80cd-4cb8-9105-5f3e5fb06c10",
   "metadata": {},
   "source": [
    "### PC projection alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734bbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_site_M1 = [isite for isite in recording_site if isite in recording_brain_areas['M1']]\n",
    "recording_site_PM = [isite for isite in recording_site if isite in recording_brain_areas['PM']]\n",
    "nrecs_M1 = len(recording_site_M1)\n",
    "nrecs_PM = len(recording_site_PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f1c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npcs = 3\n",
    "ccs = np.zeros((nrecs, nrecs, npcs))*np.nan\n",
    "ccs_trd = np.zeros((nrecs, nrecs, npcs))*np.nan\n",
    "np_acc_arg_sort = np.argsort(max_np_decoding)\n",
    "# np_acc_arg_sort = np.arange(nrecs)\n",
    "for irec in tqdm(range(nrecs)):\n",
    "    for irec2 in range(nrecs):\n",
    "        # if proj_data[irec].shape[1] >= 5 and proj_data[irec2].shape[1] >=5:\n",
    "        for ipc in range(npcs):\n",
    "            # Ma, Mb, S = compute_CCA(np.vstack(np.swapaxes(rotations[np_acc_arg_sort[irec]][1], 1,2)), np.vstack(np.swapaxes(rotations[np_acc_arg_sort[irec2]][1], 1,2)))\n",
    "            Ma, Mb, S = compute_CCA(proj_data[irec], proj_data[irec2])\n",
    "            ccs[irec,irec2,:] =S[:npcs]\n",
    "            \n",
    "            Ma_trd, Mb_trd, S_trd = compute_CCA(proj_trd_data[irec], proj_trd_data[irec2])\n",
    "            ccs_trd[irec,irec2,:] =S_trd[:npcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de1659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*9, 5.5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs[:,:,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, recording_site)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site)\n",
    "    ax[ipc].set(xlabel='Recording Site', ylabel='Recording Site', title=f\"CC: {ipc+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bf392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*6, 5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs[np_acc_arg_sort,:,:][:,np_acc_arg_sort,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, recording_site[np_acc_arg_sort], rotation = 90)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, np.round(np.array(max_np_decoding)[np_acc_arg_sort], 2))\n",
    "    ax[ipc].set(xlabel='Neuropixel Decoding', ylabel='Neuropixel Decoding', title=f\"CC: {ipc+1}\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173937c6-bbd6-44d1-bb1c-1401ea1c90b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by caudal to rostral\n",
    "cr_sort = np.argsort(ecog_dec_acc[subject]['rc_axis'][:,0])\n",
    "# cr_sort = cr_sort[np.logical_and(cr_sort != 0, cr_sort!=3)]\n",
    "fig, ax = plt.subplots(1, npcs, figsize=(16.,5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs[cr_sort,:,:][:,cr_sort,ipc], vmin=0, vmax=1)\n",
    "    \n",
    "    # ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort], rotation = 30)\n",
    "    ax[ipc].set_xticks(np.arange(len(cr_sort), step=2)+0.5, np.round(ecog_dec_acc[subject]['rc_axis'][:,0][cr_sort][::2], 1), rotation = 90)\n",
    "    # ax[ipc].set_xticks(np.arange(len(cr_sort), step=2)+0.5, np.arange(np.sum(mask),step=2)+1)\n",
    "    ax[ipc].set_yticks([],[])\n",
    "    ax[ipc].set(xlabel='Site X-pos [mm]',  title=f\"Mode {ipc+1}\")\n",
    "    ax[ipc].set_aspect('equal')\n",
    "    \n",
    "    if ipc == 0:\n",
    "        ax[ipc].set_ylabel('Site X-pos [mm]')\n",
    "        # ax[ipc].set_yticks(np.arange(np.sum(mask), step=2)+0.5, np.arange(np.sum(mask), step=2)+1)\n",
    "        # ax[ipc].set_yticks(np.arange(len(cr_sort),step=2)+0.5, np.round(ecog_dec_acc[subject]['rc_axis'][:,0][cr_sort][::2], 1))\n",
    "        ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort])\n",
    "    elif ipc == npcs-1:\n",
    "        cb = plt.colorbar(im)    \n",
    "    \n",
    "fig.tight_layout()\n",
    "aopy.visualization.savefig(base_save_dir, f'cc_rostral_caudal.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79441507-db18-4287-94a0-78e6fb13e5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot spatial map of decoding\n",
    "# ref_site = 107\n",
    "ref_site = 98\n",
    "ref_site_idx = np.where(recording_site==ref_site)[0]\n",
    "fig, ax = plt.subplots(1,npcs,figsize=(16,5))\n",
    "for ipc in range(npcs):\n",
    "    colors = ccs[:,ref_site_idx,ipc]\n",
    "    dec_map = ax[ipc].scatter(ecog_dec_acc[subject]['rec_locations'][:,0], ecog_dec_acc[subject]['rec_locations'][:,1], s=100, c=colors, cmap='YlGnBu', vmin=0.2, vmax=.8)\n",
    "    cb = plt.colorbar(dec_map)\n",
    "    ax[ipc].set(xlim=(-6,6), ylim=(-6,6), title=f\"CC {ipc+1}\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a14223-e5b8-4a43-97ab-21859e313ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by medial to lateral\n",
    "cr_sort = np.argsort(ecog_dec_acc[subject]['rc_axis'][:,1])\n",
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*5, 3.5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs[cr_sort,:,:][:,cr_sort,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort], rotation = 30)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, np.round(ecog_dec_acc['beignet']['rec_locations'][:,1][cr_sort], 2), rotation = 60)\n",
    "    ax[ipc].set(xlabel='Medial - Lateral Position', ylabel='Recording Site Number', title=f\"PC: {ipc+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193602c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "for ipc in range(npcs):\n",
    "    ccs_plt = ccs[:,:,ipc]\n",
    "    ax.plot(np.flip(np.sort(ccs_plt[ccs_plt<0.999].flatten())))\n",
    "\n",
    "ax.set(xlabel='Recording Pair', ylabel='CC', ylim=(0,1))\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.legend([f\"CC{ipc+1}\" for ipc in range(npcs)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b05d0-d5ae-4997-ba34-5c9b33e29470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,npcs,figsize=(3*npcs,3))\n",
    "pos_diff = np.zeros((ccs.shape[0], ccs.shape[1]))*np.nan\n",
    "pos_labels = np.zeros((ccs.shape[0], ccs.shape[1],2))*np.nan\n",
    "for irec1 in range(ccs.shape[0]):\n",
    "    for irec2 in range(ccs.shape[1]):\n",
    "        if irec1 != irec2:\n",
    "            pos_diff[irec1,irec2] = np.abs(ecog_dec_acc['beignet']['rec_locations'][irec1,0] - ecog_dec_acc['beignet']['rec_locations'][irec2,0])\n",
    "            pos_labels[irec1,irec2,0] = irec1\n",
    "            pos_labels[irec1,irec2,1] = irec2\n",
    "slopes = []\n",
    "intercepts = []\n",
    "for ipc in range(npcs):\n",
    "    nan_mask = ~np.isnan(pos_diff.flatten())\n",
    "    fit, fitscore, pcc, pval, regfit = aopy.analysis.base.linear_fit_analysis2D(pos_diff.flatten()[nan_mask], ccs[:,:,ipc].flatten()[nan_mask])\n",
    "    intercept = regfit.intercept_\n",
    "    intercepts.append(intercept)\n",
    "    slope = regfit.coef_[0]\n",
    "    slopes.append(slope)\n",
    "    ax[ipc].plot(pos_diff.flatten(), ccs[:,:,ipc].flatten(),'.')\n",
    "    ax[ipc].plot([0,10], [intercept, slope*10 + intercept], 'k')\n",
    "    ax[ipc].set(xlabel='$\\Delta$ Rostral - Caudal Position', ylabel='Correlation', title=f\"CC{ipc} p={np.round(pval,3)}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea33e7-396b-4fcd-b52e-0c7bb0a4d478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# recording_site[8], recording_site[14]\n",
    "# print(ecog_dec_acc['beignet']['rec_locations'][8,0], ecog_dec_acc['beignet']['rec_locations'][11,0])\n",
    "# ecog_dec_acc['beignet']['rec_locations'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27760482-1df3-4047-8919-ca3d63b14cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(pos_labels[:,:,0].flatten())\n",
    "# print(pos_labels[:,:,1].flatten())\n",
    "# print(dec_diff.flatten())\n",
    "# # print(ccs[:,:,0].flatten())\n",
    "# ipt = 1\n",
    "# print(pos_labels[:,:,0].flatten()[ipt] == 0, pos_labels[:,:,1].flatten()[ipt]==1)\n",
    "# print(pos_labels[:,:,0].flatten()[ipt] == 0 and pos_labels[:,:,1].flatten()[ipt] == 1)\n",
    "# dec_diff*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0bd6b-7248-4042-b16a-1d2ecf4f2a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,npcs,figsize=(12.5,5))\n",
    "dec_diff = np.zeros((ccs.shape[0], ccs.shape[1]))*np.nan\n",
    "for irec1 in range(ccs.shape[0]):\n",
    "    for irec2 in range(ccs.shape[1]):\n",
    "        if irec1 != 0 and irec2 != 0 and irec1 != 3 and irec2 != 3 and irec1 != irec2:\n",
    "            # if irec1 != 3 and irec2 != 3:\n",
    "            dec_diff[irec1,irec2] = np.abs(max_np_decoding[irec1] - max_np_decoding[irec2]) \n",
    "\n",
    "rec1 = 8\n",
    "rec2 = 11\n",
    "            \n",
    "for ipc in range(npcs):\n",
    "    # ax[ipc].plot(100*dec_diff.flatten(), ccs[:,:,ipc].flatten(),'k.', markersize=10)\n",
    "    # dec_diff_map = ax[ipc].scatter(100*dec_diff.flatten(), ccs[:,:,ipc].flatten(),s=50, c=(0.75, 0.75, 0.75))\n",
    "    dec_diff_map = ax[ipc].scatter(100*dec_diff.flatten(), ccs[:,:,ipc].flatten(),s=50, c='black')\n",
    "    for ipt in range(len(dec_diff.flatten())):\n",
    "        if pos_labels[:,:,0].flatten()[ipt] == rec1 and pos_labels[:,:,1].flatten()[ipt] == rec2:\n",
    "            # print(100*dec_diff.flatten()[ipt], ccs[:,:,ipc].flatten()[ipt])\n",
    "            dec_diff_map = ax[ipc].scatter(100*dec_diff.flatten()[ipt], ccs[:,:,ipc].flatten()[ipt],s=50, c='black')\n",
    "    \n",
    "    nan_mask = ~np.isnan(dec_diff.flatten())\n",
    "    fit, fitscore, pcc, pval, regfit = aopy.analysis.base.linear_fit_analysis2D(100*dec_diff.flatten()[nan_mask], ccs[:,:,ipc].flatten()[nan_mask])\n",
    "    intercept = regfit.intercept_\n",
    "    # intercepts.append(intercept)\n",
    "    slope = regfit.coef_[0]\n",
    "    # slopes.append(slope)\n",
    "    print(pval)\n",
    "    ax[ipc].plot([0,10], [intercept, slope*10 + intercept], color=(0.5, 0.5, 0.5))\n",
    "\n",
    "    ax[ipc].set_yticks([])\n",
    "    ax[ipc].set(title=f\"Mode {ipc+1}\", ylim=(0,1.05))\n",
    "    if ipc == 0:\n",
    "        ax[ipc].set_yticks([0,.5,1])\n",
    "        ax[ipc].set(ylabel='Correlation')\n",
    "    if ipc == 1:\n",
    "        ax[ipc].set(xlabel='Decoding Difference [%]')\n",
    "    # elif ipc == npcs-1:\n",
    "    #     cb = plt.colorbar(dec_diff_map, label='X-Position \\n Difference [mm]')\n",
    "fig.tight_layout()\n",
    "aopy.visualization.savefig(base_save_dir, f'cca_cc_delta_dec.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274dedf-aae0-4c4f-a366-8f88950d1f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,npcs,figsize=(15,5))\n",
    "dec_diff = np.zeros((ccs.shape[0], ccs.shape[1]))*np.nan\n",
    "for irec1 in range(ccs.shape[0]):\n",
    "    for irec2 in range(ccs.shape[1]):\n",
    "        if irec1 != 0 and irec2 != 0 and irec1 != 3 and irec2 != 3 and irec1 != irec2:\n",
    "            # if irec1 != 3 and irec2 != 3:\n",
    "            dec_diff[irec1,irec2] = np.abs(max_np_decoding[irec1] - max_np_decoding[irec2]) \n",
    "\n",
    "for ipc in range(npcs):\n",
    "    # ax[ipc].plot(100*dec_diff.flatten(), ccs[:,:,ipc].flatten(),'k.', markersize=10)\n",
    "    dec_diff_map = ax[ipc].scatter(100*dec_diff.flatten(), ccs[:,:,ipc].flatten(),s=50, c=pos_diff.flatten(), cmap='plasma')\n",
    "    cb = plt.colorbar(dec_diff_map, label='Pos Diff')\n",
    "    ax[ipc].set_yticks([])\n",
    "    ax[ipc].set(xlabel='Decoding \\n Difference [%]', title=f\"CC{ipc+1}\", ylim=(0,1.05))\n",
    "    if ipc == 0:\n",
    "        ax[ipc].set_yticks([0,.5,1])\n",
    "        ax[ipc].set(ylabel='Correlation')\n",
    "        \n",
    "    # elif ipc == npcs-1:\n",
    "    #     cb = plt.colorbar(dec_diff_map, label='X-Position \\n Difference [mm]')\n",
    "fig.tight_layout()\n",
    "aopy.visualization.savefig(base_save_dir, f'cca_cc_delta_dec_colored.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35456c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract ccs for sites within each brain area\n",
    "site_mask_M1 = np.isin(recording_site, recording_brain_areas['M1'])\n",
    "site_mask_PM = np.isin(recording_site, recording_brain_areas['PM'])\n",
    "\n",
    "fig, ax = plt.subplots(3, npcs, figsize=(npcs*4, 9))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[0,ipc].pcolor(ccs[site_mask_M1, :,ipc][:,site_mask_M1])\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[0,ipc].set_xticks(np.arange(np.sum(site_mask_M1))+0.5, recording_site[site_mask_M1])\n",
    "    ax[0,ipc].set_yticks(np.arange(np.sum(site_mask_M1))+0.5, recording_site[site_mask_M1])\n",
    "    ax[0,ipc].set(xlabel='Recording Site', ylabel='Recording Site', title=f\"M1 Sites PC: {ipc+1}\")\n",
    "\n",
    "    im = ax[1,ipc].pcolor(ccs[site_mask_PM, :,ipc][:,site_mask_PM])\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[1,ipc].set_xticks(np.arange(np.sum(site_mask_PM))+0.5, recording_site[site_mask_PM])\n",
    "    ax[1,ipc].set_yticks(np.arange(np.sum(site_mask_PM))+0.5, recording_site[site_mask_PM])\n",
    "    ax[1,ipc].set(xlabel='Recording Site', ylabel='Recording Site', title=f\"PM Sites PC: {ipc+1}\")\n",
    "\n",
    "    im = ax[2,ipc].pcolor(ccs[site_mask_M1, :,ipc][:,site_mask_PM])\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[2,ipc].set_xticks(np.arange(np.sum(site_mask_PM))+0.5, recording_site[site_mask_PM])\n",
    "    ax[2,ipc].set_yticks(np.arange(np.sum(site_mask_M1))+0.5, recording_site[site_mask_M1])\n",
    "    ax[2,ipc].set(xlabel='Recording Site PM', ylabel='Recording Site M1', title=f\"Cross Area PC: {ipc+1}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99133243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project trials onto shared PCs. Compare targeted pairs\n",
    "fig, ax = plt.subplots(1,6, figsize=(20,3))\n",
    "ntargets = np.array(rotations[0][0]).shape[2]\n",
    "smooth_width = 300\n",
    "\n",
    "# Compare site 11 and 45\n",
    "irec1 = np.where(recording_site==98)[0][0]\n",
    "irec2 = np.where(recording_site==45)[0][0]\n",
    "# Ma, Mb, S = compute_CCA(np.vstack(np.swapaxes(rotations[irec1][1], 1,2)).T, np.vstack(np.swapaxes(rotations[irec2][1], 1,2)).T)\n",
    "Ma, Mb, S = compute_CCA(proj_data[irec1], proj_data[irec2])\n",
    "site1_proj_all = []\n",
    "site2_proj_all = []\n",
    "for itarget in range(ntargets):\n",
    "    # site1_proj = np.array(rotations[irec1][0])[:,:,itarget] @ Ma\n",
    "    # site2_proj = np.array(rotations[irec2][0])[:,:,itarget] @ Mb\n",
    "    temp_target_labels1 = np.array(df['target_idx'][df['good_trial']*(df['date']==dates[irec1])])\n",
    "    temp_target_labels2 = np.array(df['target_idx'][df['good_trial']*(df['date']==dates[irec2])])\n",
    "    site1_proj = np.mean(centered_data[irec1][:,temp_target_labels1==(itarget+1),:], axis=1) @ Ma\n",
    "    site2_proj = np.mean(centered_data[irec2][:,temp_target_labels2==(itarget+1),:], axis=1) @ Mb\n",
    "    site1_proj_all.append(site1_proj)\n",
    "    site2_proj_all.append(site2_proj)\n",
    "    # smooth_timeseries_gaus(rotations[irec][0][:,0,icond], new_bin_fs_rot, smooth_width)\n",
    "    \n",
    "    \n",
    "centered_cc1_site1 = np.array(site1_proj_all)[:,:,0] - np.mean(np.array(site1_proj_all)[:,:,0], axis=0)\n",
    "centered_cc2_site1 = np.array(site1_proj_all)[:,:,1] - np.mean(np.array(site1_proj_all)[:,:,1], axis=0)\n",
    "centered_cc1_site2 = np.array(site2_proj_all)[:,:,0] - np.mean(np.array(site2_proj_all)[:,:,0], axis=0)\n",
    "centered_cc2_site2 = np.array(site2_proj_all)[:,:,1] - np.mean(np.array(site2_proj_all)[:,:,1], axis=0)\n",
    "# ax[0].plot(smooth_timeseries_gaus(site1_proj[:,0], new_bin_fs, smooth_width), smooth_timeseries_gaus(site1_proj[:,1], new_bin_fs, smooth_width), color=colors[itarget])\n",
    "# ax[0].plot(smooth_timeseries_gaus(site2_proj[:,0], new_bin_fs, smooth_width), smooth_timeseries_gaus(site2_proj[:,1], new_bin_fs, smooth_width), '--', color=colors[itarget])\n",
    "for itarget in range(ntargets):\n",
    "    ax[0].plot(smooth_timeseries_gaus(centered_cc1_site1[itarget,:], new_bin_fs, smooth_width), smooth_timeseries_gaus(centered_cc2_site1[itarget,:], new_bin_fs, smooth_width), color=colors[itarget])\n",
    "    ax[1].plot(smooth_timeseries_gaus(centered_cc1_site2[itarget,:], new_bin_fs, smooth_width), smooth_timeseries_gaus(centered_cc2_site2[itarget,:], new_bin_fs, smooth_width), '--', color=colors[itarget])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ac962-e7e7-4432-9e7c-8a88efdf6704",
   "metadata": {},
   "source": [
    "### TRD projection alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a05d4-0bf0-40b5-bc62-c0fab717b9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*9, 5.5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs_trd[:,:,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, recording_site)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site)\n",
    "    ax[ipc].set(xlabel='Recording Site', ylabel='Recording Site', title=f\"CC: {ipc+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb05ef8-21d4-4e47-8847-b60cc827e346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*6, 5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs_trd[np_acc_arg_sort,:,:][:,np_acc_arg_sort,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, recording_site[np_acc_arg_sort], rotation = 90)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, np.round(np.array(max_np_decoding)[np_acc_arg_sort], 2))\n",
    "    ax[ipc].set(xlabel='Neuropixel Decoding', ylabel='Neuropixel Decoding')\n",
    "    \n",
    "ax[0].set_title('Intercept'), ax[1].set_title('X-position'), ax[2].set_title('Y-position')\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01b550-5bf2-4c89-8d9c-83514c21de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by caudal to rostral\n",
    "cr_sort = np.argsort(ecog_dec_acc[subject]['rc_axis'][:,0])\n",
    "# cr_sort = cr_sort[np.logical_and(cr_sort != 0, cr_sort!=3)]\n",
    "fig, ax = plt.subplots(1, npcs, figsize=(16.,5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs_trd[cr_sort,:,:][:,cr_sort,ipc], vmin=0, vmax=1)\n",
    "    \n",
    "    # ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort], rotation = 30)\n",
    "    ax[ipc].set_xticks(np.arange(len(cr_sort), step=2)+0.5, np.round(ecog_dec_acc[subject]['rc_axis'][:,0][cr_sort][::2], 1), rotation = 90)\n",
    "    # ax[ipc].set_xticks(np.arange(len(cr_sort), step=2)+0.5, np.arange(np.sum(mask),step=2)+1)\n",
    "    ax[ipc].set_yticks([],[])\n",
    "    ax[ipc].set(xlabel='Site X-pos [mm]')\n",
    "    ax[ipc].set_aspect('equal')\n",
    "    \n",
    "    if ipc == 0:\n",
    "        ax[ipc].set_ylabel('Site X-pos [mm]')\n",
    "        # ax[ipc].set_yticks(np.arange(np.sum(mask), step=2)+0.5, np.arange(np.sum(mask), step=2)+1)\n",
    "        # ax[ipc].set_yticks(np.arange(len(cr_sort),step=2)+0.5, np.round(ecog_dec_acc[subject]['rc_axis'][:,0][cr_sort][::2], 1))\n",
    "        ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort])\n",
    "    elif ipc == npcs-1:\n",
    "        cb = plt.colorbar(im)    \n",
    "ax[0].set_title('Intercept'), ax[1].set_title('X-position'), ax[2].set_title('Y-position')\n",
    "        \n",
    "fig.tight_layout()\n",
    "# aopy.visualization.savefig(base_save_dir, f'cc_rostral_caudal.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc5353-5d40-4eb2-8eb4-65047e45b172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort by medial to lateral\n",
    "cr_sort = np.argsort(ecog_dec_acc[subject]['rc_axis'][:,1])\n",
    "fig, ax = plt.subplots(1, npcs, figsize=(npcs*5, 3.5))\n",
    "for ipc in range(npcs):\n",
    "    im = ax[ipc].pcolor(ccs[cr_sort,:,:][:,cr_sort,ipc], vmin=0.1, vmax=1)\n",
    "    cb = plt.colorbar(im)\n",
    "    ax[ipc].set_yticks(np.arange(nrecs)+0.5, recording_site[cr_sort], rotation = 30)\n",
    "    ax[ipc].set_xticks(np.arange(nrecs)+0.5, np.round(ecog_dec_acc['beignet']['rec_locations'][:,1][cr_sort], 2), rotation = 60)\n",
    "    ax[ipc].set(xlabel='Medial - Lateral Position', ylabel='Recording Site Number', title=f\"PC: {ipc+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89783326-3512-45b4-a4ae-eb4739f31302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b66f5-22f8-4274-a4df-e180c4844fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a87d0d93",
   "metadata": {},
   "source": [
    "## Decoding in different PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114f9c1-5047-46e7-81b0-52fc3d95ae58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94d0c2-5bec-4849-bd40-194106fcf8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(site1_proj_all)[:,:,0].shape\n",
    "np.mean(np.array(site1_proj_all)[:,:,0], axis=0).shape\n",
    "np.mean(centered_cc1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9aa65-2ce8-4bc7-a509-8ae5744226d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc0eb3-aca3-4183-bde1-081eedd2046b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae03fda-1b0f-447b-8f9d-651f19241104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb0d0e-b834-4b73-b43c-2e8f993c203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5574be3-3e0e-4082-b468-313c6a2ac1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6428942-eeb0-4a07-9a21-7710f8db3f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad720b30-ca3d-4775-a582-d8042bd3c2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fd6dd-e38e-48d5-b243-8d6ef5e00337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb3b1a-d6d2-44d3-814d-28fa036a426b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b912995-aefb-42c8-bfd1-7dde6167b42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31950852-f541-4854-bf35-b5f4256e1087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b76f6-1943-490e-9ae7-a9a735dc9f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836782a7-d2e4-404b-8d7b-af4b3119f993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cd6f0-6c7a-425b-a36c-0f67bea391dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:np_targeting]",
   "language": "python",
   "name": "conda-env-np_targeting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
