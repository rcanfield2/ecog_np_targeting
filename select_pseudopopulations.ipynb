{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d446e86-44e7-4d8a-8212-5a22da47136f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_hdf_group(data_dir, hdf_filename, group=\"/\"):\n",
    "    '''\n",
    "    Loads any datasets from the given hdf group into a dictionary. Also will\n",
    "    recursively load other groups if any exist under the given group\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): folder where data is located\n",
    "        hdf_filename (str): name of hdf file\n",
    "        group (str): name of the group to load\n",
    "    \n",
    "    Returns:\n",
    "        dict: all the datasets contained in the given group\n",
    "    '''\n",
    "    full_file_name = os.path.join(data_dir, hdf_filename)\n",
    "    hdf = h5py.File(full_file_name, 'r')\n",
    "    if group not in hdf:\n",
    "        raise ValueError('No such group in file {}'.format(hdf_filename))\n",
    "\n",
    "    # Recursively load groups until datasets are reached\n",
    "    def _load_hdf_group(hdf):\n",
    "        keys = hdf.keys()\n",
    "        data = dict()\n",
    "        for k in keys:\n",
    "            if isinstance(hdf[k], h5py.Group):\n",
    "                data[k] = _load_hdf_group(hdf[k])\n",
    "            else:\n",
    "                k_, v = _load_hdf_dataset(hdf[k], k)\n",
    "                data[k_] = v\n",
    "        return data\n",
    "\n",
    "    data = _load_hdf_group(hdf[group])\n",
    "    hdf.close()\n",
    "    return data\n",
    "\n",
    "def _load_hdf_dataset(dataset, name):\n",
    "    '''\n",
    "    Internal function for loading hdf datasets. Decodes json and unicode data automatically.\n",
    "\n",
    "    Args:\n",
    "        dataset (hdf object): dataset to load\n",
    "        name (str): name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing:\n",
    "            | **name (str):** name of the dataset (might be modified)\n",
    "            | **data (object):** loaded data\n",
    "    '''\n",
    "    data = dataset[()]\n",
    "    if '_json' in name:\n",
    "        import json\n",
    "        name = name.replace('_json', '')\n",
    "        data = json.loads(data)\n",
    "    try:\n",
    "        data = data.decode('utf-8')\n",
    "    except:\n",
    "        pass\n",
    "    return name, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5802cedd-b3cd-4c74-b71e-a49db1d6c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aopy\n",
    "import os\n",
    "import pandas as pds\n",
    "from db import dbfunctions as db\n",
    "from ipywidgets import interactive, widgets\n",
    "import scipy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from itertools import compress\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import math\n",
    "from scipy.fft import fft\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b1345-3532-4c0a-be1b-9895db46adda",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd6e7969-b9c3-4121-8594-a6646a7497f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "base_save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/\"\n",
    "np_preproc_data_folder = 'np_analysis_preproc_data'\n",
    "ecog_dec_acc_file_name = 'ecog_decoding_maps/npinsert_ecog_decoding'\n",
    "\n",
    "subject = 'beignet'\n",
    "align_events = ['TARGET ONSET', 'GO CUE', 'MOVEMENT ONSET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd692701-dc60-4b11-a361-5a93fc22ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding calculation parameters\n",
    "tbefore = 0.5\n",
    "tafter = 1\n",
    "nlda_lags = 1\n",
    "niter_match = 50\n",
    "min_trial_prop = .85\n",
    "ntrial_bin_size = 96\n",
    "nfolds = 4\n",
    "\n",
    "# Visualization parameters\n",
    "colors = sn.color_palette(n_colors=9)\n",
    "recording_brain_areas={'M1': [30, 56, 47, 40, 121, 48, 120, 98], 'PM':[11, 9, 18, 22, 10, 45]}\n",
    "day_colors = ['dodgerblue', 'indigo', 'violet', 'lightblue', 'mediumorchid',\n",
    "              'purple', 'steelblue', 'dodgerblue', 'lightblue', 'red', 'black', 'green', 'purple', 'cyan', 'gray', 'yellow'] \n",
    "\n",
    "save_dir = \"/media/moor-data/results/Ryan/neuropixel_targeting/np_analysis_preproc_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00433fce-e97d-46aa-b9c7-c2d30cd2998a",
   "metadata": {},
   "source": [
    "# Load and extract relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8099da1e-5d21-40dc-b084-7da935c18dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecog_dec_acc = load_hdf_group(base_save_dir, ecog_dec_acc_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4381962-bc14-4232-8991-643780d7c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 min to load preprocessed data\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df, rasters, preproc_metadata = aopy.data.base.pkl_read(f\"{subject}_np_preprocessed\", os.path.join(base_save_dir, np_preproc_data_folder))\n",
    "print(f\"{np.round((time.time()-start)/60)} min to load preprocessed data\")\n",
    "nrecs = preproc_metadata['nrecs']\n",
    "recording_site = preproc_metadata['recording_sites'] # will be the same for all align events\n",
    "implants = ['NPinsert72' if preproc_metadata['implant'][irec] == 'NP_Insert72' else 'NPinsert137' for irec in range(len(preproc_metadata['implant']))] #Rename because name in bmi3d is slightly different (TODO)\n",
    "dates = np.unique(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c58de2-234d-416e-a7ae-63d0d7357120",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_results, ksdrift = aopy.data.base.pkl_read(f\"{subject}_QCunits\", os.path.join(base_save_dir, np_preproc_data_folder))\n",
    "stable_unit_labels = [qc_results['final_good_unit_labels'][irec] for irec in range(nrecs)]\n",
    "stable_unit_idx = [qc_results['final_good_unit_idx'][irec] for irec in range(nrecs)]\n",
    "nstable_unit = np.array([len(qc_results['final_good_unit_idx'][irec]) for irec in range(nrecs)])\n",
    "neuron_pos = [qc_results['position'][irec] for irec in range(nrecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61c2c0de-8ba7-41a5-bf6c-de5b682bec77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee987cc65174ef7b88a8a0f749634d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compile dataframe of unit information\n",
    "# Need columns for: date, recording site, unit_label, absolute y-pos, relative y-pos, waveform\n",
    "unit_info = {'rec_number': [], 'date': [], 'rec_site': [], 'rec_xpos': [], 'rec_ypos': [], 'implant': [],\n",
    "             'unit_label': [], 'unit_idx': [], 'abs_depth': [], 'rel_depth': [], 'waveform': []}\n",
    "for irec in tqdm(range(nrecs)):\n",
    "    for iunit in range(nstable_unit[irec]):\n",
    "        unit_info['rec_number'].append(irec) # Recording_number\n",
    "        unit_info['date'].append(np.unique(df['date'])[irec]) # date (assumes each recording is done on a different day)\n",
    "        unit_info['rec_site'].append(recording_site[irec]) # Recording site\n",
    "        unit_info['rec_xpos'].append(ecog_dec_acc[subject]['rec_locations'][irec,0]) # Recording site x pos in chamber\n",
    "        unit_info['rec_ypos'].append(ecog_dec_acc[subject]['rec_locations'][irec,1]) # Recording site y pos in chamber\n",
    "        unit_info['implant'].append(implants[irec]) # Implant\n",
    "        unit_info['unit_label'].append(stable_unit_labels[irec][iunit]) # unit label output from kilosort\n",
    "        unit_info['unit_idx'].append(stable_unit_idx[irec][iunit]) # unit label output from kilosort\n",
    "        unit_info['abs_depth'].append(3840 - neuron_pos[irec][iunit]) #Absolute depth [um]\n",
    "        unit_info['rel_depth'].append(3840-neuron_pos[irec][iunit]-np.min(3840-neuron_pos[irec])) #Relative depth [um] (to top detected neuron)\n",
    "        unit_info['waveform'].append(qc_results['mean_wfs'][irec][iunit,:]) #waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d22c72e-b007-4bb4-9f54-b43525e6f845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit_df = pds.DataFrame(unit_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c27f6f-9304-484d-b19d-a5d1505c3f6f",
   "metadata": {},
   "source": [
    "# Create pseudopopulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "149ea534-93ef-412d-b436-9c2a6640b462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp_configs = ['random', 'column', 'depth'] # Pseudopopulation cofigurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdba088-489b-4296-b9fa-ea91c17b23d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f473ec7-a65c-4dc6-b02e-7a4cd8364ef3",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f8fbb39-0e5a-47b0-a548-d657e70b0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random neuron populations\n",
    "nrandom_units = 13 # Number of random units chosen in each group\n",
    "nrandom_groups = 500 # Number of random groups to make\n",
    "random_group_info = []\n",
    "for igroup in range(nrandom_groups):\n",
    "    group_idx = np.random.choice(np.arange(len(unit_df)), size=(nrandom_units), replace=False)\n",
    "    random_group_info.append(unit_df.loc[group_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3c1a9-aff8-4f9f-a424-19a89a3c71a3",
   "metadata": {},
   "source": [
    "## Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "853f8810-8fdd-42ed-a1c1-5b6f838f3a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create random neuron populations from each recording_location\n",
    "unique_rec_pos = np.unique(ecog_dec_acc[subject]['rec_locations'], axis=0)\n",
    "column_group_info = []\n",
    "for ipos in range(unique_rec_pos.shape[0]):\n",
    "    pos = unique_rec_pos[ipos,:]\n",
    "    column_group_info.append(unit_df.loc[(unit_df['rec_xpos']==pos[0]) & (unit_df['rec_ypos']==pos[1])].reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663e792-6bd0-4cce-abae-d4ec194279a3",
   "metadata": {},
   "source": [
    "## Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be9957bb-f500-4bef-ba38-e842a789cfbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create random neuron populations from shallow and deep neurons\n",
    "depth_ranges = [(0,1000), (1000, 2000), (2000, 100000)] #Boundary distinguishing shallow and deep neurons \n",
    "depth_group_info = []\n",
    "for irange, depth_range in enumerate(depth_ranges):\n",
    "    depth_group_info.append(unit_df.loc[(unit_df['rel_depth'] >= depth_range[0]) & (unit_df['rel_depth'] < depth_range[1])].reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e811bd-b4da-45d2-bad9-301e399b649d",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "121813b3-8d62-451f-ab69-6a31bfbb61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudopopulation_metadata = {'nrandom_units': nrandom_units, 'nrandom_groups': nrandom_groups, 'depth_ranges': depth_ranges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e880982-c856-4aac-b805-1a4d75af210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "aopy.data.base.pkl_write(f\"{subject}_np_psuedopopulations\", (random_group_info, column_group_info, depth_group_info, pseudopopulation_metadata, unit_df), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c84e80ed-dfa1-4132-b81a-a1666257edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "145\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "print(len(depth_group_info[0]))\n",
    "print(len(depth_group_info[1]))\n",
    "print(len(depth_group_info[2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:np_targeting]",
   "language": "python",
   "name": "conda-env-np_targeting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
